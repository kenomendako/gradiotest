# utils.py (å®Œå…¨æœ€çµ‚ç‰ˆ)

import datetime
import os
import re
import traceback
import html
from typing import List, Dict, Optional, Tuple, Union
import constants
import sys
import psutil
from pathlib import Path
import json
import time
import uuid
from bs4 import BeautifulSoup
import io
import contextlib

_model_token_limits_cache: Dict[str, Dict[str, int]] = {}
LOCK_FILE_PATH = Path.home() / ".nexus_ark.global.lock"

def acquire_lock() -> bool:
    print("--- ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ»ãƒ­ãƒƒã‚¯ã®å–å¾—ã‚’è©¦ã¿ã¾ã™ ---")
    try:
        if not LOCK_FILE_PATH.exists():
            _create_lock_file()
            print("--- ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã—ã¾ã—ãŸ (æ–°è¦ä½œæˆ) ---")
            return True
        with open(LOCK_FILE_PATH, "r", encoding="utf-8") as f:
            lock_info = json.load(f)
        pid = lock_info.get('pid')
        if pid and psutil.pid_exists(pid):
            print("\n" + "="*60)
            print("!!! ã‚¨ãƒ©ãƒ¼: Nexus Arkã®åˆ¥ãƒ—ãƒ­ã‚»ã‚¹ãŒæ—¢ã«å®Ÿè¡Œä¸­ã§ã™ã€‚")
            print(f"    - å®Ÿè¡Œä¸­ã®PID: {pid}")
            print(f"    - ãƒ‘ã‚¹: {lock_info.get('path', 'ä¸æ˜')}")
            print("    å¤šé‡èµ·å‹•ã¯ã§ãã¾ã›ã‚“ã€‚æ—¢å­˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã™ã‚‹ã‹ã€")
            print("    ã‚¿ã‚¹ã‚¯ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‹ã‚‰ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¼·åˆ¶çµ‚äº†ã—ã¦ãã ã•ã„ã€‚")
            print("="*60 + "\n")
            return False
        else:
            print("\n" + "!"*60)
            print("è­¦å‘Š: å¤ã„ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
            print(f"  - è¨˜éŒ²ã•ã‚Œã¦ã„ãŸPID: {pid or 'ä¸æ˜'} (ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯ç¾åœ¨å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“)")
            print("  å¤ã„ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•çš„ã«å‰Šé™¤ã—ã¦ã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã€‚")
            print("!"*60 + "\n")
            LOCK_FILE_PATH.unlink()
            time.sleep(0.5)
            _create_lock_file()
            print("--- ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã—ã¾ã—ãŸ (è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œ) ---")
            return True
    except (json.JSONDecodeError, IOError) as e:
        print(f"è­¦å‘Š: ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ« '{LOCK_FILE_PATH}' ãŒç ´æã—ã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚ã‚¨ãƒ©ãƒ¼: {e}")
        print("ç ´æã—ãŸãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦ã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã€‚")
        try:
            LOCK_FILE_PATH.unlink()
            time.sleep(0.5)
            _create_lock_file()
            print("--- ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã—ã¾ã—ãŸ (ç ´æãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¾Œ) ---")
            return True
        except Exception as delete_e:
            print(f"!!! ã‚¨ãƒ©ãƒ¼: ç ´æã—ãŸãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {delete_e}")
            return False
    except Exception as e:
        print(f"!!! ã‚¨ãƒ©ãƒ¼: ãƒ­ãƒƒã‚¯å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()
        return False

def _create_lock_file():
    with open(LOCK_FILE_PATH, "w", encoding="utf-8") as f:
        json.dump({"pid": os.getpid(), "path": os.path.abspath(os.path.dirname(__file__))}, f)

def release_lock():
    try:
        if not LOCK_FILE_PATH.exists():
            return
        with open(LOCK_FILE_PATH, "r", encoding="utf-8") as f:
            lock_info = json.load(f)
        if lock_info.get('pid') == os.getpid():
            LOCK_FILE_PATH.unlink()
            print("\n--- ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ»ãƒ­ãƒƒã‚¯ã‚’è§£æ”¾ã—ã¾ã—ãŸ ---")
        else:
            print(f"\nè­¦å‘Š: è‡ªåˆ†ã®ã‚‚ã®ã§ã¯ãªã„ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ« (PID: {lock_info.get('pid')}) ã‚’è§£æ”¾ã—ã‚ˆã†ã¨ã—ã¾ã—ãŸãŒã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"\nè­¦å‘Š: ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æ”¾ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def load_chat_log(file_path: str) -> List[Dict[str, str]]:
    """
    (Definitive Edition v3)
    Reads a log file and returns a unified list of dictionaries.
    This version uses a robust finditer approach to prevent message content
    from being misinterpreted as a new speaker header.
    """
    messages: List[Dict[str, str]] = []
    if not file_path or not os.path.exists(file_path):
        return messages
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« '{file_path}' èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
        return messages

    if not content.strip():
        return messages

    # Regex to find all valid headers
    header_pattern = re.compile(r'^## (USER|AGENT|SYSTEM):(.+?)$', re.MULTILINE)

    matches = list(header_pattern.finditer(content))

    for i, match in enumerate(matches):
        # Extract header info
        role = match.group(1).upper()
        responder = match.group(2).strip()
        if role == "USER":
            responder = "user"

        # Determine content span
        start_of_content = match.end()
        end_of_content = matches[i + 1].start() if i + 1 < len(matches) else len(content)

        # Extract and clean content
        message_content = content[start_of_content:end_of_content].strip()

        messages.append({"role": role, "responder": responder, "content": message_content})

    return messages


def _perform_log_archiving(log_file_path: str, character_name: str, threshold_bytes: int, keep_bytes: int) -> Optional[str]:
    # Import locally to avoid circular dependencies
    import room_manager
    try:
        if os.path.getsize(log_file_path) <= threshold_bytes:
            return None

        # Create a backup before modifying the log file
        room_manager.create_backup(character_name, 'log')

        print(f"--- [ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–é–‹å§‹] {log_file_path} ãŒ {threshold_bytes / 1024 / 1024:.1f}MB ã‚’è¶…ãˆã¾ã—ãŸ ---")
        with open(log_file_path, "r", encoding="utf-8") as f: content = f.read()
        log_parts = re.split(r'^(## .*?:)$', content, flags=re.MULTILINE)
        messages = []
        header = None
        for part in log_parts:
            part_strip = part.strip()
            if not part_strip: continue
            if part_strip.startswith("## ") and part_strip.endswith(":"): header = part
            elif header: messages.append(header + part); header = None
        current_size = 0
        split_index = len(messages)
        for i in range(len(messages) - 1, -1, -1):
            current_size += len(messages[i].encode('utf-8'))
            if current_size >= keep_bytes:
                if messages[i].strip().startswith(f"## {character_name}:"): split_index = i + 1
                else: split_index = i
                break
        if split_index >= len(messages) or split_index == 0:
            print("--- [ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–] é©åˆ‡ãªåˆ†å‰²ç‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸ ---")
            return None
        content_to_archive = "".join(messages[:split_index])
        content_to_keep = "".join(messages[split_index:])
        archive_dir = os.path.join(os.path.dirname(log_file_path), "log_archives")
        os.makedirs(archive_dir, exist_ok=True)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_path = os.path.join(archive_dir, f"log_archive_{timestamp}.txt")
        with open(archive_path, "w", encoding="utf-8") as f: f.write(content_to_archive.strip())
        with open(log_file_path, "w", encoding="utf-8") as f: f.write(content_to_keep.strip() + "\n\n")
        archive_size_mb = os.path.getsize(archive_path) / 1024 / 1024
        message = f"å¤ã„ãƒ­ã‚°ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã—ã¾ã—ãŸ ({archive_size_mb:.2f}MB)"
        print(f"--- [ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Œäº†] {message} -> {archive_path} ---")
        return message
    except Exception as e:
        print(f"!!! [ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚¨ãƒ©ãƒ¼] {e}"); traceback.print_exc()
        return None

def save_message_to_log(log_file_path: str, header: str, text_content: str) -> Optional[str]:
    import config_manager
    if not all([log_file_path, header, text_content, text_content.strip()]): return None
    try:
        content_to_append = f"{header.strip()}\n{text_content.strip()}\n\n"
        if not os.path.exists(log_file_path) or os.path.getsize(log_file_path) == 0:
             content_to_append = content_to_append.lstrip()
        with open(log_file_path, "a", encoding="utf-8") as f: f.write(content_to_append)
        character_name = os.path.basename(os.path.dirname(log_file_path))
        threshold_mb = config_manager.CONFIG_GLOBAL.get("log_archive_threshold_mb", 10)
        keep_mb = config_manager.CONFIG_GLOBAL.get("log_keep_size_mb", 5)
        threshold_bytes = threshold_mb * 1024 * 1024
        keep_bytes = keep_mb * 1024 * 1024
        return _perform_log_archiving(log_file_path, character_name, threshold_bytes, keep_bytes)
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« '{log_file_path}' æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"); traceback.print_exc()
        return None

def delete_message_from_log(log_file_path: str, message_to_delete: Dict[str, str]) -> bool:
    if not log_file_path or not os.path.exists(log_file_path) or not message_to_delete: return False
    try:
        all_messages = load_chat_log(log_file_path)
        original_len = len(all_messages)
        all_messages = [msg for msg in all_messages if not (msg.get("content") == message_to_delete.get("content") and msg.get("responder") == message_to_delete.get("responder"))]
        if len(all_messages) >= original_len:
            print(f"è­¦å‘Š: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å†…ã«å‰Šé™¤å¯¾è±¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"); return False
        log_content_parts = []
        for msg in all_messages:
            role = msg.get("role", "AGENT").upper(); responder_id = msg.get("responder", "ä¸æ˜")
            header = f"## {role}:{responder_id}"
            content = msg.get('content', '').strip()
            if content: log_content_parts.append(f"{header}\n{content}")
        new_log_content = "\n\n".join(log_content_parts)
        with open(log_file_path, "w", encoding="utf-8") as f: f.write(new_log_content)
        if new_log_content:
            with open(log_file_path, "a", encoding="utf-8") as f: f.write("\n\n")
        print("--- Successfully deleted message from log ---"); return True
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ­ã‚°ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‰Šé™¤ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}"); traceback.print_exc()
        return False

def remove_thoughts_from_text(text: str) -> str:
    if not text: return ""
    # æ–°ã—ã„ <thinking> ã‚¿ã‚°ã«å¯¾å¿œ
    thoughts_pattern = re.compile(r"<thinking>.*?</thinking>\s*", re.DOTALL | re.IGNORECASE)
    return thoughts_pattern.sub("", text).strip()

def get_current_location(character_name: str) -> Optional[str]:
    try:
        location_file_path = os.path.join("characters", character_name, "current_location.txt")
        if os.path.exists(location_file_path):
            with open(location_file_path, 'r', encoding='utf-8') as f: return f.read().strip()
    except Exception as e:
        print(f"è­¦å‘Š: ç¾åœ¨åœ°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    return None

def extract_raw_text_from_html(html_content: Union[str, tuple, None]) -> str:
    if not html_content or not isinstance(html_content, str): return ""
    soup = BeautifulSoup(html_content, 'html.parser')
    thoughts_text = ""
    thoughts_div = soup.find('div', class_='thoughts')
    if thoughts_div:
        for br in thoughts_div.find_all("br"): br.replace_with("\n")
        thoughts_content = thoughts_div.get_text()
        if thoughts_content: thoughts_text = f"ã€Thoughtsã€‘\n{thoughts_content.strip()}\nã€/Thoughtsã€‘\n\n"
        thoughts_div.decompose()
    for nav_div in soup.find_all('div', style=lambda v: v and 'text-align: right' in v): nav_div.decompose()
    for anchor_span in soup.find_all('span', id=lambda v: v and v.startswith('msg-anchor-')): anchor_span.decompose()
    for br in soup.find_all("br"): br.replace_with("\n")
    main_text = soup.get_text()
    return (thoughts_text + main_text).strip()

def load_scenery_cache(room_name: str) -> dict:
    if not room_name: return {}
    cache_path = os.path.join(constants.ROOMS_DIR, room_name, "cache", "scenery.json")
    if os.path.exists(cache_path):
        try:
            with open(cache_path, "r", encoding="utf-8") as f:
                content = f.read()
                if not content.strip(): return {}
                data = json.loads(content)
                return data if isinstance(data, dict) else {}
        except (json.JSONDecodeError, IOError): return {}
    return {}

def save_scenery_cache(room_name: str, cache_key: str, location_name: str, scenery_text: str):
    if not room_name or not cache_key: return
    cache_path = os.path.join(constants.ROOMS_DIR, room_name, "cache", "scenery.json")
    try:
        existing_cache = load_scenery_cache(room_name)
        data_to_save = {"location_name": location_name, "scenery_text": scenery_text, "timestamp": datetime.datetime.now().isoformat()}
        existing_cache[cache_key] = data_to_save
        with open(cache_path, "w", encoding="utf-8") as f: json.dump(existing_cache, f, indent=2, ensure_ascii=False)
    except Exception as e:
        print(f"!! ã‚¨ãƒ©ãƒ¼: æƒ…æ™¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def format_tool_result_for_ui(tool_name: str, tool_result: str) -> Optional[str]:
    if not tool_name or not tool_result: return None
    if "Error" in tool_result or "ã‚¨ãƒ©ãƒ¼" in tool_result: return f"âš ï¸ ãƒ„ãƒ¼ãƒ«ã€Œ{tool_name}ã€ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    display_text = ""
    if tool_name == 'set_current_location':
        location_match = re.search(r"ç¾åœ¨åœ°ã¯ '(.*?)' ã«è¨­å®šã•ã‚Œã¾ã—ãŸ", tool_result)
        if location_match: display_text = f'ç¾åœ¨åœ°ã‚’ã€Œ{location_match.group(1)}ã€ã«è¨­å®šã—ã¾ã—ãŸã€‚'
    elif tool_name == 'set_timer':
        duration_match = re.search(r"for (\d+) minutes", tool_result)
        if duration_match: display_text = f"ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚»ãƒƒãƒˆã—ã¾ã—ãŸï¼ˆ{duration_match.group(1)}åˆ†ï¼‰"
    elif tool_name == 'set_pomodoro_timer':
        match = re.search(r"(\d+) cycles \((\d+) min work, (\d+) min break\)", tool_result)
        if match: display_text = f"ãƒãƒ¢ãƒ‰ãƒ¼ãƒ­ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚»ãƒƒãƒˆã—ã¾ã—ãŸï¼ˆ{match.group(2)}åˆ†ãƒ»{match.group(3)}åˆ†ãƒ»{match.group(1)}ã‚»ãƒƒãƒˆï¼‰"
    elif tool_name == 'web_search_tool': display_text = 'Webæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚'
    elif tool_name == 'add_to_notepad':
        entry_match = re.search(r'entry "(.*?)" was added', tool_result)
        if entry_match: display_text = f'ãƒ¡ãƒ¢å¸³ã«ã€Œ{entry_match.group(1)[:30]}...ã€ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚'
    elif tool_name == 'update_notepad':
        entry_match = re.search(r'updated to "(.*?)"', tool_result)
        if entry_match: display_text = f'ãƒ¡ãƒ¢å¸³ã‚’ã€Œ{entry_match.group(1)[:30]}...ã€ã«æ›´æ–°ã—ã¾ã—ãŸã€‚'
    elif tool_name == 'delete_from_notepad':
        entry_match = re.search(r'deleted from the notepad', tool_result)
        if entry_match: display_text = f'ãƒ¡ãƒ¢å¸³ã‹ã‚‰é …ç›®ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚'
    elif tool_name == 'generate_image': display_text = 'æ–°ã—ã„ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚'
    return f"ğŸ› ï¸ {display_text}" if display_text else f"ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«ã€Œ{tool_name}ã€ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚"

def get_season(month: int) -> str:
    if month in [3, 4, 5]: return "spring"
    if month in [6, 7, 8]: return "summer"
    if month in [9, 10, 11]: return "autumn"
    return "winter"

def get_time_of_day(hour: int) -> str:
    if 5 <= hour < 10: return "morning"
    if 10 <= hour < 17: return "daytime"
    if 17 <= hour < 19: return "evening"
    return "night"

def find_scenery_image(room_name: str, location_id: str, season_en: str = None, time_of_day_en: str = None) -> Optional[str]:
    """
    ã€v2: æ™‚é–“æŒ‡å®šå¯¾å¿œã€‘
    æŒ‡å®šã•ã‚ŒãŸå ´æ‰€ã¨æ™‚é–“ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æœ€ã‚‚ä¸€è‡´ã™ã‚‹æƒ…æ™¯ç”»åƒã‚’æ¤œç´¢ã™ã‚‹ã€‚
    å®Œå…¨ä¸€è‡´ -> å­£ç¯€ä¸€è‡´ -> å ´æ‰€ã®ã¿ä¸€è‡´ ã®å„ªå…ˆé †ä½ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ã€‚
    """
    if not room_name or not location_id: return None
    image_dir = os.path.join(constants.ROOMS_DIR, room_name, "spaces", "images")
    if not os.path.isdir(image_dir): return None

    # --- é©ç”¨ã™ã¹ãæ™‚é–“ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ±ºå®š ---
    # å¼•æ•°ã§æ¸¡ã•ã‚Œãªã‹ã£ãŸå ´åˆã¯ã€ç¾åœ¨æ™‚åˆ»ã‹ã‚‰å–å¾—ã™ã‚‹
    now = datetime.datetime.now()
    effective_season = season_en or get_season(now.month)
    effective_time_of_day = time_of_day_en or get_time_of_day(now.hour)

    # 1. å®Œå…¨ä¸€è‡´ã®æ¤œç´¢ (å ´æ‰€_å­£ç¯€_æ™‚é–“å¸¯.png)
    target_filename = f"{location_id}_{effective_season}_{effective_time_of_day}.png"
    target_path = os.path.join(image_dir, target_filename)
    if os.path.exists(target_path):
        print(f"--- æœ€é©ãªæƒ…æ™¯ç”»åƒã‚’ç™ºè¦‹ (å®Œå…¨ä¸€è‡´): {target_path} ---"); return target_path

    # 2. å­£ç¯€ä¸€è‡´ã®æ¤œç´¢ (å ´æ‰€_å­£ç¯€_*.png)
    try:
        for filename in os.listdir(image_dir):
            if filename.startswith(f"{location_id}_{effective_season}_") and filename.lower().endswith('.png'):
                found_path = os.path.join(image_dir, filename)
                print(f"--- æœ€é©ãªæƒ…æ™¯ç”»åƒã‚’ç™ºè¦‹ (å­£ç¯€ä¸€è‡´): {found_path} ---"); return found_path
    except FileNotFoundError: pass

    # 3. å ´æ‰€ã®ã¿ä¸€è‡´ã®æ¤œç´¢ (å ´æ‰€.png ã¾ãŸã¯ å ´æ‰€_*.png)
    try:
        # ã¾ãšã¯å˜ç´”ãª `å ´æ‰€.png` ã‚’æ¢ã™
        fallback_path = os.path.join(image_dir, f"{location_id}.png")
        if os.path.exists(fallback_path):
            print(f"--- æœ€é©ãªæƒ…æ™¯ç”»åƒã‚’ç™ºè¦‹ (å ´æ‰€ä¸€è‡´): {fallback_path} ---"); return fallback_path

        # ãã‚Œã‚‚ãªã‘ã‚Œã° `å ´æ‰€_` ã§å§‹ã¾ã‚‹ã‚‚ã®ã‚’æ¢ã™
        for filename in os.listdir(image_dir):
            if filename.startswith(f"{location_id}_") and filename.lower().endswith('.png'):
                found_path = os.path.join(image_dir, filename)
                print(f"--- æœ€é©ãªæƒ…æ™¯ç”»åƒã‚’ç™ºè¦‹ (å ´æ‰€ä¸€è‡´): {found_path} ---"); return found_path
    except FileNotFoundError: pass

    # 4. ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneã‚’è¿”ã™
    return None

def parse_world_file(file_path: str) -> dict:
    if not os.path.exists(file_path): return {}
    with open(file_path, "r", encoding="utf-8") as f: content = f.read()
    world_data = {}; current_area_key = None; current_place_key = None
    lines = content.split('\n')
    for line in lines:
        line_strip = line.strip()
        if line_strip.startswith("## "):
            current_area_key = line_strip[3:].strip()
            if current_area_key not in world_data: world_data[current_area_key] = {}
            current_place_key = None
        elif line_strip.startswith("### "):
            if current_area_key:
                current_place_key = line_strip[4:].strip()
                world_data[current_area_key][current_place_key] = ""
            else: print(f"è­¦å‘Š: ã‚¨ãƒªã‚¢ãŒå®šç¾©ã•ã‚Œã‚‹å‰ã«å ´æ‰€ '{line_strip}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
        else:
            if current_area_key and current_place_key:
                if world_data[current_area_key][current_place_key]: world_data[current_area_key][current_place_key] += "\n" + line
                else: world_data[current_area_key][current_place_key] = line
    for area, places in world_data.items():
        for place, text in places.items(): world_data[area][place] = text.strip()
    return world_data

def delete_and_get_previous_user_input(log_file_path: str, ai_message_to_delete: Dict[str, str]) -> Optional[str]:
    if not all([log_file_path, os.path.exists(log_file_path), ai_message_to_delete]): return None
    try:
        all_messages = load_chat_log(log_file_path)
        target_start_index = -1
        for i, msg in enumerate(all_messages):
            if (msg.get("content") == ai_message_to_delete.get("content") and msg.get("responder") == ai_message_to_delete.get("responder")):
                target_start_index = i; break
        if target_start_index == -1: return None
        last_user_message_index = -1
        for i in range(target_start_index - 1, -1, -1):
            if all_messages[i].get("role") == "USER":
                last_user_message_index = i; break
        if last_user_message_index == -1: return None
        user_message_content = all_messages[last_user_message_index].get("content", "")
        messages_to_keep = all_messages[:last_user_message_index]
        log_content_parts = []
        for msg in messages_to_keep:
            header = f"## {msg.get('role', 'AGENT').upper()}:{msg.get('responder', 'ä¸æ˜')}"
            content = msg.get('content', '').strip()
            if content: log_content_parts.append(f"{header}\n{content}")
        new_log_content = "\n\n".join(log_content_parts)
        with open(log_file_path, "w", encoding="utf-8") as f: f.write(new_log_content)
        if new_log_content:
            with open(log_file_path, "a", encoding="utf-8") as f: f.write("\n\n")
        content_without_timestamp = re.sub(r'\n\n\d{4}-\d{2}-\d{2} \(...\) \d{2}:\d{2}:\d{2}$', '', user_message_content, flags=re.MULTILINE)
        restored_input = content_without_timestamp.strip()
        print("--- Successfully reset conversation to the last user input for rerun ---")
        return restored_input
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: å†ç”Ÿæˆã®ãŸã‚ã®ãƒ­ã‚°å‰Šé™¤ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}"); traceback.print_exc()
        return None

@contextlib.contextmanager
def capture_prints():
    original_stdout = sys.stdout; original_stderr = sys.stderr
    string_io = io.StringIO()
    sys.stdout = string_io; sys.stderr = string_io
    try: yield string_io
    finally: sys.stdout = original_stdout; sys.stderr = original_stderr

def delete_user_message_and_after(log_file_path: str, user_message_to_delete: Dict[str, str]) -> Optional[str]:
    if not all([log_file_path, os.path.exists(log_file_path), user_message_to_delete]): return None
    try:
        all_messages = load_chat_log(log_file_path)
        target_index = -1
        for i, msg in enumerate(all_messages):
            if (msg.get("content") == user_message_to_delete.get("content") and msg.get("responder") == user_message_to_delete.get("responder")):
                target_index = i; break
        if target_index == -1: return None
        user_message_content = all_messages[target_index].get("content", "")
        messages_to_keep = all_messages[:target_index]
        log_content_parts = []
        for msg in messages_to_keep:
            header = f"## {msg.get('role', 'AGENT').upper()}:{msg.get('responder', 'ä¸æ˜')}"
            content = msg.get('content', '').strip()
            if content: log_content_parts.append(f"{header}\n{content}")
        new_log_content = "\n\n".join(log_content_parts)
        with open(log_file_path, "w", encoding="utf-8") as f: f.write(new_log_content)
        if new_log_content:
            with open(log_file_path, "a", encoding="utf-8") as f: f.write("\n\n")
        content_without_timestamp = re.sub(r'\n\n\d{4}-\d{2}-\d{2} \(...\) \d{2}:\d{2}:\d{2}$', '', user_message_content, flags=re.MULTILINE)
        restored_input = content_without_timestamp.strip()
        print("--- Successfully reset conversation to before the selected user input for rerun ---")
        return restored_input
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ä»¥é™ã®ãƒ­ã‚°å‰Šé™¤ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}"); traceback.print_exc()
        return None

def create_dynamic_sanctuary(main_log_path: str, user_start_phrase: str) -> Optional[str]:
    if not main_log_path or not os.path.exists(main_log_path) or not user_start_phrase: return None
    try:
        with open(main_log_path, "r", encoding="utf-8") as f: full_content = f.read()
        cleaned_phrase = re.sub(r'\n\n\d{4}-\d{2}-\d{2} \(...\) \d{2}:\d{2}:\d{2}$', '', user_start_phrase, flags=re.MULTILINE).strip()
        pattern = re.compile(r"(^## ãƒ¦ãƒ¼ã‚¶ãƒ¼:\s*" + re.escape(cleaned_phrase) + r".*?)(?=^## |\Z)", re.DOTALL | re.MULTILINE)
        match = pattern.search(full_content)
        if not match:
            print(f"è­¦å‘Šï¼šå‹•çš„è–åŸŸã®èµ·ç‚¹ã¨ãªã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å®Œå…¨ãªãƒ­ã‚°ã‚’è–åŸŸã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚")
            sanctuary_content = full_content
        else: sanctuary_content = full_content[match.start():]
        temp_dir = os.path.join("temp", "sanctuaries"); os.makedirs(temp_dir, exist_ok=True)
        sanctuary_path = os.path.join(temp_dir, f"sanctuary_{uuid.uuid4().hex}.txt")
        with open(sanctuary_path, "w", encoding="utf-8") as f: f.write(sanctuary_content)
        return sanctuary_path
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ï¼šå‹•çš„è–åŸŸã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); traceback.print_exc()
        return None

def cleanup_sanctuaries():
    temp_dir = os.path.join("temp", "sanctuaries")
    if not os.path.exists(temp_dir): return

def create_turn_snapshot(main_log_path: str, user_start_phrase: str) -> Optional[str]:
    if not main_log_path or not os.path.exists(main_log_path) or not user_start_phrase: return None
    try:
        with open(main_log_path, "r", encoding="utf-8") as f: full_content = f.read()
        cleaned_phrase = re.sub(r'\[ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜:.*?\]', '', user_start_phrase, flags=re.DOTALL).strip()
        cleaned_phrase = re.sub(r'\n\n\d{4}-\d{2}-\d{2} \(...\) \d{2}:\d{2}:\d{2}$', '', cleaned_phrase, flags=re.MULTILINE).strip()
        pattern = re.compile(r"(^## (?:ãƒ¦ãƒ¼ã‚¶ãƒ¼|ãƒ¦ãƒ¼ã‚¶ãƒ¼):" + re.escape(cleaned_phrase) + r".*?)(?=^## (?:ãƒ¦ãƒ¼ã‚¶ãƒ¼|ãƒ¦ãƒ¼ã‚¶ãƒ¼):|\Z)", re.DOTALL | re.MULTILINE)
        matches = [m for m in pattern.finditer(full_content)]
        if not matches: snapshot_content = f"## ãƒ¦ãƒ¼ã‚¶ãƒ¼:\n{user_start_phrase.strip()}\n\n"
        else: last_match = matches[-1]; snapshot_content = full_content[last_match.start():]
        temp_dir = os.path.join("temp", "snapshots"); os.makedirs(temp_dir, exist_ok=True)
        snapshot_path = os.path.join(temp_dir, f"snapshot_{uuid.uuid4().hex}.txt")
        with open(snapshot_path, "w", encoding="utf-8") as f: f.write(snapshot_content)
        return snapshot_path
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ï¼šã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); traceback.print_exc()
        return None

def is_character_name(name: str) -> bool:
    if not name or not isinstance(name, str) or not name.strip(): return False
    if ".." in name or "/" in name or "\\" in name: return False
    room_dir = os.path.join(constants.ROOMS_DIR, name)
    return os.path.isdir(room_dir)

# â–¼â–¼â–¼ã€ã“ã“ã‹ã‚‰ãŒæ–°ã—ãè¿½åŠ ã™ã‚‹é–¢æ•°ã€‘â–¼â–¼â–¼
def _overwrite_log_file(file_path: str, messages: List[Dict]):
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¾æ›¸ã®ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Œå…¨ã«ä¸Šæ›¸ãã™ã‚‹ã€‚
    """
    log_content_parts = []
    for msg in messages:
        # æ–°ã—ã„ãƒ­ã‚°å½¢å¼ `ROLE:NAME` ã«å®Œå…¨æº–æ‹ ã—ã¦æ›¸ãå‡ºã™
        role = msg.get("role", "AGENT").upper()
        responder_id = msg.get("responder", "ä¸æ˜")
        header = f"## {role}:{responder_id}"
        content = msg.get('content', '').strip()
        # contentãŒç©ºã§ã‚‚ãƒ˜ãƒƒãƒ€ãƒ¼ã¯è¨˜éŒ²ã•ã‚Œã‚‹ã¹ãå ´åˆãŒã‚ã‚‹ãŸã‚ã€
        # responder_idãŒå­˜åœ¨ã™ã‚Œã°ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆã™ã‚‹
        if responder_id:
             log_content_parts.append(f"{header}\n{content}")

    new_log_content = "\n\n".join(log_content_parts)
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(new_log_content)
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ«å°¾ã«è¿½è¨˜ç”¨ã®æ”¹è¡Œã‚’è¿½åŠ 
    if new_log_content:
        with open(file_path, "a", encoding="utf-8") as f:
            f.write("\n\n")

# â–²â–²â–²ã€è¿½åŠ ã¯ã“ã“ã¾ã§ã€‘â–²â–²â–²

def load_html_cache(room_name: str) -> Dict[str, str]:
    """æŒ‡å®šã•ã‚ŒãŸãƒ«ãƒ¼ãƒ ã®HTMLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã‚€ã€‚"""
    if not room_name:
        return {}
    cache_path = os.path.join(constants.ROOMS_DIR, room_name, "cache", "html_cache.json")
    if os.path.exists(cache_path):
        try:
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ0ã§ãªã„ã“ã¨ã‚‚ãƒã‚§ãƒƒã‚¯
            if os.path.getsize(cache_path) > 0:
                with open(cache_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    return data if isinstance(data, dict) else {}
        except (json.JSONDecodeError, IOError):
            pass # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯æ–°ã—ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½œæˆ
    return {}

def save_html_cache(room_name: str, cache_data: Dict[str, str]):
    """æŒ‡å®šã•ã‚ŒãŸãƒ«ãƒ¼ãƒ ã®HTMLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜ã™ã‚‹ã€‚"""
    if not room_name:
        return
    cache_dir = os.path.join(constants.ROOMS_DIR, room_name, "cache")
    os.makedirs(cache_dir, exist_ok=True)
    cache_path = os.path.join(cache_dir, "html_cache.json")
    try:
        # æ–°ã—ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã—ã¦ã‹ã‚‰ãƒªãƒãƒ¼ãƒ ã™ã‚‹ã“ã¨ã§ã€æ›¸ãè¾¼ã¿ä¸­ã®ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ç ´æã‚’é˜²ã
        temp_path = cache_path + ".tmp"
        with open(temp_path, "w", encoding="utf-8") as f:
            json.dump(cache_data, f) # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãŸã‚ã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆãªã—ã§ä¿å­˜
        os.replace(temp_path, cache_path)
    except Exception as e:
        print(f"!! ã‚¨ãƒ©ãƒ¼: HTMLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
