# agent/graph.py ã®å†…å®¹ã‚’ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§å®Œå…¨ã«ç½®ãæ›ãˆã¦ãã ã•ã„

import os
import re
import traceback
from typing import TypedDict, Annotated, List, Literal
from langchain_core.messages import SystemMessage, BaseMessage, ToolMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END, START, add_messages
from datetime import datetime
from langgraph.prebuilt import ToolNode

from agent.prompts import CORE_PROMPT_TEMPLATE
from tools.space_tools import set_current_location, find_location_id_by_name
from tools.memory_tools import read_memory_by_path, edit_memory, add_secret_diary_entry, summarize_and_save_core_memory, read_full_memory
from tools.notepad_tools import add_to_notepad, update_notepad, delete_from_notepad, read_full_notepad
from tools.web_tools import web_search_tool, read_url_tool
from tools.image_tools import generate_image
from tools.alarm_tools import set_personal_alarm
from rag_manager import diary_search_tool, conversation_memory_search_tool

# --- 1. ãƒ„ãƒ¼ãƒ«å®šç¾© ---
all_tools = [
    set_current_location, find_location_id_by_name, read_memory_by_path, edit_memory,
    add_secret_diary_entry, summarize_and_save_core_memory, add_to_notepad,
    update_notepad, delete_from_notepad, read_full_notepad, web_search_tool,
    read_url_tool, diary_search_tool, conversation_memory_search_tool,
    generate_image, read_full_memory, set_personal_alarm
]

# --- 2. çŠ¶æ…‹å®šç¾© ---
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    character_name: str
    api_key: str
    tavily_api_key: str
    model_name: str
    system_prompt: SystemMessage
    send_core_memory: bool # â˜…â˜…â˜… ã“ã®è¡Œã‚’è¿½åŠ  â˜…â˜…â˜…

# --- 3. ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– ---
def get_configured_llm(model_name: str, api_key: str):
    return ChatGoogleGenerativeAI(model=model_name, google_api_key=api_key, convert_system_message_to_human=False)

# --- 4. ã‚°ãƒ©ãƒ•ã®ãƒãƒ¼ãƒ‰å®šç¾© ---
def context_generator_node(state: AgentState):
    print("--- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒãƒ¼ãƒ‰ (context_generator_node) å®Ÿè¡Œ ---")
    character_name = state['character_name']
    api_key = state['api_key']
    scenery_text = "ï¼ˆç¾åœ¨ã®å ´æ‰€ã®æƒ…æ™¯æå†™ã¯ã€å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
    
    try:
        location_to_describe = None
        last_tool_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, ToolMessage)), None)
        if last_tool_message and "Success: Location set to" in last_tool_message.content:
            match = re.search(r"'(.*?)'", last_tool_message.content)
            if match:
                location_to_describe = match.group(1)
                print(f"  - ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã‹ã‚‰æœ€æ–°ã®å ´æ‰€ '{location_to_describe}' ã‚’ç‰¹å®šã—ã¾ã—ãŸã€‚")

        if not location_to_describe:
            try:
                location_file_path = os.path.join("characters", character_name, "current_location.txt")
                if os.path.exists(location_file_path):
                    with open(location_file_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if content:
                            location_to_describe = content
                            print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç¾åœ¨ã®å ´æ‰€ '{location_to_describe}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
            except Exception as e:
                print(f"  - è­¦å‘Š: ç¾åœ¨åœ°ãƒ•ã‚¡ã‚¤ãƒ«èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")

        if not location_to_describe:
            location_to_describe = "living_space"
            print(f"  - å ´æ‰€ãŒç‰¹å®šã§ããªã‹ã£ãŸãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® '{location_to_describe}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

        llm_flash = get_configured_llm("gemini-2.5-flash", api_key)
        
        found_id_result = find_location_id_by_name.invoke({"location_name": location_to_describe, "character_name": character_name})
        id_to_use = location_to_describe
        if not found_id_result.startswith("Error:"):
            id_to_use = found_id_result
        
        space_def = read_memory_by_path.invoke({"path": f"living_space.{id_to_use}", "character_name": character_name})

        if not space_def.startswith("ã€Errorã€‘") and not space_def.startswith("Error:"):
            now = datetime.now()
            scenery_prompt = f"ç©ºé–“å®šç¾©:{space_def}\næ™‚åˆ»:{now.strftime('%H:%M')}\nå­£ç¯€:{now.month}æœˆ\nä»¥ä¸Šã®æƒ…å ±ã‹ã‚‰2-3æ–‡ã§ã€äººç‰©æå†™ã‚’æ’ã—æ°—æ¸©ãƒ»æ¹¿åº¦ãƒ»éŸ³ãƒ»åŒ‚ã„ãƒ»æ„Ÿè§¦ã¾ã§ä¼ã‚ã‚‹ã‚ˆã†ãªç²¾ç·»ã§å†™å®Ÿçš„ãªæƒ…æ™¯ã‚’æå†™:"
            scenery_text = llm_flash.invoke(scenery_prompt).content
            print(f"  - ç”Ÿæˆã•ã‚ŒãŸæƒ…æ™¯æå†™: {scenery_text}")
        else:
            print(f"  - è­¦å‘Š: å ´æ‰€ã€Œ{location_to_describe}ã€(ID: {id_to_use}) ã®å®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    except Exception as e:
        print(f"--- è­¦å‘Š: æƒ…æ™¯æå†™ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ---\n{traceback.format_exc()}")

    char_prompt_path = os.path.join("characters", character_name, "SystemPrompt.txt")
    character_prompt = ""
    if os.path.exists(char_prompt_path):
        with open(char_prompt_path, 'r', encoding='utf-8') as f: character_prompt = f.read().strip()

    # â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ â˜…â˜…â˜…
    core_memory = ""
    if state.get("send_core_memory", True): # stateã‹ã‚‰ãƒ•ãƒ©ã‚°ã‚’å–å¾—ã€‚ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆTrue
        core_memory_path = os.path.join("characters", character_name, "core_memory.txt")
        if os.path.exists(core_memory_path):
            with open(core_memory_path, 'r', encoding='utf-8') as f:
                core_memory = f.read().strip()
    # â˜…â˜…â˜… ä¿®æ­£ã“ã“ã¾ã§ â˜…â˜…â˜…

    tools_list_str = "\n".join([f"- `{tool.name}({', '.join(tool.args.keys())})`: {tool.description}" for tool in all_tools])

    class SafeDict(dict):
        def __missing__(self, key):
            return f'{{{key}}}'
            
    prompt_vars = {
        'character_name': character_name,
        'character_prompt': character_prompt,
        'core_memory': core_memory,
        'tools_list': tools_list_str
    }
    formatted_core_prompt = CORE_PROMPT_TEMPLATE.format_map(SafeDict(prompt_vars))
    final_system_prompt_text = f"{formatted_core_prompt}\n---\nã€ç¾åœ¨ã®æƒ…æ™¯ã€‘\n{scenery_text}\n---"

    return {"system_prompt": SystemMessage(content=final_system_prompt_text)}

def agent_node(state: AgentState):
    print("--- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ‰ (agent_node) å®Ÿè¡Œ ---")
    llm = get_configured_llm(state['model_name'], state['api_key'])
    llm_with_tools = llm.bind_tools(all_tools)
    messages_for_agent = [state['system_prompt']] + state['messages']
    response = llm_with_tools.invoke(messages_for_agent)
    return {"messages": [response]}

# --- 5. ãƒ«ãƒ¼ã‚¿ãƒ¼ã®å®šç¾© ---
def route_after_agent(state: AgentState) -> Literal["__end__", "tool_node"]:
    print("--- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_agent) å®Ÿè¡Œ ---")
    last_message = state["messages"][-1]
    
    if last_message.tool_calls:
        # â˜… å¤‰æ›´ç‚¹1: ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®è©³ç´°ã‚’ãƒ­ã‚°ã«å‡ºåŠ› â˜…
        print("  - ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚ã‚Šã€‚ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒãƒ¼ãƒ‰ã¸ã€‚")
        for tool_call in last_message.tool_calls:
            print(f"    ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: {tool_call['name']} | å¼•æ•°: {tool_call['args']}")
        return "tool_node"
        
    print("  - ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãªã—ã€‚æ€è€ƒå®Œäº†ã¨åˆ¤æ–­ã—ã€ã‚°ãƒ©ãƒ•ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    return "__end__"

def route_after_tools(state: AgentState) -> Literal["context_generator", "agent"]:
    print("--- ãƒ„ãƒ¼ãƒ«å¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_tools) å®Ÿè¡Œ ---")
    
    # â˜… å¤‰æ›´ç‚¹2: ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã‚’ãƒ­ã‚°ã«å‡ºåŠ› â˜…
    # æœ€å¾Œã®AIMessageä»¥é™ã«è¿½åŠ ã•ã‚ŒãŸToolMessageã‚’ç‰¹å®šã—ã¦ãƒ­ã‚°ã«å‡ºåŠ›
    last_ai_message_index = -1
    for i in range(len(state["messages"]) - 1, -1, -1):
        if isinstance(state["messages"][i], AIMessage):
            last_ai_message_index = i
            break
            
    if last_ai_message_index != -1:
        new_tool_messages = state["messages"][last_ai_message_index + 1:]
        for msg in new_tool_messages:
            if isinstance(msg, ToolMessage):
                # â˜… å¤‰æ›´ç‚¹3: çµæœãŒé•·ã„å ´åˆã«çœç•¥ã™ã‚‹å‡¦ç†ã‚’è¿½åŠ  â˜…
                content_to_log = (str(msg.content)[:200] + '...') if len(str(msg.content)) > 200 else str(msg.content)
                print(f"    âœ… ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ: {msg.name} | çµæœ: {content_to_log}")

    last_ai_message_with_tool_call = next((msg for msg in reversed(state['messages']) if isinstance(msg, AIMessage) and msg.tool_calls), None)
    
    if last_ai_message_with_tool_call:
        if any(call['name'] == 'set_current_location' for call in last_ai_message_with_tool_call.tool_calls):
            print("  - `set_current_location` ãŒå®Ÿè¡Œã•ã‚ŒãŸãŸã‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†ç”Ÿæˆã¸ã€‚")
            return "context_generator"
            
    print("  - é€šå¸¸ã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå®Œäº†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€è€ƒã¸ã€‚")
    return "agent"

# --- 6. ã‚°ãƒ©ãƒ•æ§‹ç¯‰ ---
workflow = StateGraph(AgentState)

workflow.add_node("context_generator", context_generator_node)
workflow.add_node("agent", agent_node)
tool_node = ToolNode(all_tools)
workflow.add_node("tool_node", tool_node)

workflow.add_edge(START, "context_generator")
workflow.add_edge("context_generator", "agent")

workflow.add_conditional_edges(
    "agent",
    route_after_agent,
    {"tool_node": "tool_node", "__end__": END}
)

workflow.add_conditional_edges(
    "tool_node",
    route_after_tools,
    {"context_generator": "context_generator", "agent": "agent"}
)

app = workflow.compile()
print("--- æœ€çµ‚å®Œæˆç‰ˆv36ï¼šãƒ„ãƒ¼ãƒ«åˆ©ç”¨ã®ãƒ­ã‚°å‡ºåŠ›æ©Ÿèƒ½ã‚’æ­è¼‰ã—ãŸã‚°ãƒ©ãƒ•ãŒã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¾ã—ãŸ ---")
