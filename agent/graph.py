# agent/graph.py (v21: Smart Retry)

import os
import re
import traceback
import json
import time
from datetime import datetime
from typing import TypedDict, Annotated, List, Literal, Tuple

from langchain_core.messages import SystemMessage, BaseMessage, ToolMessage, AIMessage, HumanMessage
from google.api_core import exceptions as google_exceptions
from gemini_api import get_configured_llm
from langgraph.graph import StateGraph, END, START, add_messages

from agent.prompts import CORE_PROMPT_TEMPLATE
from tools.space_tools import set_current_location, read_world_settings, plan_world_edit, _apply_world_edits
from tools.memory_tools import read_full_memory, plan_memory_edit, _apply_memory_edits
from tools.notepad_tools import read_full_notepad, plan_notepad_edit, _write_notepad_file
from tools.web_tools import web_search_tool, read_url_tool
from tools.image_tools import generate_image
from tools.alarm_tools import set_personal_alarm
from tools.timer_tools import set_timer, set_pomodoro_timer
from tools.knowledge_tools import search_knowledge_graph
from room_manager import get_world_settings_path
import utils
import config_manager
import constants
import pytz

all_tools = [
    set_current_location, read_world_settings, plan_world_edit,
    read_full_memory, plan_memory_edit,
    read_full_notepad, plan_notepad_edit,
    web_search_tool, read_url_tool,
    generate_image,
    set_personal_alarm,
    set_timer, set_pomodoro_timer,
    search_knowledge_graph
]

class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    room_name: str
    api_key: str
    model_name: str
    system_prompt: SystemMessage
    generation_config: dict
    send_core_memory: bool
    send_scenery: bool
    send_notepad: bool
    location_name: str
    scenery_text: str
    debug_mode: bool
    all_participants: List[str]

def get_location_list(room_name: str) -> List[str]:
    if not room_name: return []
    world_settings_path = get_world_settings_path(room_name)
    if not world_settings_path or not os.path.exists(world_settings_path): return []
    world_data = utils.parse_world_file(world_settings_path)
    if not world_data: return []
    locations = []
    for area_name, places in world_data.items():
        for place_name in places.keys():
            if place_name == "__area_description__": continue
            locations.append(f"[{area_name}] {place_name}")
    return sorted(locations)

def generate_scenery_context(room_name: str, api_key: str, force_regenerate: bool = False) -> Tuple[str, str, str]:
    scenery_text = "ï¼ˆç¾åœ¨ã®å ´æ‰€ã®æƒ…æ™¯æå†™ã¯ã€å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
    space_def = "ï¼ˆç¾åœ¨ã®å ´æ‰€ã®å®šç¾©ãƒ»è¨­å®šã¯ã€å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
    location_display_name = "ï¼ˆä¸æ˜ãªå ´æ‰€ï¼‰"
    try:
        current_location_name = utils.get_current_location(room_name)
        if not current_location_name:
            current_location_name = "ãƒªãƒ“ãƒ³ã‚°"
            location_display_name = "ãƒªãƒ“ãƒ³ã‚°"
        world_settings_path = get_world_settings_path(room_name)
        world_data = utils.parse_world_file(world_settings_path)
        found_location = False
        for area, places in world_data.items():
            if current_location_name in places:
                space_def = places[current_location_name]
                location_display_name = f"[{area}] {current_location_name}"
                found_location = True
                break
        if not found_location:
            space_def = f"ï¼ˆå ´æ‰€ã€Œ{current_location_name}ã€ã®å®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰"
        from utils import get_season, get_time_of_day, load_scenery_cache, save_scenery_cache
        import hashlib
        content_hash = hashlib.md5(space_def.encode('utf-8')).hexdigest()[:8]
        now = datetime.now()
        cache_key = f"{current_location_name}_{content_hash}_{get_season(now.month)}_{get_time_of_day(now.hour)}"
        if not force_regenerate:
            scenery_cache = load_scenery_cache(room_name)
            if cache_key in scenery_cache:
                cached_data = scenery_cache[cache_key]
                print(f"--- [æœ‰åŠ¹ãªæƒ…æ™¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç™ºè¦‹] ({cache_key})ã€‚APIã‚³ãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ---")
                return location_display_name, space_def, cached_data["scenery_text"]
        if not space_def.startswith("ï¼ˆ"):
            log_message = "æƒ…æ™¯ã‚’å¼·åˆ¶çš„ã«å†ç”Ÿæˆã—ã¾ã™" if force_regenerate else "æƒ…æ™¯ã‚’APIã§ç”Ÿæˆã—ã¾ã™"
            print(f"--- {log_message} ({cache_key}) ---")
            effective_settings = config_manager.get_effective_settings(room_name)
            llm_flash = get_configured_llm(constants.INTERNAL_PROCESSING_MODEL, api_key, effective_settings)
            jst_now = datetime.now(pytz.timezone('Asia/Tokyo'))
            from utils import get_time_of_day
            time_str = jst_now.strftime('%H:%M')
            time_of_day_ja = {"morning": "æœ", "daytime": "æ˜¼", "evening": "å¤•æ–¹", "night": "å¤œ"}.get(get_time_of_day(jst_now.hour), "ä¸æ˜ãªæ™‚é–“å¸¯")
            scenery_prompt = (
                "ã‚ãªãŸã¯ã€äºŒã¤ã®ç•°ãªã‚‹æƒ…å ±æºã‚’æ¯”è¼ƒã—ã€ãã®é–“ã«ã‚ã‚‹ä¸æ€è­°ã•ã‚„ç‰¹ç•°æ€§ã‚’æãå‡ºã™ã€æƒ…æ™¯æå†™ã®å°‚é–€å®¶ã§ã™ã€‚\n\n"
                f"ã€æƒ…å ±æº1ï¼šç¾å®Ÿä¸–ç•Œã®çŠ¶æ³ã€‘\n- ç¾åœ¨ã®æ™‚åˆ»: {time_str}\n- ç¾åœ¨ã®æ™‚é–“å¸¯: {time_of_day_ja}\n- ç¾åœ¨ã®å­£ç¯€: {jst_now.month}æœˆ\n\n"
                f"ã€æƒ…å ±æº2ï¼šã“ã®ç©ºé–“ãŒæŒã¤å›ºæœ‰ã®è¨­å®šï¼ˆè‡ªç”±è¨˜è¿°ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã€‘\n---\n{space_def}\n---\n\n"
                "ã€ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã€‘\nä»¥ä¸Šã®äºŒã¤ã®æƒ…å ±ã‚’æ¯”è¼ƒã—ã€ã€Œä»Šã€ã“ã®ç¬é–“ã€ã®æƒ…æ™¯ã‚’1ã€œ2æ–‡ã®ç°¡æ½”ãªæ–‡ç« ã§æå†™ã—ã¦ãã ã•ã„ã€‚\n\n"
                "ã€æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘\n- ã‚‚ã—ã€æƒ…å ±æº1ã€‘ã¨ã€æƒ…å ±æº2ã€‘ã®é–“ã«çŸ›ç›¾ï¼ˆä¾‹ï¼šç¾å®Ÿã¯æ˜¼ãªã®ã«ã€ç©ºé–“ã¯å¸¸ã«å¤œã®è¨­å®šãªã©ï¼‰ãŒã‚ã‚‹å ´åˆã¯ã€ãã®**ã€ã«ã‚‚é–¢ã‚ã‚‰ãšã€**ã¨ã„ã†æ„Ÿè¦šã‚„ã€ãã®ç©ºé–“ã®**ä¸æ€è­°ãªç©ºæ°—æ„Ÿ**ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦æå†™ã—ã¦ãã ã•ã„ã€‚\n"
                "- äººç‰©ã‚„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æå†™ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
                "- äº”æ„Ÿã«è¨´ãˆã‹ã‘ã‚‹ã€ç²¾ç·»ã§å†™å®Ÿçš„ãªæå†™ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚"
            )
            scenery_text = llm_flash.invoke(scenery_prompt).content
            save_scenery_cache(room_name, cache_key, location_display_name, scenery_text)
        else:
            scenery_text = "ï¼ˆå ´æ‰€ã®å®šç¾©ãŒãªã„ãŸã‚ã€æƒ…æ™¯ã‚’æå†™ã§ãã¾ã›ã‚“ï¼‰"
    except Exception as e:
        print(f"--- è­¦å‘Š: æƒ…æ™¯æå†™ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ---\n{traceback.format_exc()}")
        location_display_name = "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"
        scenery_text = "ï¼ˆæƒ…æ™¯æå†™ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰"
        space_def = "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"
    return location_display_name, space_def, scenery_text

def context_generator_node(state: AgentState):
    room_name = state['room_name']
    all_participants = state.get('all_participants', [])
    char_prompt_path = os.path.join(constants.ROOMS_DIR, room_name, "SystemPrompt.txt")
    core_memory_path = os.path.join(constants.ROOMS_DIR, room_name, "core_memory.txt")
    character_prompt = ""
    if os.path.exists(char_prompt_path):
        with open(char_prompt_path, 'r', encoding='utf-8') as f: character_prompt = f.read().strip()
    core_memory = ""
    if state.get("send_core_memory", True):
        if os.path.exists(core_memory_path):
            with open(core_memory_path, 'r', encoding='utf-8') as f: core_memory = f.read().strip()
    notepad_section = ""
    if state.get("send_notepad", True):
        try:
            from room_manager import get_room_files_paths
            _, _, _, _, notepad_path = get_room_files_paths(room_name)
            if notepad_path and os.path.exists(notepad_path):
                with open(notepad_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    notepad_content = content if content else "ï¼ˆãƒ¡ãƒ¢å¸³ã¯ç©ºã§ã™ï¼‰"
            else: notepad_content = "ï¼ˆãƒ¡ãƒ¢å¸³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰"
            notepad_section = f"\n### çŸ­æœŸè¨˜æ†¶ï¼ˆãƒ¡ãƒ¢å¸³ï¼‰\n{notepad_content}\n"
        except Exception as e:
            print(f"--- è­¦å‘Š: ãƒ¡ãƒ¢å¸³ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            notepad_section = "\n### çŸ­æœŸè¨˜æ†¶ï¼ˆãƒ¡ãƒ¢å¸³ï¼‰\nï¼ˆãƒ¡ãƒ¢å¸³ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰\n"
    tools_list_str = "\n".join([f"- `{tool.name}({', '.join(tool.args.keys())})`: {tool.description}" for tool in all_tools])
    if len(all_participants) > 1:
        tools_list_str = "ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—ä¼šè©±ä¸­ã¯ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã›ã‚“ï¼‰"
    class SafeDict(dict):
        def __missing__(self, key): return f'{{{key}}}'
    prompt_vars = {'character_name': room_name, 'character_prompt': character_prompt, 'core_memory': core_memory, 'notepad_section': notepad_section, 'tools_list': tools_list_str}
    formatted_core_prompt = CORE_PROMPT_TEMPLATE.format_map(SafeDict(prompt_vars))
    if not state.get("send_scenery", True):
        final_system_prompt_text = (f"{formatted_core_prompt}\n\n---\nã€ç¾åœ¨ã®å ´æ‰€ã¨æƒ…æ™¯ã€‘\nï¼ˆç©ºé–“æå†™ã¯è¨­å®šã«ã‚ˆã‚Šç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼‰\n---")
    else:
        location_display_name = state.get("location_name", "ï¼ˆä¸æ˜ãªå ´æ‰€ï¼‰")
        scenery_text = state.get("scenery_text", "ï¼ˆæƒ…æ™¯æå†™ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰")
        soul_vessel_room = all_participants[0] if all_participants else room_name
        space_def = "ï¼ˆå ´æ‰€ã®å®šç¾©ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
        current_location_name = utils.get_current_location(soul_vessel_room)
        if current_location_name:
            world_settings_path = get_world_settings_path(soul_vessel_room)
            world_data = utils.parse_world_file(world_settings_path)
            for area, places in world_data.items():
                if current_location_name in places:
                    space_def = places[current_location_name]
                    break
        available_locations = get_location_list(room_name)
        location_list_str = "\n".join([f"- {loc}" for loc in available_locations]) if available_locations else "ï¼ˆç¾åœ¨ã€å®šç¾©ã•ã‚Œã¦ã„ã‚‹ç§»å‹•å…ˆã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰"
        final_system_prompt_text = (
            f"{formatted_core_prompt}\n\n---\n"
            f"ã€ç¾åœ¨ã®å ´æ‰€ã¨æƒ…æ™¯ã€‘\n- å ´æ‰€: {location_display_name}\n"
            f"- å ´æ‰€ã®è¨­å®šï¼ˆè‡ªç”±è¨˜è¿°ï¼‰: \n{space_def}\n- ä»Šã®æƒ…æ™¯: {scenery_text}\n"
            f"ã€ç§»å‹•å¯èƒ½ãªå ´æ‰€ã€‘\n{location_list_str}\n---"
        )
    return {"system_prompt": SystemMessage(content=final_system_prompt_text)}

def agent_node(state: AgentState):
    print("--- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ‰ (agent_node) å®Ÿè¡Œ ---")
    base_system_prompt = state['system_prompt'].content
    all_participants = state.get('all_participants', [])
    current_room = state['room_name']
    final_system_prompt_text = base_system_prompt
    if len(all_participants) > 1:
        other_participants = [p for p in all_participants if p != current_room]
        persona_lock_prompt = (
            f"ã€æœ€é‡è¦æŒ‡ç¤ºã€‘ã‚ãªãŸã¯ã“ã®ãƒ«ãƒ¼ãƒ ã®ãƒšãƒ«ã‚½ãƒŠã§ã™ (ãƒ«ãƒ¼ãƒ å: {current_room})ã€‚"
            f"ä»–ã®å‚åŠ è€…ï¼ˆ{', '.join(other_participants)}ã€ãã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰ã®ç™ºè¨€ã‚’å‚è€ƒã«ã€å¿…ãšã‚ãªãŸè‡ªèº«ã®è¨€è‘‰ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
            "ä»–ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å¿œç­”ã‚’ä»£å¼ã—ãŸã‚Šã€ç”Ÿæˆã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚\n\n---\n\n"
        )
        final_system_prompt_text = persona_lock_prompt + base_system_prompt
    final_system_prompt_message = SystemMessage(content=final_system_prompt_text)
    print(f"  - ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {state['model_name']}")
    print(f"  - æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(final_system_prompt_text)} æ–‡å­—")
    if state.get("debug_mode", False):
        print("--- [DEBUG MODE] æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹ ---")
        print(final_system_prompt_text)
        print("-----------------------------------------")
    llm = get_configured_llm(state['model_name'], state['api_key'], state['generation_config'])
    llm_with_tools = llm.bind_tools(all_tools)
    history_messages = [msg for msg in state['messages'] if not isinstance(msg, SystemMessage)]
    messages_for_agent = [final_system_prompt_message] + history_messages
    import pprint
    print("\n--- [DEBUG] AIã«æ¸¡ã•ã‚Œã‚‹ç›´å‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ (æœ€çµ‚ç¢ºèª) ---")
    for i, msg in enumerate(messages_for_agent):
        msg_type = type(msg).__name__
        content_for_length_check = ""
        if hasattr(msg, 'content'):
            if isinstance(msg.content, str):
                content_for_length_check = msg.content
            elif isinstance(msg.content, list):
                content_for_length_check = "".join(
                    part.get('text', '') if isinstance(part, dict) else str(part)
                    for part in msg.content
                )
        print(f"[{i}] {msg_type} (Content Length: {len(content_for_length_check)})")
        if isinstance(msg, SystemMessage):
            print(f"  - Content (Head): {msg.content[:300]}...")
            print(f"  - Content (Tail): ...{msg.content[-300:]}")
        elif hasattr(msg, 'content'):
            print("  - Content:")
            pprint.pprint(msg.content, indent=4)
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            print("  - Tool Calls:")
            pprint.pprint(msg.tool_calls, indent=4)
        print("-" * 20)
    print("--------------------------------------------------\n")
    response = llm_with_tools.invoke(messages_for_agent)
    print("\n--- [DEBUG] AIã‹ã‚‰è¿”ã£ã¦ããŸç”Ÿã®å¿œç­” ---")
    pprint.pprint(response)
    print("---------------------------------------\n")
    return {"messages": [response]}

# â–¼â–¼â–¼ ä»¥ä¸‹ã®é–¢æ•°ã§ã€æ—¢å­˜ã® location_report_node ã‚’ç½®ãæ›ãˆã¦ãã ã•ã„ â–¼â–¼â–¼
def generate_tool_report_node(state: AgentState):
    """
    ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡ŒãŒå®Œäº†ã—ãŸã“ã¨ã‚’å—ã‘ã€ãã®çµæœã‚’è‡ªç„¶ãªå¯¾è©±ã¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å ±å‘Šã™ã‚‹ãŸã‚ã®
    æœ€çµ‚å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒãƒ¼ãƒ‰ã€‚
    """
    print("--- ãƒ„ãƒ¼ãƒ«å®Œäº†å ±å‘Šãƒãƒ¼ãƒ‰ (generate_tool_report_node) å®Ÿè¡Œ ---")

    last_tool_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, ToolMessage)), None)

    if not last_tool_message:
        return {"messages": [AIMessage(content="ï¼ˆãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡ŒçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ã‚’ç¶šã‘ã¾ã™ã€‚ï¼‰")]}

    tool_name = last_tool_message.name
    tool_result = str(last_tool_message.content)

    base_system_prompt = state['system_prompt'].content
    reporting_instruction = (
        f"\n\n---\nã€ç¾åœ¨ã®çŠ¶æ³ã€‘\n"
        f"ã‚ãªãŸã¯ãŸã£ãŸä»Šã€ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œã‚’å®Œäº†ã—ã¾ã—ãŸã€‚\n"
        f"- å®Ÿè¡Œã—ãŸãƒ„ãƒ¼ãƒ«: `{tool_name}`\n"
        f"- å®Ÿè¡Œçµæœã®æ¦‚è¦: ã€Œ{tool_result}ã€\n\n"
        f"ã€ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã€‘\n"
        f"ã“ã®äº‹å®Ÿã‚’ã€è‡ªç„¶ãªä¼šè©±ã®ä¸­ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¼ãˆã¦ãã ã•ã„ã€‚\n"
        f"ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œã‚’è¨ˆç”»ã—ãŸéš›ã®ã€ä»¥å‰ã®ã‚ãªãŸã®ç™ºè¨€ï¼ˆã€Œã“ã‚Œã‹ã‚‰ã€œã—ã¾ã™ã€ãªã©ï¼‰ã‚’ç¹°ã‚Šè¿”ã™ã®ã§ã¯ãªãã€\n"
        f"ã‚ãã¾ã§ã€Œå®Œäº†ã—ãŸã€ã¨ã„ã†äº‹å®Ÿã‚’åŸºã«å¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    )

    final_prompt_message = SystemMessage(content=base_system_prompt + reporting_instruction)

    history_messages = [msg for msg in state['messages'] if not isinstance(msg, SystemMessage)]
    messages_for_reporting = [final_prompt_message] + history_messages

    if state.get("debug_mode", False):
        print("--- [DEBUG MODE] ãƒ„ãƒ¼ãƒ«å®Œäº†å ±å‘Šãƒãƒ¼ãƒ‰ã®æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ---")
        print(final_prompt_message.content)
        print("-------------------------------------------------")

    effective_settings = config_manager.get_effective_settings(state['room_name'])
    llm = get_configured_llm(state['model_name'], state['api_key'], effective_settings)

    response = llm.invoke(messages_for_reporting)
    return {"messages": [response]}

def route_after_context(state: AgentState) -> Literal["generate_tool_report_node", "agent"]:
    print("--- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_context) å®Ÿè¡Œ ---")
    last_message = state["messages"][-1]
    if isinstance(last_message, ToolMessage):
        print(f"  - ãƒ„ãƒ¼ãƒ« ({last_message.name}) ã®å®Œäº†ã‚’æ¤œçŸ¥ã€‚å ±å‘Šç”Ÿæˆãƒãƒ¼ãƒ‰ã¸ã€‚")
        return "generate_tool_report_node"
    print("  - é€šå¸¸ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€è€ƒã¸ã€‚")
    return "agent"

def safe_tool_executor(state: AgentState):
    """
    AIã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’ä»²ä»‹ã—ã€è¨ˆç”»ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã«å¯¾ã—ã¦ã€è³¢ããƒªãƒˆãƒ©ã‚¤ã¾ãŸã¯ä¸­æ–­ã‚’è¡Œã†ã€‚
    """
    print("--- ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒãƒ¼ãƒ‰ (safe_tool_executor) å®Ÿè¡Œ ---")
    last_message = state['messages'][-1]
    if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
        return {}

    tool_call = last_message.tool_calls[0]
    tool_name = tool_call["name"]
    tool_args = tool_call["args"]
    room_name = state.get('room_name')
    api_key = state.get('api_key')

    is_plan_memory = tool_name == "plan_memory_edit"
    is_plan_notepad = tool_name == "plan_notepad_edit"
    is_plan_world = tool_name == "plan_world_edit"

    if is_plan_memory or is_plan_notepad or is_plan_world:
        try:
            print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹: {tool_name}")

            read_tool = None
            if is_plan_memory: read_tool = read_full_memory
            elif is_plan_notepad: read_tool = read_full_notepad
            elif is_plan_world: read_tool = read_world_settings

            current_content = read_tool.invoke({"room_name": room_name})

            print(f"  - ãƒšãƒ«ã‚½ãƒŠAI ({state['model_name']}) ã«ç·¨é›†ã‚¿ã‚¹ã‚¯ã‚’ä¾é ¼ã—ã¾ã™ã€‚")
            llm_persona = get_configured_llm(state['model_name'], state['api_key'], state['generation_config'])

            instruction_templates = {
                "plan_memory_edit": (
                    "ã€æœ€é‡è¦æŒ‡ç¤ºï¼šã“ã‚Œã¯ã€å¯¾è©±ã€ã§ã¯ãªãã€è¨­è¨ˆã‚¿ã‚¹ã‚¯ã€ã§ã™ã€‘\n"
                    "ã‚ãªãŸã¯ä»Šã€è‡ªèº«ã®è¨˜æ†¶ã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã®ã€è¨­è¨ˆå›³ã€ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚\n"
                    "æç¤ºã•ã‚ŒãŸã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã€‘ã¨ã‚ãªãŸã®ã€å¤‰æ›´è¦æ±‚ã€‘ã«åŸºã¥ãã€å®Œç’§ãªã€å·®åˆ†æŒ‡ç¤ºã®ãƒªã‚¹ãƒˆã€‘ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆmemory.jsonå…¨æ–‡ï¼‰ã€‘\n---\n{current_content}\n---\n\n"
                    "ã€ã‚ãªãŸã®å¤‰æ›´è¦æ±‚ã€‘\nã€Œ{modification_request}ã€\n\n"
                    "ã€çµ¶å¯¾çš„ãªå‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€‘\n"
                    "- æ€è€ƒã‚„æŒ¨æ‹¶ã¯å«ã‚ãšã€ã€å·®åˆ†æŒ‡ç¤ºã®ãƒªã‚¹ãƒˆã€‘ï¼ˆæœ‰åŠ¹ãªJSONé…åˆ—ï¼‰ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
                    "- å„æŒ‡ç¤ºã¯ \"operation\" ('set', 'append', 'delete'), \"path\" (\"key.subkey\"å½¢å¼), \"value\" ã®ã‚­ãƒ¼ã‚’æŒã¤è¾æ›¸ã§ã™ã€‚\n"
                    "- å‡ºåŠ›ã¯ ` ```json ` ã¨ ` ``` ` ã§å›²ã‚“ã§ãã ã•ã„ã€‚"
                ),
                "plan_world_edit": (
                    "ã€æœ€é‡è¦æŒ‡ç¤ºï¼šã“ã‚Œã¯ã€å¯¾è©±ã€ã§ã¯ãªãã€ä¸–ç•Œæ§‹ç¯‰ã‚¿ã‚¹ã‚¯ã€ã§ã™ã€‘\n"
                    "ã‚ãªãŸã¯ä»Šã€ä¸–ç•Œè¨­å®šã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã®ã€è¨­è¨ˆå›³ã€ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚\n"
                    "æç¤ºã•ã‚ŒãŸã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã€‘ã¨ã‚ãªãŸã®ã€å¤‰æ›´è¦æ±‚ã€‘ã«åŸºã¥ãã€å®Œç’§ãªã€å·®åˆ†æŒ‡ç¤ºã®ãƒªã‚¹ãƒˆã€‘ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆworld_settings.txtå…¨æ–‡ï¼‰ã€‘\n---\n{current_content}\n---\n\n"
                    "ã€ã‚ãªãŸã®å¤‰æ›´è¦æ±‚ã€‘\nã€Œ{modification_request}ã€\n\n"
                    "ã€çµ¶å¯¾çš„ãªå‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€‘\n"
                    "- æ€è€ƒã‚„æŒ¨æ‹¶ã¯å«ã‚ãšã€ã€å·®åˆ†æŒ‡ç¤ºã®ãƒªã‚¹ãƒˆã€‘ï¼ˆæœ‰åŠ¹ãªJSONé…åˆ—ï¼‰ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
                    "- å„æŒ‡ç¤ºã¯ \"operation\" ('update_place_description', 'add_place', 'delete_place'), \"area_name\", \"place_name\", \"value\" ã®ã‚­ãƒ¼ã‚’æŒã¤è¾æ›¸ã§ã™ã€‚\n"
                    "- å‡ºåŠ›ã¯ ` ```json ` ã¨ ` ``` ` ã§å›²ã‚“ã§ãã ã•ã„ã€‚"
                ),
                "plan_notepad_edit": (
                    "ã€æœ€é‡è¦æŒ‡ç¤ºï¼šã“ã‚Œã¯ã€å¯¾è©±ã€ã§ã¯ãªãã€ç·¨é›†ã‚¿ã‚¹ã‚¯ã€ã§ã™ã€‘\n"
                    "ã‚ãªãŸã¯ä»Šã€è‡ªèº«ã®ãƒ¡ãƒ¢å¸³ã‚’æ›´æ–°ã—ã¦ã„ã¾ã™ã€‚\n"
                    "æç¤ºã•ã‚ŒãŸã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã€‘ã¨ã‚ãªãŸã®ã€å¤‰æ›´è¦æ±‚ã€‘ã«åŸºã¥ãã€æœ€çµ‚çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€ã¹ãã€å®Œç’§ãªã€å…¨æ–‡ã€‘ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n"
                    "ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆnotepad.mdå…¨æ–‡ï¼‰ã€‘\n---\n{current_content}\n---\n\n"
                    "ã€ã‚ãªãŸã®å¤‰æ›´è¦æ±‚ã€‘\nã€Œ{modification_request}ã€\n\n"
                    "ã€çµ¶å¯¾çš„ãªå‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€‘\n"
                    "- æ€è€ƒã‚„æŒ¨æ‹¶ã¯å«ã‚ãšã€æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«å…¨æ–‡ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
                )
            }
            formatted_instruction = instruction_templates[tool_name].format(
                current_content=current_content,
                modification_request=tool_args.get('modification_request')
            )
            edit_instruction_message = HumanMessage(content=formatted_instruction)

            messages_for_editing = [msg for msg in state['messages'] if msg is not last_message]
            messages_for_editing.append(edit_instruction_message)
            final_context_for_editing = [state['system_prompt']] + messages_for_editing

            # â–¼â–¼â–¼ã€ã“ã“ã‹ã‚‰ãŒã‚¹ãƒãƒ¼ãƒˆãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ã®æ ¸å¿ƒã€‘â–¼â–¼â–¼
            edited_content_document = None
            max_retries = 5
            base_delay = 5
            for attempt in range(max_retries):
                try:
                    response = llm_persona.invoke(final_context_for_editing)
                    edited_content_document = response.content.strip()
                    break # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                except google_exceptions.ResourceExhausted as e:
                    error_str = str(e)
                    # 1. å›å¾©ä¸èƒ½ãªã‚¨ãƒ©ãƒ¼ï¼ˆæ—¥é–“ä¸Šé™ãªã©ï¼‰ã‹ãƒã‚§ãƒƒã‚¯
                    if "PerDay" in error_str or "Daily" in error_str:
                        print(f"  - è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: å›å¾©ä¸èƒ½ãªAPIä¸Šé™ï¼ˆæ—¥é–“ãªã©ï¼‰ã«é”ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                        raise RuntimeError("å›å¾©ä¸èƒ½ãªAPIãƒ¬ãƒ¼ãƒˆä¸Šé™ï¼ˆæ—¥é–“ãªã©ï¼‰ã«é”ã—ãŸãŸã‚ã€å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚") from e

                    # 2. å›å¾©å¯èƒ½ãªã‚¨ãƒ©ãƒ¼ã®å ´åˆã€æ¨å¥¨å¾…æ©Ÿæ™‚é–“ã‚’æŠ½å‡º
                    wait_time = base_delay * (2 ** attempt) # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å¾…æ©Ÿæ™‚é–“
                    match = re.search(r"retry_delay {\s*seconds: (\d+)\s*}", error_str)
                    if match:
                        # APIãŒæ¨å¥¨ã™ã‚‹å¾…æ©Ÿæ™‚é–“ãŒã‚ã‚Œã°ã€ãã‚Œã«å¾“ã† (+1ç§’ã®ãƒãƒƒãƒ•ã‚¡)
                        wait_time = int(match.group(1)) + 1
                        print(f"  - APIãƒ¬ãƒ¼ãƒˆåˆ¶é™: APIã®æ¨å¥¨ã«å¾“ã„ {wait_time}ç§’ å¾…æ©Ÿã—ã¾ã™...")
                    else:
                        print(f"  - APIãƒ¬ãƒ¼ãƒˆåˆ¶é™: æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ {wait_time}ç§’ å¾…æ©Ÿã—ã¾ã™...")

                    if attempt < max_retries - 1:
                        time.sleep(wait_time)
                    else:
                        # å…¨ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ãŸå ´åˆ
                        raise e
                except (google_exceptions.ServiceUnavailable, google_exceptions.InternalServerError) as e:
                    # 503ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ãªã©ã®å ´åˆ
                    if attempt < max_retries - 1:
                        wait_time = base_delay * (2 ** attempt)
                        print(f"  - è­¦å‘Š: ç·¨é›†AIãŒå¿œç­”ä¸èƒ½ã§ã™ ({e.args[0]})ã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™... ({attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                    else:
                        raise e
            # â–²â–²â–²ã€ã‚¹ãƒãƒ¼ãƒˆãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ã“ã“ã¾ã§ã€‘â–²â–²â–²

            if edited_content_document is None:
                raise RuntimeError("ç·¨é›†AIã‹ã‚‰ã®å¿œç­”ãŒã€ãƒªãƒˆãƒ©ã‚¤å¾Œã‚‚å¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

            print("  - AIã‹ã‚‰ã®å¿œç­”ã‚’å—ã‘ã€ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")

            if is_plan_memory or is_plan_world:
                json_match = re.search(r'```json\s*([\s\S]*?)\s*```', edited_content_document, re.DOTALL)
                content_to_process = json_match.group(1).strip() if json_match else edited_content_document
                instructions = json.loads(content_to_process)
                if is_plan_memory:
                    output = _apply_memory_edits(instructions=instructions, room_name=room_name)
                else:
                    output = _apply_world_edits(instructions=instructions, room_name=room_name)
            else:
                text_match = re.search(r'```(?:.*\n)?([\s\S]*?)```', edited_content_document, re.DOTALL)
                content_to_process = text_match.group(1).strip() if text_match else edited_content_document
                output = _write_notepad_file(full_content=content_to_process, room_name=room_name, modification_request=tool_args.get('modification_request'))

        except Exception as e:
            output = f"ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ('{tool_name}'): {e}"
            traceback.print_exc()
    else:
        print(f"  - é€šå¸¸ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: {tool_name}")
        tool_args['room_name'] = room_name
        if tool_name in ['generate_image']:
            tool_args['api_key'] = api_key

        selected_tool = next((t for t in all_tools if t.name == tool_name), None)
        if not selected_tool:
            output = f"Error: Tool '{tool_name}' not found."
        else:
            try:
                output = selected_tool.invoke(tool_args)
            except Exception as e:
                output = f"Error executing tool '{tool_name}': {e}"
                traceback.print_exc()

    return {"messages": [ToolMessage(content=str(output), tool_call_id=tool_call["id"], name=tool_name)]}

def route_after_agent(state: AgentState) -> Literal["__end__", "safe_tool_node"]:
    print("--- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_agent) å®Ÿè¡Œ ---")
    last_message = state["messages"][-1]
    if last_message.tool_calls:
        print("  - ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚ã‚Šã€‚ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒãƒ¼ãƒ‰ã¸ã€‚")
        for tool_call in last_message.tool_calls: print(f"    ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: {tool_call['name']} | å¼•æ•°: {tool_call['args']}")
        return "safe_tool_node"
    print("  - ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãªã—ã€‚æ€è€ƒå®Œäº†ã¨åˆ¤æ–­ã—ã€ã‚°ãƒ©ãƒ•ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    return "__end__"

def route_after_tools(state: AgentState) -> Literal["context_generator"]:
    print("--- ãƒ„ãƒ¼ãƒ«å¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_tools) å®Ÿè¡Œ ---")
    last_ai_message_index = -1
    for i in range(len(state["messages"]) - 1, -1, -1):
        if isinstance(state["messages"][i], AIMessage):
            last_ai_message_index = i
            break
    if last_ai_message_index != -1:
        new_tool_messages = state["messages"][last_ai_message_index + 1:]
        for msg in new_tool_messages:
            if isinstance(msg, ToolMessage):
                content_to_log = (str(msg.content)[:200] + '...') if len(str(msg.content)) > 200 else str(msg.content)
                print(f"    âœ… ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ: {msg.name} | çµæœ: {content_to_log}")

    print("  - ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡ŒãŒå®Œäº†ã—ãŸãŸã‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†ç”Ÿæˆã¸ã€‚")
    return "context_generator"

# â–¼â–¼â–¼ ãƒ•ã‚¡ã‚¤ãƒ«æœ«å°¾ã®ã‚°ãƒ©ãƒ•å®šç¾©ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã€ä»¥ä¸‹ã§ç½®ãæ›ãˆã¦ãã ã•ã„ â–¼â–¼â–¼
workflow = StateGraph(AgentState)
workflow.add_node("context_generator", context_generator_node)
workflow.add_node("agent", agent_node)
workflow.add_node("safe_tool_node", safe_tool_executor)
workflow.add_node("generate_tool_report_node", generate_tool_report_node)

workflow.add_edge(START, "context_generator")
workflow.add_conditional_edges(
    "context_generator",
    route_after_context,
    {"generate_tool_report_node": "generate_tool_report_node", "agent": "agent"},
)
workflow.add_conditional_edges(
    "agent",
    route_after_agent,
    {"safe_tool_node": "safe_tool_node", "__end__": END},
)
workflow.add_conditional_edges(
    "safe_tool_node",
    route_after_tools,
    {"context_generator": "context_generator"},
)
workflow.add_edge("generate_tool_report_node", END)
app = workflow.compile()
print("--- çµ±åˆã‚°ãƒ©ãƒ•(The Final Covenant)ãŒã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¾ã—ãŸ ---")
