# agent/graph.py

# 1. ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã«å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿½åŠ 
import os
import re
import traceback
import json
import pytz # â˜… è¿½åŠ 
from datetime import datetime # â˜… è¿½åŠ 
from typing import TypedDict, Annotated, List, Literal, Optional, Tuple # â˜… Optionalã¨Tupleã‚’è¿½åŠ 

# 2. æ—¢å­˜ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ä¸‹ã«ã€æ–°ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ 
from langchain_core.messages import SystemMessage, BaseMessage, ToolMessage, AIMessage
from langchain_google_genai import HarmCategory, HarmBlockThreshold
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END, START, add_messages
from langgraph.prebuilt import ToolNode

# --- å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚„ãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from agent.prompts import CORE_PROMPT_TEMPLATE
from tools.space_tools import (
    set_current_location, update_location_content, add_new_location, read_world_settings
)
from tools.memory_tools import read_memory_by_path, edit_memory, add_secret_diary_entry, summarize_and_save_core_memory, read_full_memory
from tools.notepad_tools import add_to_notepad, update_notepad, delete_from_notepad, read_full_notepad
from tools.web_tools import web_search_tool, read_url_tool
from tools.image_tools import generate_image
from tools.alarm_tools import set_personal_alarm
# â–¼â–¼â–¼ æ–°ã—ã„ã‚¿ã‚¤ãƒãƒ¼ãƒ„ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â–¼â–¼â–¼
from tools.timer_tools import set_timer, set_pomodoro_timer
from rag_manager import diary_search_tool, conversation_memory_search_tool
from character_manager import get_world_settings_path
from memory_manager import load_memory_data_safe
import utils # â˜… utilsã‚’ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import config_manager

all_tools = [
    set_current_location, read_memory_by_path, edit_memory,
    add_secret_diary_entry, summarize_and_save_core_memory, add_to_notepad,
    update_notepad, delete_from_notepad, read_full_notepad, web_search_tool,
    read_url_tool, diary_search_tool, conversation_memory_search_tool,
    generate_image, read_full_memory, set_personal_alarm,
    update_location_content, add_new_location,
    set_timer, set_pomodoro_timer,
    read_world_settings
]

class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    character_name: str
    api_key: str
    tavily_api_key: str
    model_name: str
    system_prompt: SystemMessage
    send_core_memory: bool
    send_scenery: bool
    send_notepad: bool
    location_name: str
    scenery_text: str
    debug_mode: bool
    all_participants: List[str] # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å‚åŠ ã—ã¦ã„ã‚‹å…¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãƒªã‚¹ãƒˆ

def get_configured_llm(model_name: str, api_key: str, generation_config: dict):
    """
    ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã”ã¨ã®è¨­å®šã‚’å«ã‚€ã€LangChainç”¨ã®LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    threshold_map = {
        "BLOCK_NONE": HarmBlockThreshold.BLOCK_NONE,
        "BLOCK_LOW_AND_ABOVE": HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        "BLOCK_MEDIUM_AND_ABOVE": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        "BLOCK_ONLY_HIGH": HarmBlockThreshold.BLOCK_ONLY_HIGH,
    }

    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: threshold_map.get(generation_config.get("safety_block_threshold_harassment")),
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: threshold_map.get(generation_config.get("safety_block_threshold_hate_speech")),
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: threshold_map.get(generation_config.get("safety_block_threshold_sexually_explicit")),
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: threshold_map.get(generation_config.get("safety_block_threshold_dangerous_content")),
    }

    return ChatGoogleGenerativeAI(
        model=model_name,
        google_api_key=api_key,
        convert_system_message_to_human=False,
        max_retries=6,
        temperature=generation_config.get("temperature", 0.8),
        top_p=generation_config.get("top_p", 0.95),
        safety_settings=safety_settings
    )

# 3. ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒ©ã‚¹ã‚„é–¢æ•°å®šç¾©ã®å‰ã«ã€æ–°ã—ã„ã€Œæƒ…æ™¯ç”Ÿæˆã€é–¢æ•°ã‚’è¿½åŠ 
def get_location_list(character_name: str) -> List[str]:
    """
    åˆ©ç”¨å¯èƒ½ãªã™ã¹ã¦ã®å ´æ‰€ã®ãƒªã‚¹ãƒˆã‚’ã€Œ[ã‚¨ãƒªã‚¢å] å ´æ‰€åã€ã®å½¢å¼ã§ç”Ÿæˆã™ã‚‹ã€‚
    """
    if not character_name: return []
    world_settings_path = get_world_settings_path(character_name)
    if not world_settings_path or not os.path.exists(world_settings_path): return []

    # æ–°ã—ã„ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½¿ç”¨
    world_data = utils.parse_world_file(world_settings_path)
    if not world_data: return []

    locations = []
    for area_name, places in world_data.items():
        for place_name in places.keys():
            # ç‰¹æ®Šãªã‚­ãƒ¼ã¯é™¤å¤–
            if place_name == "__area_description__": continue
            locations.append(f"[{area_name}] {place_name}")

    return sorted(locations)


def generate_scenery_context(character_name: str, api_key: str, force_regenerate: bool = False) -> Tuple[str, str, str]:
    """
    æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç¾åœ¨ã®å ´æ‰€ã«åŸºã¥ã„ã¦ã€æƒ…æ™¯ã‚’æå†™ã—ã€
    å ´æ‰€ã®åå‰ã€è‡ªç”±è¨˜è¿°ãƒ†ã‚­ã‚¹ãƒˆã€æå†™ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™ã€‚
    force_regenerate=True ã®å ´åˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å¿…ãšå†ç”Ÿæˆã™ã‚‹ã€‚
    """
    scenery_text = "ï¼ˆç¾åœ¨ã®å ´æ‰€ã®æƒ…æ™¯æå†™ã¯ã€å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
    space_def = "ï¼ˆç¾åœ¨ã®å ´æ‰€ã®å®šç¾©ãƒ»è¨­å®šã¯ã€å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
    location_display_name = "ï¼ˆä¸æ˜ãªå ´æ‰€ï¼‰"

    try:
        # 1. ç¾åœ¨ã®å ´æ‰€åã‚’å–å¾—
        current_location_name = utils.get_current_location(character_name)
        if not current_location_name:
            current_location_name = "ãƒªãƒ“ãƒ³ã‚°" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            location_display_name = "ãƒªãƒ“ãƒ³ã‚°"

        # 2. ä¸–ç•Œè¨­å®šã‚’ãƒ‘ãƒ¼ã‚¹
        world_settings_path = get_world_settings_path(character_name)
        world_data = utils.parse_world_file(world_settings_path)

        # 3. å ´æ‰€åã«å¯¾å¿œã™ã‚‹å®šç¾©(è‡ªç”±è¨˜è¿°ãƒ†ã‚­ã‚¹ãƒˆ)ã‚’æ¢ã™
        found_location = False
        for area, places in world_data.items():
            if current_location_name in places:
                space_def = places[current_location_name]
                location_display_name = f"[{area}] {current_location_name}"
                found_location = True
                break

        if not found_location:
            space_def = f"ï¼ˆå ´æ‰€ã€Œ{current_location_name}ã€ã®å®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰"

        # 4. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ­ã‚¸ãƒƒã‚¯
        from utils import get_season, get_time_of_day, load_scenery_cache, save_scenery_cache
        import hashlib
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã¯å ´æ‰€åã¨å†…å®¹ã®ãƒãƒƒã‚·ãƒ¥ã€å­£ç¯€ã€æ™‚é–“å¸¯ã‹ã‚‰ç”Ÿæˆ
        content_hash = hashlib.md5(space_def.encode('utf-8')).hexdigest()[:8]
        now = datetime.now()
        cache_key = f"{current_location_name}_{content_hash}_{get_season(now.month)}_{get_time_of_day(now.hour)}"

        if not force_regenerate:
            scenery_cache = load_scenery_cache(character_name)
            if cache_key in scenery_cache:
                cached_data = scenery_cache[cache_key]
                print(f"--- [æœ‰åŠ¹ãªæƒ…æ™¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç™ºè¦‹] ({cache_key})ã€‚APIã‚³ãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ ---")
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿”ã™å ´åˆã‚‚ã€æœ€æ–°ã®è¡¨ç¤ºåã‚’è¿”ã™
                return location_display_name, space_def, cached_data["scenery_text"]

        # 5. æƒ…æ™¯ç”Ÿæˆ
        if not space_def.startswith("ï¼ˆ"):
            log_message = "æƒ…æ™¯ã‚’å¼·åˆ¶çš„ã«å†ç”Ÿæˆã—ã¾ã™" if force_regenerate else "æƒ…æ™¯ã‚’APIã§ç”Ÿæˆã—ã¾ã™"
            print(f"--- {log_message} ({cache_key}) ---")

            effective_settings = config_manager.get_effective_settings(character_name)
            llm_flash = get_configured_llm("gemini-2.5-flash", api_key, effective_settings)
            jst_now = datetime.now(pytz.timezone('Asia/Tokyo'))
            scenery_prompt = (
                f"ç©ºé–“å®šç¾©ï¼ˆè‡ªç”±è¨˜è¿°ãƒ†ã‚­ã‚¹ãƒˆï¼‰:\n---\n{space_def}\n---\n\n"
                f"æ™‚åˆ»:{jst_now.strftime('%H:%M')} / å­£ç¯€:{jst_now.month}æœˆ\n\n"
                "ä»¥ä¸Šã®æƒ…å ±ã‹ã‚‰ã€ã‚ãªãŸã¯ã“ã®ç©ºé–“ã®ã€Œä»Šã“ã®ç¬é–“ã€ã‚’åˆ‡ã‚Šå–ã‚‹æƒ…æ™¯æå†™ã®å°‚é–€å®¶ã§ã™ã€‚\n"
                "ã€ãƒ«ãƒ¼ãƒ«ã€‘\n- äººç‰©ã‚„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æå†™ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
                "- 1ã€œ2æ–‡ã®ç°¡æ½”ãªæ–‡ç« ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                "- çª“ã®å¤–ã®å­£ç¯€æ„Ÿã‚„æ™‚é–“å¸¯ã€å®¤å†…ã®ç©ºæ°—æ„Ÿã‚„é™°å½±ãªã©ã€äº”æ„Ÿã«è¨´ãˆã‹ã‘ã‚‹ç²¾ç·»ã§å†™å®Ÿçš„ãªæå†™ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚"
            )
            scenery_text = llm_flash.invoke(scenery_prompt).content
            save_scenery_cache(character_name, cache_key, location_display_name, scenery_text)
        else:
            scenery_text = "ï¼ˆå ´æ‰€ã®å®šç¾©ãŒãªã„ãŸã‚ã€æƒ…æ™¯ã‚’æå†™ã§ãã¾ã›ã‚“ï¼‰"

    except Exception as e:
        print(f"--- è­¦å‘Š: æƒ…æ™¯æå†™ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ---\n{traceback.format_exc()}")
        location_display_name = "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"
        scenery_text = "ï¼ˆæƒ…æ™¯æå†™ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰"
        space_def = "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"

    return location_display_name, space_def, scenery_text


def context_generator_node(state: AgentState):
    character_name = state['character_name']
    all_participants = state.get('all_participants', [])

    # --- å…±é€šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéƒ¨å“ã‚’ç”Ÿæˆ ---
    char_prompt_path = os.path.join("characters", character_name, "SystemPrompt.txt")
    core_memory_path = os.path.join("characters", character_name, "core_memory.txt")
    character_prompt = ""
    if os.path.exists(char_prompt_path):
        with open(char_prompt_path, 'r', encoding='utf-8') as f: character_prompt = f.read().strip()

    core_memory = ""
    if state.get("send_core_memory", True):
        if os.path.exists(core_memory_path):
            with open(core_memory_path, 'r', encoding='utf-8') as f: core_memory = f.read().strip()

    notepad_section = ""
    if state.get("send_notepad", True):
        try:
            from character_manager import get_character_files_paths
            _, _, _, _, notepad_path = get_character_files_paths(character_name)
            if notepad_path and os.path.exists(notepad_path):
                with open(notepad_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    notepad_content = content if content else "ï¼ˆãƒ¡ãƒ¢å¸³ã¯ç©ºã§ã™ï¼‰"
            else: notepad_content = "ï¼ˆãƒ¡ãƒ¢å¸³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰"
            notepad_section = f"\n### çŸ­æœŸè¨˜æ†¶ï¼ˆãƒ¡ãƒ¢å¸³ï¼‰\n{notepad_content}\n"
        except Exception as e:
            print(f"--- è­¦å‘Š: ãƒ¡ãƒ¢å¸³ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            notepad_section = "\n### çŸ­æœŸè¨˜æ†¶ï¼ˆãƒ¡ãƒ¢å¸³ï¼‰\nï¼ˆãƒ¡ãƒ¢å¸³ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰\n"

    tools_list_str = "\n".join([f"- `{tool.name}({', '.join(tool.args.keys())})`: {tool.description}" for tool in all_tools])
    # ã‚°ãƒ«ãƒ¼ãƒ—ä¼šè©±ä¸­ã¯ãƒ„ãƒ¼ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç„¡åŠ¹åŒ–
    if len(all_participants) > 1:
        tools_list_str = "ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—ä¼šè©±ä¸­ã¯ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã›ã‚“ï¼‰"

    class SafeDict(dict):
        def __missing__(self, key): return f'{{{key}}}'
    prompt_vars = {'character_name': character_name, 'character_prompt': character_prompt, 'core_memory': core_memory, 'notepad_section': notepad_section, 'tools_list': tools_list_str}
    formatted_core_prompt = CORE_PROMPT_TEMPLATE.format_map(SafeDict(prompt_vars))

    # --- ç©ºé–“æå†™ ---
    if not state.get("send_scenery", True):
        final_system_prompt_text = (f"{formatted_core_prompt}\n\n---\nã€ç¾åœ¨ã®å ´æ‰€ã¨æƒ…æ™¯ã€‘\nï¼ˆç©ºé–“æå†™ã¯è¨­å®šã«ã‚ˆã‚Šç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼‰\n---")
    else:
        # stateã‹ã‚‰å…±æœ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ã¦ä½¿ç”¨ã™ã‚‹
        location_display_name = state.get("location_name", "ï¼ˆä¸æ˜ãªå ´æ‰€ï¼‰")
        scenery_text = state.get("scenery_text", "ï¼ˆæƒ…æ™¯æå†™ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰")

        # å ´æ‰€ã®å®šç¾©ï¼ˆspace_defï¼‰ã¯ã€ãƒ¡ã‚¤ãƒ³AIï¼ˆé­‚ã®å™¨ï¼‰ã®ç¾åœ¨åœ°ã‹ã‚‰å–å¾—ã™ã‚‹
        soul_vessel_character = all_participants[0] if all_participants else character_name
        space_def = "ï¼ˆå ´æ‰€ã®å®šç¾©ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
        current_location_name = utils.get_current_location(soul_vessel_character)
        if current_location_name:
            world_settings_path = get_world_settings_path(soul_vessel_character)
            world_data = utils.parse_world_file(world_settings_path)
            for area, places in world_data.items():
                if current_location_name in places:
                    space_def = places[current_location_name]
                    break

        available_locations = get_location_list(character_name) # ç§»å‹•å…ˆã¯è‡ªåˆ†è‡ªèº«ã®ã‚‚ã®
        location_list_str = "\n".join([f"- {loc}" for loc in available_locations]) if available_locations else "ï¼ˆç¾åœ¨ã€å®šç¾©ã•ã‚Œã¦ã„ã‚‹ç§»å‹•å…ˆã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰"

        final_system_prompt_text = (
            f"{formatted_core_prompt}\n\n---\n"
            f"ã€ç¾åœ¨ã®å ´æ‰€ã¨æƒ…æ™¯ã€‘\n- å ´æ‰€: {location_display_name}\n"
            f"- å ´æ‰€ã®è¨­å®šï¼ˆè‡ªç”±è¨˜è¿°ï¼‰: \n{space_def}\n- ä»Šã®æƒ…æ™¯: {scenery_text}\n"
            f"ã€ç§»å‹•å¯èƒ½ãªå ´æ‰€ã€‘\n{location_list_str}\n---"
        )

    return {"system_prompt": SystemMessage(content=final_system_prompt_text)}

def agent_node(state: AgentState):
    print("--- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ‰ (agent_node) å®Ÿè¡Œ ---")
    base_system_prompt = state['system_prompt'].content
    all_participants = state.get('all_participants', [])
    current_character = state['character_name']

    final_system_prompt_text = base_system_prompt
    if len(all_participants) > 1:
        other_participants = [p for p in all_participants if p != current_character]
        persona_lock_prompt = (
            f"ã€æœ€é‡è¦æŒ‡ç¤ºã€‘ã‚ãªãŸã¯ã€Œ{current_character}ã€ã§ã™ã€‚"
            f"ä»–ã®å‚åŠ è€…ï¼ˆ{', '.join(other_participants)}ã€ãã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰ã®ç™ºè¨€ã‚’å‚è€ƒã«ã€å¿…ãšã‚ãªãŸè‡ªèº«ã®è¨€è‘‰ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
            "ä»–ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å¿œç­”ã‚’ä»£å¼ã—ãŸã‚Šã€ç”Ÿæˆã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚\n\n---\n\n"
        )
        final_system_prompt_text = persona_lock_prompt + base_system_prompt

    final_system_prompt_message = SystemMessage(content=final_system_prompt_text)

    print(f"  - ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {state['model_name']}")
    print(f"  - æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(final_system_prompt_text)} æ–‡å­—")

    if state.get("debug_mode", False):
        print("--- [DEBUG MODE] æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹ ---")
        print(final_system_prompt_text)
        print("-----------------------------------------")

    effective_settings = config_manager.get_effective_settings(state['character_name'])
    llm = get_configured_llm(state['model_name'], state['api_key'], effective_settings)
    llm_with_tools = llm.bind_tools(all_tools)

    # â–¼â–¼â–¼ã€ã“ã“ã‹ã‚‰ãŒä¿®æ­£ã®æ ¸å¿ƒã€‘â–¼â–¼â–¼
    # å±¥æ­´ã‹ã‚‰å¤ã„SystemMessageã‚’é™¤å»ã—ã€å¸¸ã«æœ€æ–°ã®ä¸€ã¤ã ã‘ãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
    history_messages = [msg for msg in state['messages'] if not isinstance(msg, SystemMessage)]
    messages_for_agent = [final_system_prompt_message] + history_messages
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    response = llm_with_tools.invoke(messages_for_agent)
    return {"messages": [response]}


# agent/graph.py (agent_node ã®ç›´å¾Œã«è¿½åŠ )

def location_report_node(state: AgentState):
    """
    ã€æœ€çµ‚ç‰ˆã€‘å ´æ‰€ç§»å‹•ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ€§ã‚’ç¶­æŒã—ãŸã¾ã¾è‡ªå¾‹çš„ã«å ±å‘Šã™ã‚‹ãŸã‚ã®å°‚ç”¨æ€è€ƒãƒãƒ¼ãƒ‰ã€‚
    """
    print("--- å ´æ‰€ç§»å‹•å ±å‘Šãƒãƒ¼ãƒ‰ (location_report_node) å®Ÿè¡Œ ---")

    last_tool_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, ToolMessage) and msg.name == 'set_current_location'), None)
    location_name = "æŒ‡å®šã®å ´æ‰€"
    if last_tool_message:
        match = re.search(r"ç¾åœ¨åœ°ã¯ '(.*?)' ã«è¨­å®šã•ã‚Œã¾ã—ãŸ", str(last_tool_message.content))
        if match:
            location_name = match.group(1)

    base_system_prompt = state['system_prompt'].content
    reporting_instruction = (
        f"\n\n---\nã€æœ€é‡è¦æŒ‡ç¤ºã€‘\nã‚ãªãŸã¯ä»Šã€å ´æ‰€ã®ç§»å‹•ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚"
        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã€ç¾åœ¨åœ°ãŒã€Œ{location_name}ã€ã«å¤‰ã‚ã£ãŸã“ã¨ã‚’ã€ã‚ãªãŸè‡ªèº«ã®è¨€è‘‰ã§ã€è‡ªç„¶ãªä¼šè©±ã¨ã—ã¦å ±å‘Šã—ã¦ãã ã•ã„ã€‚"
        "ã“ã®å ±å‘Šã®è¿”ç­”ãŒã€ã‚ãªãŸã®ã“ã®ã‚¿ãƒ¼ãƒ³ã®æœ€çµ‚çš„ãªå¿œç­”ã¨ãªã‚Šã¾ã™ã€‚ä»–ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚„ææ¡ˆã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚"
    )
    final_prompt_message = SystemMessage(content=base_system_prompt + reporting_instruction)

    history_messages = [msg for msg in state['messages'] if not isinstance(msg, SystemMessage)]
    messages_for_reporting = [final_prompt_message] + history_messages

    if state.get("debug_mode", False):
        print("--- [DEBUG MODE] å ´æ‰€ç§»å‹•å ±å‘Šãƒãƒ¼ãƒ‰ã®æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ---")
        print(final_prompt_message.content)
        print("-------------------------------------------------")

    effective_settings = config_manager.get_effective_settings(state['character_name'])
    llm = get_configured_llm(state['model_name'], state['api_key'], effective_settings)
    response = llm.invoke(messages_for_reporting)
    return {"messages": [response]}


def route_after_context(state: AgentState) -> Literal["location_report_node", "agent"]:
    """
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå¾Œã€ç›´å‰ã®æ“ä½œãŒå ´æ‰€ç§»å‹•ã ã£ãŸã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã—ã€å‡¦ç†ã‚’æŒ¯ã‚Šåˆ†ã‘ã‚‹ãƒ«ãƒ¼ã‚¿ãƒ¼ã€‚
    """
    print("--- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_context) å®Ÿè¡Œ ---")
    last_message = state["messages"][-1]
    if isinstance(last_message, ToolMessage) and last_message.name == 'set_current_location':
        print("  - `set_current_location` ã®å®Œäº†ã‚’æ¤œçŸ¥ã€‚å ±å‘Šç”Ÿæˆãƒãƒ¼ãƒ‰ã¸ã€‚")
        return "location_report_node"

    print("  - é€šå¸¸ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€è€ƒã¸ã€‚")
    return "agent"


def safe_tool_executor(state: AgentState):
    print("--- ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒãƒ¼ãƒ‰ (safe_tool_executor) å®Ÿè¡Œ ---")
    messages = state['messages']
    last_message = messages[-1]
    tool_invocations = last_message.tool_calls

    api_key = state.get('api_key')
    tavily_api_key = state.get('tavily_api_key')

    tool_outputs = []
    for tool_call in tool_invocations:
        tool_name = tool_call["name"]
        print(f"  - æº–å‚™ä¸­ã®ãƒ„ãƒ¼ãƒ«: {tool_name} | å¼•æ•°: {tool_call['args']}")

        if tool_name == 'generate_image' or tool_name == 'summarize_and_save_core_memory':
            tool_call['args']['api_key'] = api_key
            print(f"    - 'api_key' ã‚’å¼•æ•°ã«è¿½åŠ ã—ã¾ã—ãŸã€‚")
        elif tool_name == 'web_search_tool':
            tool_call['args']['api_key'] = tavily_api_key
            print(f"    - 'tavily_api_key' ã‚’å¼•æ•°ã«è¿½åŠ ã—ã¾ã—ãŸã€‚")

        selected_tool = next((t for t in all_tools if t.name == tool_name), None)
        if not selected_tool:
            output = f"Error: Tool '{tool_name}' not found."
        else:
            try:
                output = selected_tool.invoke(tool_call['args'])
            except Exception as e:
                output = f"Error executing tool '{tool_name}': {e}"
                traceback.print_exc()

        # â–¼â–¼â–¼ã€ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ã€‘â–¼â–¼â–¼
        # ToolMessageã«ã€å®Ÿè¡Œã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã®åå‰ã‚’æ¸¡ã™
        tool_outputs.append(
            ToolMessage(content=str(output), tool_call_id=tool_call["id"], name=tool_name)
        )
        # â–²â–²â–²ã€ä¿®æ­£ã“ã“ã¾ã§ã€‘â–²â–²â–²

    return {"messages": tool_outputs}

def route_after_agent(state: AgentState) -> Literal["__end__", "safe_tool_node"]:
    print("--- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_agent) å®Ÿè¡Œ ---")
    last_message = state["messages"][-1]
    if last_message.tool_calls:
        print("  - ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚ã‚Šã€‚ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒãƒ¼ãƒ‰ã¸ã€‚")
        for tool_call in last_message.tool_calls: print(f"    ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: {tool_call['name']} | å¼•æ•°: {tool_call['args']}")
        return "safe_tool_node"
    print("  - ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãªã—ã€‚æ€è€ƒå®Œäº†ã¨åˆ¤æ–­ã—ã€ã‚°ãƒ©ãƒ•ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    return "__end__"

def route_after_tools(state: AgentState) -> Literal["context_generator", "agent"]:
    print("--- ãƒ„ãƒ¼ãƒ«å¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_tools) å®Ÿè¡Œ ---")
    # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã®ãƒ­ã‚°å‡ºåŠ›
    last_ai_message_index = -1
    for i in range(len(state["messages"]) - 1, -1, -1):
        if isinstance(state["messages"][i], AIMessage):
            last_ai_message_index = i
            break
    if last_ai_message_index != -1:
        new_tool_messages = state["messages"][last_ai_message_index + 1:]
        for msg in new_tool_messages:
            if isinstance(msg, ToolMessage):
                content_to_log = (str(msg.content)[:200] + '...') if len(str(msg.content)) > 200 else str(msg.content)
                print(f"    âœ… ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ: {msg.name} | çµæœ: {content_to_log}")

    # set_current_locationãŒå®Ÿè¡Œã•ã‚ŒãŸã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    last_ai_message_with_tool_call = next((msg for msg in reversed(state['messages']) if isinstance(msg, AIMessage) and msg.tool_calls), None)
    if last_ai_message_with_tool_call:
        if any(call['name'] == 'set_current_location' for call in last_ai_message_with_tool_call.tool_calls):
            print("  - `set_current_location` ãŒå®Ÿè¡Œã•ã‚ŒãŸãŸã‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†ç”Ÿæˆã¸ã€‚")
            return "context_generator"

    print("  - é€šå¸¸ã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå®Œäº†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€è€ƒã¸ã€‚")
    return "agent"

# agent/graph.py ã®æœ«å°¾

workflow = StateGraph(AgentState)
workflow.add_node("context_generator", context_generator_node)
workflow.add_node("agent", agent_node)
workflow.add_node("safe_tool_node", safe_tool_executor)
workflow.add_node("location_report_node", location_report_node) # æ–°ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 

workflow.add_edge(START, "context_generator")

# context_generator ã®å¾Œã¯ã€æ–°ã—ã„ãƒ«ãƒ¼ã‚¿ãƒ¼ã§åˆ¤æ–­ã™ã‚‹
workflow.add_conditional_edges(
    "context_generator",
    route_after_context,
    {
        "location_report_node": "location_report_node",
        "agent": "agent",
    },
)

# agentï¼ˆå¸ä»¤å®˜ï¼‰ã®å¾Œã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã¶ã‹çµ‚äº†ã™ã‚‹ã‹ã‚’åˆ¤æ–­
workflow.add_conditional_edges(
    "agent",
    route_after_agent,
    {
        "safe_tool_node": "safe_tool_node",
        "__end__": END,
    },
)

# ãƒ„ãƒ¼ãƒ«ã®å¾Œã¯ã€å ´æ‰€ç§»å‹•ãŒã‚ã£ãŸã‹ãªã©ã‚’åˆ¤æ–­ã™ã‚‹
workflow.add_conditional_edges(
    "safe_tool_node",
    route_after_tools,
    {"context_generator": "context_generator", "agent": "agent"},
)

# location_report_nodeï¼ˆå ±å‘Šæ‹…å½“å®˜ï¼‰ã¯ã€å ±å‘Šã—ãŸã‚‰ã‚¿ã‚¹ã‚¯å®Œäº†
workflow.add_edge("location_report_node", END)

app = workflow.compile()
print("--- çµ±åˆã‚°ãƒ©ãƒ•(v11)ãŒã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¾ã—ãŸ ---")
