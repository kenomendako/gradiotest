# agent/graph.py ã‚’ã€ã“ã®ã‚³ãƒ¼ãƒ‰ã§å®Œå…¨ã«ç½®ãæ›ãˆã¦ãã ã•ã„

import os
import re
import traceback
import json
import pytz
from typing import TypedDict, Annotated, List, Literal
from langchain_core.messages import SystemMessage, BaseMessage, ToolMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END, START, add_messages
from datetime import datetime
from langgraph.prebuilt import ToolNode

# --- 1. æ­£ã—ã„ãƒ„ãƒ¼ãƒ«ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from agent.prompts import CORE_PROMPT_TEMPLATE
from tools.space_tools import set_current_location, find_location_id_by_name
from tools.memory_tools import read_memory_by_path, edit_memory, add_secret_diary_entry, summarize_and_save_core_memory, read_full_memory
from tools.notepad_tools import add_to_notepad, update_notepad, delete_from_notepad, read_full_notepad
from tools.web_tools import web_search_tool, read_url_tool
from tools.image_tools import generate_image
from tools.alarm_tools import set_personal_alarm
from rag_manager import diary_search_tool, conversation_memory_search_tool

# --- 2. æ­£ã—ã„ãƒ„ãƒ¼ãƒ«ãƒªã‚¹ãƒˆã®å®šç¾© ---
all_tools = [
    set_current_location, find_location_id_by_name, read_memory_by_path, edit_memory,
    add_secret_diary_entry, summarize_and_save_core_memory, add_to_notepad,
    update_notepad, delete_from_notepad, read_full_notepad, web_search_tool,
    read_url_tool, diary_search_tool, conversation_memory_search_tool,
    generate_image, read_full_memory, set_personal_alarm
]

# --- 3. çŠ¶æ…‹(State)ã®å®šç¾© ---
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    character_name: str
    api_key: str
    tavily_api_key: str
    model_name: str
    system_prompt: SystemMessage
    send_core_memory: bool
    send_scenery: bool
    send_notepad: bool # â˜…â˜…â˜… ã“ã®è¡Œã‚’è¿½åŠ  â˜…â˜…â˜…
    location_name: str
    scenery_text: str

# --- 4. ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–é–¢æ•°ã®ä¿®æ­£ ---
def get_configured_llm(model_name: str, api_key: str):
    # â˜…â˜…â˜… ã“ã“ãŒä¿®æ­£ç‚¹ã§ã™ â˜…â˜…â˜…
    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’å¢—ã‚„ã™
    return ChatGoogleGenerativeAI(
        model=model_name,
        google_api_key=api_key,
        convert_system_message_to_human=False,
        max_retries=6 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(2)ã‹ã‚‰å¢—ã‚„ã™ã“ã¨ã§ã€å¾…æ©Ÿæ™‚é–“ãŒé•·ããªã‚Šã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã—ã‚„ã™ããªã‚‹
    )

def context_generator_node(state: AgentState):
    # --- ãƒ‘ã‚¹1: ç©ºé–“æå†™ãŒOFFã®å ´åˆ ---
    if not state.get("send_scenery", True):
        char_prompt_path = os.path.join("characters", state['character_name'], "SystemPrompt.txt")
        core_memory_path = os.path.join("characters", state['character_name'], "core_memory.txt")
        character_prompt = ""
        if os.path.exists(char_prompt_path):
            with open(char_prompt_path, 'r', encoding='utf-8') as f: character_prompt = f.read().strip()
        core_memory = ""
        if state.get("send_core_memory", True):
            if os.path.exists(core_memory_path):
                with open(core_memory_path, 'r', encoding='utf-8') as f:
                    core_memory = f.read().strip()

        notepad_section = ""
        if state.get("send_notepad", True):
            try:
                from character_manager import get_character_files_paths
                _, _, _, _, notepad_path = get_character_files_paths(state['character_name'])
                if notepad_path and os.path.exists(notepad_path):
                    with open(notepad_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        notepad_content = content if content else "ï¼ˆãƒ¡ãƒ¢å¸³ã¯ç©ºã§ã™ï¼‰"
                else:
                    notepad_content = "ï¼ˆãƒ¡ãƒ¢å¸³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰"
                notepad_section = f"\n### çŸ­æœŸè¨˜æ†¶ï¼ˆãƒ¡ãƒ¢å¸³ï¼‰\n{notepad_content}\n"
            except Exception as e:
                print(f"--- è­¦å‘Š: ãƒ¡ãƒ¢å¸³ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                notepad_section = "\n### çŸ­æœŸè¨˜æ†¶ï¼ˆãƒ¡ãƒ¢å¸³ï¼‰\nï¼ˆãƒ¡ãƒ¢å¸³ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰\n"

        tools_list_str = "\n".join([f"- `{tool.name}({', '.join(tool.args.keys())})`: {tool.description}" for tool in all_tools])
        class SafeDict(dict):
            def __missing__(self, key): return f'{{{key}}}'
        prompt_vars = {
            'character_name': state['character_name'], 'character_prompt': character_prompt,
            'core_memory': core_memory, 'notepad_section': notepad_section, 'tools_list': tools_list_str
        }
        formatted_core_prompt = CORE_PROMPT_TEMPLATE.format_map(SafeDict(prompt_vars))
        final_system_prompt_text = (f"{formatted_core_prompt}\n\n---\n" f"ã€ç¾åœ¨ã®å ´æ‰€ã¨æƒ…æ™¯ã€‘\n" f"- å ´æ‰€ã®åå‰: ï¼ˆç©ºé–“æå†™OFFï¼‰\n" f"- å ´æ‰€ã®å®šç¾©: ï¼ˆç©ºé–“æå†™OFFï¼‰\n" f"- ä»Šã®æƒ…æ™¯: ï¼ˆç©ºé–“æå†™OFFï¼‰\n" "---")
        return {"system_prompt": SystemMessage(content=final_system_prompt_text), "location_name": "ï¼ˆç©ºé–“æå†™OFFï¼‰", "scenery_text": "ï¼ˆç©ºé–“æå†™ã¯è¨­å®šã«ã‚ˆã‚Šç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼‰"}

    # --- ãƒ‘ã‚¹2: ç©ºé–“æå†™ãŒONã®å ´åˆ ---
    character_name = state['character_name']; api_key = state['api_key']
    scenery_text = "ï¼ˆç¾åœ¨ã®å ´æ‰€ã®æƒ…æ™¯æå†™ã¯ã€å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
    space_def = "ï¼ˆç¾åœ¨ã®å ´æ‰€ã®å®šç¾©ãƒ»è¨­å®šã¯ã€å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
    location_display_name = "ï¼ˆä¸æ˜ãªå ´æ‰€ï¼‰"

    try:
        location_id_to_process = None
        last_tool_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, ToolMessage)), None)
        if last_tool_message and "Success: Current location has been set to" in last_tool_message.content:
            match = re.search(r"'(.*?)'", last_tool_message.content)
            if match:
                location_id_to_process = match.group(1)

        if not location_id_to_process:
            location_file_path = os.path.join("characters", character_name, "current_location.txt")
            if os.path.exists(location_file_path):
                with open(location_file_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    if content: location_id_to_process = content

        if not location_id: location_id = "living_space"

        world_settings_path = get_world_settings_path(character_name)
        space_data = {}
        if world_settings_path and os.path.exists(world_settings_path):
            world_settings = load_memory_data_safe(world_settings_path)
            if "error" not in world_settings:
                from character_manager import find_space_data_by_id_recursive
                space_data = find_space_data_by_id_recursive(world_settings, location_id)

        if space_data and isinstance(space_data, dict):
            location_display_name = space_data.get("name", location_id)
            space_def = json.dumps(space_data, ensure_ascii=False, indent=2)

        if not space_def.startswith("ï¼ˆ"):
            llm_flash = get_configured_llm("gemini-2.5-flash", api_key)

            # â˜…â˜…â˜… UTCã§ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—ã—ã€æ—¥æœ¬æ™‚é–“ã«å¤‰æ› â˜…â˜…â˜…
            utc_now = datetime.now(pytz.utc)
            jst_now = utc_now.astimezone(pytz.timezone('Asia/Tokyo'))

            scenery_prompt = (f"ç©ºé–“å®šç¾©:{space_def}\næ™‚åˆ»:{jst_now.strftime('%H:%M')} / å­£ç¯€:{jst_now.month}æœˆ\n\nä»¥ä¸Šã®æƒ…å ±ã‹ã‚‰ã€ã‚ãªãŸã¯ã“ã®ç©ºé–“ã®ã€Œä»Šã“ã®ç¬é–“ã€ã‚’åˆ‡ã‚Šå–ã‚‹æƒ…æ™¯æå†™ã®å°‚é–€å®¶ã§ã™ã€‚\nã€ãƒ«ãƒ¼ãƒ«ã€‘\n- äººç‰©ã‚„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æå†™ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n- 1ã€œ2æ–‡ã®ç°¡æ½”ãªæ–‡ç« ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n- çª“ã®å¤–ã®å­£ç¯€æ„Ÿã‚„æ™‚é–“å¸¯ã€å®¤å†…ã®ç©ºæ°—æ„Ÿã‚„é™°å½±ãªã©ã€äº”æ„Ÿã«è¨´ãˆã‹ã‘ã‚‹ç²¾ç·»ã§å†™å®Ÿçš„ãªæå†™ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚")
            scenery_text = llm_flash.invoke(scenery_prompt).content
        else:
            scenery_text = "ï¼ˆå ´æ‰€ã®å®šç¾©ãŒãªã„ãŸã‚ã€æƒ…æ™¯ã‚’æå†™ã§ãã¾ã›ã‚“ï¼‰"

    except Exception as e:
        print(f"--- è­¦å‘Š: æƒ…æ™¯æå†™ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ---\n{traceback.format_exc()}"); location_display_name = "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"; scenery_text = "ï¼ˆæƒ…æ™¯æå†™ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰"

    char_prompt_path = os.path.join("characters", character_name, "SystemPrompt.txt")
    core_memory_path = os.path.join("characters", character_name, "core_memory.txt")
    character_prompt = "";
    if os.path.exists(char_prompt_path):
        with open(char_prompt_path, 'r', encoding='utf-8') as f: character_prompt = f.read().strip()
    core_memory = ""
    if state.get("send_core_memory", True):
        if os.path.exists(core_memory_path):
            with open(core_memory_path, 'r', encoding='utf-8') as f: core_memory = f.read().strip()

    notepad_section = ""
    if state.get("send_notepad", True):
        try:
            from character_manager import get_character_files_paths
            _, _, _, _, notepad_path = get_character_files_paths(character_name)
            if notepad_path and os.path.exists(notepad_path):
                with open(notepad_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    notepad_content = content if content else "ï¼ˆãƒ¡ãƒ¢å¸³ã¯ç©ºã§ã™ï¼‰"
            else:
                notepad_content = "ï¼ˆãƒ¡ãƒ¢å¸³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰"
            notepad_section = f"\n### çŸ­æœŸè¨˜æ†¶ï¼ˆãƒ¡ãƒ¢å¸³ï¼‰\n{notepad_content}\n"
        except Exception as e:
            print(f"--- è­¦å‘Š: ãƒ¡ãƒ¢å¸³ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            notepad_section = "\n### çŸ­æœŸè¨˜æ†¶ï¼ˆãƒ¡ãƒ¢å¸³ï¼‰\nï¼ˆãƒ¡ãƒ¢å¸³ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰\n"

    tools_list_str = "\n".join([f"- `{tool.name}({', '.join(tool.args.keys())})`: {tool.description}" for tool in all_tools])
    class SafeDict(dict):
        def __missing__(self, key): return f'{{{key}}}'
    prompt_vars = {'character_name': character_name, 'character_prompt': character_prompt, 'core_memory': core_memory, 'notepad_section': notepad_section, 'tools_list': tools_list_str}
    formatted_core_prompt = CORE_PROMPT_TEMPLATE.format_map(SafeDict(prompt_vars))
    final_system_prompt_text = (
        f"{formatted_core_prompt}\n\n---\n"
        f"ã€ç¾åœ¨ã®å ´æ‰€ã¨æƒ…æ™¯ã€‘\n"
        f"- å ´æ‰€ã®åå‰: {location_display_name}\n"
        f"- å ´æ‰€ã®å®šç¾©: {space_def}\n"
        f"- ä»Šã®æƒ…æ™¯: {scenery_text}\n"
        "---"
    )

    return {"system_prompt": SystemMessage(content=final_system_prompt_text), "location_name": location_display_name, "scenery_text": scenery_text}

# --- 6. ãƒãƒ¼ãƒ‰ã®å®šç¾© ---
def agent_node(state: AgentState):
    print("--- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ‰ (agent_node) å®Ÿè¡Œ ---")
    # â˜…â˜…â˜… ã“ã“ã‹ã‚‰2è¡Œè¿½åŠ  â˜…â˜…â˜…
    print(f"  - ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {state['model_name']}")
    print(f"  - ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(state['system_prompt'].content)} æ–‡å­—")
    # â˜…â˜…â˜… ã“ã“ã¾ã§ â˜…â˜…â˜…
    llm = get_configured_llm(state['model_name'], state['api_key'])
    llm_with_tools = llm.bind_tools(all_tools)
    messages_for_agent = [state['system_prompt']] + state['messages']
    response = llm_with_tools.invoke(messages_for_agent)
    return {"messages": [response]}

def safe_tool_executor(state: AgentState):
    """stateã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã—ã€å®‰å…¨ã«ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ¼ãƒ‰"""
    print("--- ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒãƒ¼ãƒ‰ (safe_tool_executor) å®Ÿè¡Œ ---")
    messages = state['messages']
    last_message = messages[-1]
    tool_invocations = last_message.tool_calls

    api_key = state.get('api_key')
    tavily_api_key = state.get('tavily_api_key')

    tool_outputs = []
    for tool_call in tool_invocations:
        tool_name = tool_call["name"]
        print(f"  - æº–å‚™ä¸­ã®ãƒ„ãƒ¼ãƒ«: {tool_name} | å¼•æ•°: {tool_call['args']}")

        # APIã‚­ãƒ¼ã‚’å¿…è¦ã¨ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã«è‡ªå‹•ã§ã‚­ãƒ¼ã‚’æ¸¡ã™
        if tool_name == 'generate_image' or tool_name == 'summarize_and_save_core_memory':
            tool_call['args']['api_key'] = api_key
            print(f"    - 'api_key' ã‚’å¼•æ•°ã«è¿½åŠ ã—ã¾ã—ãŸã€‚")
        elif tool_name == 'web_search_tool':
            tool_call['args']['api_key'] = tavily_api_key
            print(f"    - 'tavily_api_key' ã‚’å¼•æ•°ã«è¿½åŠ ã—ã¾ã—ãŸã€‚")

        # all_toolsãƒªã‚¹ãƒˆã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã‚’åå‰ã§æ¤œç´¢
        selected_tool = next((t for t in all_tools if t.name == tool_name), None)
        if not selected_tool:
            output = f"Error: Tool '{tool_name}' not found."
        else:
            try:
                output = selected_tool.invoke(tool_call['args'])
            except Exception as e:
                output = f"Error executing tool '{tool_name}': {e}"
                traceback.print_exc()

        tool_outputs.append(
            ToolMessage(content=str(output), tool_call_id=tool_call["id"])
        )

    return {"messages": tool_outputs}

# --- 7. ãƒ«ãƒ¼ã‚¿ãƒ¼ã®å®šç¾© ---
def route_after_agent(state: AgentState) -> Literal["__end__", "safe_tool_node"]:
    print("--- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_agent) å®Ÿè¡Œ ---")
    last_message = state["messages"][-1]
    if last_message.tool_calls:
        print("  - ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚ã‚Šã€‚ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒãƒ¼ãƒ‰ã¸ã€‚")
        for tool_call in last_message.tool_calls: print(f"    ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: {tool_call['name']} | å¼•æ•°: {tool_call['args']}")
        return "safe_tool_node"
    print("  - ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãªã—ã€‚æ€è€ƒå®Œäº†ã¨åˆ¤æ–­ã—ã€ã‚°ãƒ©ãƒ•ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    return "__end__"

def route_after_tools(state: AgentState) -> Literal["context_generator", "agent"]:
    print("--- ãƒ„ãƒ¼ãƒ«å¾Œãƒ«ãƒ¼ã‚¿ãƒ¼ (route_after_tools) å®Ÿè¡Œ ---")
    last_ai_message_index = -1
    for i in range(len(state["messages"]) - 1, -1, -1):
        if isinstance(state["messages"][i], AIMessage): last_ai_message_index = i; break
    if last_ai_message_index != -1:
        new_tool_messages = state["messages"][last_ai_message_index + 1:]
        for msg in new_tool_messages:
            if isinstance(msg, ToolMessage):
                content_to_log = (str(msg.content)[:200] + '...') if len(str(msg.content)) > 200 else str(msg.content)
                print(f"    âœ… ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ: {msg.name} | çµæœ: {content_to_log}")
    last_ai_message_with_tool_call = next((msg for msg in reversed(state['messages']) if isinstance(msg, AIMessage) and msg.tool_calls), None)
    if last_ai_message_with_tool_call:
        if any(call['name'] == 'set_current_location' for call in last_ai_message_with_tool_call.tool_calls):
            print("  - `set_current_location` ãŒå®Ÿè¡Œã•ã‚ŒãŸãŸã‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†ç”Ÿæˆã¸ã€‚")
            return "context_generator"
    print("  - é€šå¸¸ã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå®Œäº†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€è€ƒã¸ã€‚")
    return "agent"

# --- 8. ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ ---
workflow = StateGraph(AgentState)
workflow.add_node("context_generator", context_generator_node)
workflow.add_node("agent", agent_node)
workflow.add_node("safe_tool_node", safe_tool_executor) # å¤‰æ›´ç‚¹ï¼šToolNodeã®ä»£ã‚ã‚Šã«ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°ã‚’ä½¿ç”¨

workflow.add_edge(START, "context_generator")
workflow.add_edge("context_generator", "agent")

workflow.add_conditional_edges(
    "agent",
    route_after_agent,
    {
        "safe_tool_node": "safe_tool_node", # å¤‰æ›´ç‚¹ï¼šå‚ç…§å…ˆã‚’æ–°ã—ã„ãƒãƒ¼ãƒ‰åã«
        "__end__": END,
    },
)
workflow.add_conditional_edges(
    "safe_tool_node", # å¤‰æ›´ç‚¹ï¼šå‚ç…§å…ƒã‚’æ–°ã—ã„ãƒãƒ¼ãƒ‰åã«
    route_after_tools,
    {"context_generator": "context_generator", "agent": "agent"},
)

app = workflow.compile()
print("--- çµ±åˆã‚°ãƒ©ãƒ•(v5)ãŒã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¾ã—ãŸ ---")
