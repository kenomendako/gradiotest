# ui_handlers.py ã‚’ã€ã“ã®æœ€çµ‚ç¢ºå®šç‰ˆã‚³ãƒ¼ãƒ‰ã§å®Œå…¨ã«ç½®ãæ›ãˆã¦ãã ã•ã„

# ... (ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆéƒ¨åˆ†ã¯å¤‰æ›´ãªã—) ...
import pandas as pd
# ... (ä»–ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ) ...
import html
import io
import base64
import filetype
import threading
from PIL import Image
import re
import os
import traceback
import json
import datetime
import gradio as gr
from typing import List, Optional, Dict, Any, Tuple
import gemini_api, config_manager, alarm_manager, character_manager, utils
from tools import memory_tools
from timers import UnifiedTimer
from character_manager import get_character_files_paths
from memory_manager import load_memory_data_safe, save_memory_data

# â˜…â˜…â˜… æ–°ã—ã„å‰Šé™¤ãƒ•ãƒ­ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒ©ç¾¤ â˜…â˜…â˜…
def handle_chatbot_selection(chatbot_history: List[Dict[str, str]], evt: gr.SelectData):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé¸æŠã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã—ã€å¯¾è±¡ã‚’Stateã«ä¿å­˜ã™ã‚‹ã€‚"""
    if not evt.value:
        return None, gr.update(visible=False)
    try:
        clicked_index = evt.index if isinstance(evt.index, int) else evt.index[0]
        # ãƒ­ã‚°ã‹ã‚‰èª­ã¿è¾¼ã‚“ã ç”Ÿã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã¯ãªããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãã®ã‚‚ã®ã‚’ä¿å­˜
        selected_raw_message = chatbot_history[clicked_index]
        return selected_raw_message, gr.update(visible=True)
    except Exception as e:
        print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é¸æŠå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return None, gr.update(visible=False)

def handle_delete_button_click(
    selected_message: Optional[Dict[str, str]],
    character_name: str,
    api_history_limit: str
):
    """ã€Œé¸æŠã—ãŸç™ºè¨€ã‚’å‰Šé™¤ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if not selected_message:
        gr.Warning("å‰Šé™¤ã™ã‚‹ç™ºè¨€ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return gr.update(), None, gr.update(visible=False)

    log_f, _, _, _, _ = get_character_files_paths(character_name)
    success = utils.delete_message_from_log(log_f, selected_message)
    if success:
        gr.Info("é¸æŠã•ã‚ŒãŸç™ºè¨€ã‚’ãƒ­ã‚°ã‹ã‚‰å‰Šé™¤ã—ã¾ã—ãŸã€‚")
    else:
        gr.Error("ç™ºè¨€ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    new_chat_history = reload_chat_log(character_name, api_history_limit)

    # å‰Šé™¤å¾Œã¯ã€é¸æŠçŠ¶æ…‹ã‚’è§£é™¤ã—ã€ãƒœã‚¿ãƒ³ã‚’éè¡¨ç¤ºã«ã™ã‚‹
    return new_chat_history, None, gr.update(visible=False)

# ... (ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ä»–ã®é–¢æ•°ã¯ã€å‰å›ã®æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æˆ»ã™ã‹ã€ãã®ã¾ã¾ç¶­æŒã—ã¦ãã ã•ã„) ...
# (ç‰¹ã«ã€_generate_initial_scenery ã‚„ handle_message_submission ãªã©)
def _generate_initial_scenery(character_name: str, api_key_name: str) -> Tuple[str, str]:
    print("--- [è»½é‡ç‰ˆ] æƒ…æ™¯ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™ ---"); api_key = config_manager.API_KEYS.get(api_key_name)
    if not character_name or not api_key: return "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰", "ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªè¨­å®šã§ã™ï¼‰"
    from agent.graph import get_configured_llm; from tools.memory_tools import read_memory_by_path
    location_id = utils.get_current_location(character_name) or "living_space"
    space_details_raw = read_memory_by_path.invoke({"path": f"living_space.{location_id}", "character_name": character_name})
    location_display_name = location_id; space_def = "ï¼ˆç¾åœ¨ã®å ´æ‰€ã®å®šç¾©ãƒ»è¨­å®šã¯ã€å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"; scenery_text = "ï¼ˆå ´æ‰€ã®å®šç¾©ãŒãªã„ãŸã‚ã€æƒ…æ™¯ã‚’æå†™ã§ãã¾ã›ã‚“ï¼‰"
    try:
        if not space_details_raw.startswith("ã€ã‚¨ãƒ©ãƒ¼ã€‘"):
            try:
                space_data = json.loads(space_details_raw)
                if isinstance(space_data, dict):
                    location_display_name = space_data.get("name", location_id)
                    space_def = json.dumps(space_data, ensure_ascii=False, indent=2)
                else:
                    space_def = str(space_data)
            except (json.JSONDecodeError, TypeError):
                space_def = space_details_raw

            if not space_def.startswith("ï¼ˆ"):
                llm_flash = get_configured_llm("gemini-2.5-flash", api_key)
                now = datetime.datetime.now()
                scenery_prompt = (
                    f"ç©ºé–“å®šç¾©:{space_def}\næ™‚åˆ»:{now.strftime('%H:%M')} / å­£ç¯€:{now.month}æœˆ\n\n"
                    "ä»¥ä¸Šã®æƒ…å ±ã‹ã‚‰ã€ã‚ãªãŸã¯ã“ã®ç©ºé–“ã®ã€Œä»Šã“ã®ç¬é–“ã€ã‚’åˆ‡ã‚Šå–ã‚‹æƒ…æ™¯æå†™ã®å°‚é–€å®¶ã§ã™ã€‚\n"
                    "ã€ãƒ«ãƒ¼ãƒ«ã€‘\n"
                    "- äººç‰©ã‚„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æå†™ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
                    "- 1ã€œ2æ–‡ã®ç°¡æ½”ãªæ–‡ç« ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                    "- çª“ã®å¤–ã®å­£ç¯€æ„Ÿã‚„æ™‚é–“å¸¯ã€å®¤å†…ã®ç©ºæ°—æ„Ÿã‚„é™°å½±ãªã©ã€äº”æ„Ÿã«è¨´ãˆã‹ã‘ã‚‹ç²¾ç·»ã§å†™å®Ÿçš„ãªæå†™ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚"
                )
                scenery_text = llm_flash.invoke(scenery_prompt).content
                print(f"  - ç”Ÿæˆã•ã‚ŒãŸæƒ…æ™¯: {scenery_text}")

    except Exception as e:
        print(f"--- [è»½é‡ç‰ˆ] æƒ…æ™¯ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        location_display_name = "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"
        scenery_text = "ï¼ˆæƒ…æ™¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼‰"

    return location_display_name, scenery_text
def handle_message_submission(*args: Any):
    (textbox_content, chatbot_history, current_character_name, current_model_name, current_api_key_name_state, file_input_list, add_timestamp_checkbox, send_thoughts_state, api_history_limit_state, send_notepad_state, use_common_prompt_state, send_core_memory_state, send_scenery_state) = args
    user_prompt_from_textbox = textbox_content.strip() if textbox_content else ""
    if not user_prompt_from_textbox and not file_input_list:
        token_count = update_token_count(current_character_name, current_model_name, None, None, api_history_limit_state, current_api_key_name_state, send_notepad_state, use_common_prompt_state, add_timestamp_checkbox, send_thoughts_state, send_core_memory_state, send_scenery_state)
        yield chatbot_history, gr.update(), gr.update(), token_count, gr.update(), gr.update()
        return

    log_message_parts = []
    if user_prompt_from_textbox:
        timestamp = f"\n\n{datetime.datetime.now().strftime('%Y-%m-%d (%a) %H:%M:%S')}" if add_timestamp_checkbox else ""
        processed_user_message = user_prompt_from_textbox + timestamp
        chatbot_history.append({"role": "user", "content": processed_user_message})
        log_message_parts.append(processed_user_message)

    if file_input_list:
        for file_obj in file_input_list:
            filepath = file_obj.name
            filename = os.path.basename(filepath)
            safe_filepath = os.path.abspath(filepath).replace("\\", "/")
            md_string = f"[{filename}](/file={safe_filepath})"
            chatbot_history.append({"role": "user", "content": md_string})
            log_message_parts.append(f"[ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜: {filepath}]")

    chatbot_history.append({"role": "assistant", "content": "æ€è€ƒä¸­... â–Œ"})
    token_count = update_token_count(current_character_name, current_model_name, textbox_content, file_input_list, api_history_limit_state, current_api_key_name_state, send_notepad_state, use_common_prompt_state, add_timestamp_checkbox, send_thoughts_state, send_core_memory_state, send_scenery_state)

    yield chatbot_history, gr.update(value=""), gr.update(value=None), token_count, gr.update(), gr.update()

    response_data = {}
    try:
        response_data = gemini_api.invoke_nexus_agent(*args)
    except Exception as e:
        traceback.print_exc()
        response_data = {"response": f"[UIãƒãƒ³ãƒ‰ãƒ©ã‚¨ãƒ©ãƒ¼: {e}]", "location_name": "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰", "scenery": "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"}

    final_response_text = response_data.get("response", "")
    location_name = response_data.get("location_name", "ï¼ˆå–å¾—å¤±æ•—ï¼‰")
    scenery_text = response_data.get("scenery", "ï¼ˆå–å¾—å¤±æ•—ï¼‰")

    log_f, _, _, _, _ = get_character_files_paths(current_character_name)
    final_log_message = "\n\n".join(log_message_parts).strip()
    if final_log_message:
        user_header = utils._get_user_header_from_log(log_f, current_character_name)
        utils.save_message_to_log(log_f, user_header, final_log_message)
    if final_response_text:
        utils.save_message_to_log(log_f, f"## {current_character_name}:", final_response_text)

    raw_history = utils.load_chat_log(log_f, current_character_name)
    display_turns = _get_display_history_count(api_history_limit_state)
    formatted_history = utils.format_history_for_gradio(raw_history[-(display_turns*2):])

    token_count = update_token_count(current_character_name, current_model_name, None, None, api_history_limit_state, current_api_key_name_state, send_notepad_state, use_common_prompt_state, add_timestamp_checkbox, send_thoughts_state, send_core_memory_state, send_scenery_state)

    yield formatted_history, gr.update(), gr.update(value=None), token_count, location_name, scenery_text
def handle_scenery_refresh(character_name: str, api_key_name: str) -> Tuple[str, str]:
    if not character_name or not api_key_name:
        return "ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªé¸æŠã§ã™ï¼‰", "ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªé¸æŠã§ã™ï¼‰"
    gr.Info(f"ã€Œ{character_name}ã€ã®ç¾åœ¨ã®æƒ…æ™¯ã‚’æ›´æ–°ã—ã¦ã„ã¾ã™...")
    loc, scen = _generate_initial_scenery(character_name, api_key_name)
    gr.Info("æƒ…æ™¯ã‚’æ›´æ–°ã—ã¾ã—ãŸ.")
    return loc, scen
def handle_location_change_and_update_scenery(character_name: str, location_id: str, api_key_name: str) -> Tuple[str, str]:
    from tools.space_tools import set_current_location
    print(f"--- UIã‹ã‚‰ã®å ´æ‰€å¤‰æ›´å‡¦ç†é–‹å§‹: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼='{character_name}', ç§»å‹•å…ˆID='{location_id}' ---")
    if not character_name or not location_id:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ç§»å‹•å…ˆã®å ´æ‰€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return _generate_initial_scenery(character_name, api_key_name)

    result = set_current_location.func(location=location_id, character_name=character_name)
    if "Success" not in result:
        gr.Error(f"å ´æ‰€ã®å¤‰æ›´ã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
        return _generate_initial_scenery(character_name, api_key_name)

    gr.Info(f"å ´æ‰€ã‚’ã€Œ{location_id}ã€ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚ç¶šã‘ã¦æƒ…æ™¯ã‚’æ›´æ–°ã—ã¾ã™ã€‚")
    loc, scen = _generate_initial_scenery(character_name, api_key_name)
    gr.Info("å ´æ‰€æƒ…å ±ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
    return loc, scen
def get_location_list_for_ui(character_name: str) -> list:
    if not character_name: return []
    _, _, _, memory_json_path, _ = get_character_files_paths(character_name)
    memory_data = load_memory_data_safe(memory_json_path)
    if "error" in memory_data or "living_space" not in memory_data: return []
    living_space = memory_data.get("living_space", {})
    location_list = []
    for loc_id, details in living_space.items():
        if isinstance(details, dict):
            location_list.append((details.get("name", loc_id), loc_id))
    return sorted(location_list, key=lambda x: x[0])
def handle_add_new_character(character_name: str):
    if not character_name or not character_name.strip():
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        char_list = character_manager.get_character_list()
        return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    safe_name = re.sub(r'[\\/*?:"<>|]', "", character_name).strip()
    if not safe_name:
        gr.Warning("ç„¡åŠ¹ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§ã™ã€‚")
        char_list = character_manager.get_character_list()
        return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    if character_manager.ensure_character_files(safe_name):
        gr.Info(f"æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã•ã‚“ã‚’è¿ãˆã¾ã—ãŸï¼")
        new_char_list = character_manager.get_character_list()
        return gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(value="")
    else:
        gr.Error(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        char_list = character_manager.get_character_list()
        return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value=character_name)
def _get_display_history_count(api_history_limit_value: str) -> int:
    return int(api_history_limit_value) if api_history_limit_value.isdigit() else config_manager.UI_HISTORY_MAX_LIMIT
def update_ui_on_character_change(character_name: Optional[str], api_history_limit_value: str):
    if not character_name:
        all_chars = character_manager.get_character_list()
        character_name = all_chars[0] if all_chars else "Default"
    config_manager.save_config("last_character", character_name)
    log_f, _, img_p, mem_p, notepad_p = get_character_files_paths(character_name)
    display_turns = _get_display_history_count(api_history_limit_value)
    chat_history = utils.format_history_for_gradio(utils.load_chat_log(log_f, character_name)[-(display_turns * 2):])
    memory_str = json.dumps(load_memory_data_safe(mem_p), indent=2, ensure_ascii=False)
    profile_image = img_p if img_p and os.path.exists(img_p) else None
    notepad_content = load_notepad_content(character_name)
    locations = get_location_list_for_ui(character_name)
    current_location_id = utils.get_current_location(character_name)
    return (character_name, chat_history, "", profile_image, memory_str, character_name, character_name, notepad_content, gr.update(choices=locations, value=current_location_id))
def handle_initial_load():
    print("--- UIåˆæœŸåŒ–å‡¦ç†(handle_initial_load)ã‚’é–‹å§‹ã—ã¾ã™ ---")
    char_name = config_manager.initial_character_global
    model_name = config_manager.initial_model_global
    api_key_name = config_manager.initial_api_key_name_global
    api_history_limit = config_manager.initial_api_history_limit_option_global
    df_with_ids = render_alarms_as_dataframe()
    display_df = get_display_df(df_with_ids)
    (ret_char, chat_hist, _, prof_img, mem_str, al_char, tm_char, note_cont, loc_dd) = update_ui_on_character_change(char_name, api_history_limit)
    loc, scen = _generate_initial_scenery(ret_char, api_key_name)
    token_count = update_token_count(ret_char, model_name, None, None, api_history_limit, api_key_name, True, True, config_manager.initial_add_timestamp_global, config_manager.initial_send_thoughts_to_api_global, True, True)
    return (display_df, df_with_ids, chat_hist, prof_img, mem_str, al_char, tm_char, "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„", token_count, note_cont, loc_dd, loc, scen)
def handle_save_memory_click(character_name, json_string_data):
    if not character_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return gr.update()
    try:
        return save_memory_data(character_name, json_string_data)
    except Exception as e:
        gr.Error(f"è¨˜æ†¶ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return gr.update()
def handle_reload_memory(character_name: str) -> str:
    if not character_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return "{}"
    gr.Info(f"ã€Œ{character_name}ã€ã®è¨˜æ†¶ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚")
    _, _, _, memory_json_path, _ = get_character_files_paths(character_name)
    memory_data = load_memory_data_safe(memory_json_path)
    return json.dumps(memory_data, indent=2, ensure_ascii=False)
def load_notepad_content(character_name: str) -> str:
    if not character_name: return ""
    _, _, _, _, notepad_path = get_character_files_paths(character_name)
    if notepad_path and os.path.exists(notepad_path):
        with open(notepad_path, "r", encoding="utf-8") as f:
            return f.read()
    return ""
def handle_save_notepad_click(character_name: str, content: str) -> str:
    if not character_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return content
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path:
        gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚")
        return content
    lines = []
    for line in content.strip().split('\n'):
        line = line.strip()
        if line and not re.match(r"^\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}\]", line):
            lines.append(f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}] {line}")
        elif line:
            lines.append(line)
    final_content = "\n".join(lines)
    try:
        with open(notepad_path, "w", encoding="utf-8") as f:
            f.write(final_content + ('\n' if final_content else ''))
        gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
        return final_content
    except Exception as e:
        gr.Error(f"ãƒ¡ãƒ¢å¸³ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return content
def handle_clear_notepad_click(character_name: str) -> str:
    if not character_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return ""
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path:
        gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚")
        return ""
    try:
        with open(notepad_path, "w", encoding="utf-8") as f:
            f.write("")
        gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ç©ºã«ã—ã¾ã—ãŸã€‚")
        return ""
    except Exception as e:
        gr.Error(f"ãƒ¡ãƒ¢å¸³ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")
        return f"ã‚¨ãƒ©ãƒ¼: {e}"
def handle_reload_notepad(character_name: str) -> str:
    if not character_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return ""
    content = load_notepad_content(character_name)
    gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚")
    return content
DAY_MAP_EN_TO_JA = {"mon": "æœˆ", "tue": "ç«", "wed": "æ°´", "thu": "æœ¨", "fri": "é‡‘", "sat": "åœŸ", "sun": "æ—¥"}
DAY_MAP_JA_TO_EN = {v: k for k, v in DAY_MAP_EN_TO_JA.items()}
def render_alarms_as_dataframe():
    alarms = sorted(alarm_manager.load_alarms(), key=lambda x: x.get("time", ""))
    all_rows = []
    for a in alarms:
        theme_content = a.get("context_memo") or ""
        date_str = a.get("date")
        days_list = a.get("days", [])
        schedule_display = "å˜ç™º"
        if date_str:
            try:
                date_obj = datetime.datetime.strptime(date_str, "%Y-%m-%d").date()
                today = datetime.date.today()
                if date_obj == today: schedule_display = "ä»Šæ—¥"
                elif date_obj == today + datetime.timedelta(days=1): schedule_display = "æ˜æ—¥"
                else: schedule_display = date_obj.strftime("%m/%d")
            except:
                schedule_display = "æ—¥ä»˜ä¸å®š"
        elif days_list:
            schedule_display = ",".join([DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in days_list])
        all_rows.append({"ID": a.get("id"), "çŠ¶æ…‹": a.get("enabled", False), "æ™‚åˆ»": a.get("time"), "äºˆå®š": schedule_display, "ã‚­ãƒ£ãƒ©": a.get("character"), "å†…å®¹": theme_content})
    return pd.DataFrame(all_rows, columns=["ID", "çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])
def get_display_df(df_with_id: pd.DataFrame):
    if df_with_id is None or df_with_id.empty:
        return pd.DataFrame(columns=["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])
    return df_with_id[["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"]] if 'ID' in df_with_id.columns else df_with_id
def handle_alarm_selection(evt: gr.SelectData, df_with_id: pd.DataFrame) -> List[str]:
    if evt.index is None or df_with_id is None or df_with_id.empty:
        return []
    try:
        indices = [idx[0] for idx in evt.index] if isinstance(evt.index, list) else [evt.index[0]]
        return [str(df_with_id.iloc[i]['ID']) for i in indices if 0 <= i < len(df_with_id)]
    except:
        return []
def handle_alarm_selection_and_feedback(evt: gr.SelectData, df_with_id: pd.DataFrame):
    selected_ids = handle_alarm_selection(evt, df_with_id)
    return selected_ids, "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„" if not selected_ids else f"{len(selected_ids)} ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠä¸­"
def toggle_selected_alarms_status(selected_ids: list, target_status: bool):
    if not selected_ids:
        gr.Warning("çŠ¶æ…‹ã‚’å¤‰æ›´ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    for alarm_id in selected_ids:
        alarm_manager.toggle_alarm_status(alarm_id, target_status)
    new_df_with_ids = render_alarms_as_dataframe()
    return new_df_with_ids, get_display_df(new_df_with_ids)
def handle_delete_selected_alarms(selected_ids: list):
    if not selected_ids:
        gr.Warning("å‰Šé™¤ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        for sid in selected_ids:
            alarm_manager.delete_alarm(str(sid))
    new_df_with_ids = render_alarms_as_dataframe()
    return new_df_with_ids, get_display_df(new_df_with_ids)
def handle_add_or_update_alarm(editing_id, h, m, char, theme, prompt, days_ja):
    from tools.alarm_tools import set_personal_alarm
    time_str = f"{h}:{m}"
    context = theme or prompt or "æ™‚é–“ã«ãªã‚Šã¾ã—ãŸ"
    days_en = [DAY_MAP_JA_TO_EN.get(d) for d in days_ja if d in DAY_MAP_JA_TO_EN]
    if editing_id:
        alarm_manager.delete_alarm(editing_id)
        gr.Info(f"ã‚¢ãƒ©ãƒ¼ãƒ ID:{editing_id}ã‚’æ›´æ–°ã—ã¾ã™ã€‚")
    set_personal_alarm.func(time=time_str, context_memo=context, character_name=char, days=days_en, date=None)
    new_df_with_ids = render_alarms_as_dataframe()
    default_char = character_manager.get_character_list()[0]
    return new_df_with_ids, get_display_df(new_df_with_ids), "ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", default_char, [], "08", "00", None
def load_alarm_to_form(selected_ids: list):
    all_chars = character_manager.get_character_list()
    default_char = all_chars[0] if all_chars else "Default"
    if not selected_ids or len(selected_ids) != 1:
        return "ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", default_char, [], "08", "00", None
    alarm = next((a for a in alarm_manager.load_alarms() if a.get("id") == selected_ids[0]), None)
    if not alarm:
        gr.Warning(f"ã‚¢ãƒ©ãƒ¼ãƒ ID '{selected_ids[0]}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return "ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", default_char, [], "08", "00", None
    h, m = alarm.get("time", "08:00").split(":")
    days_ja = [DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in alarm.get("days", [])]
    theme_content = alarm.get("context_memo") or ""
    return "ã‚¢ãƒ©ãƒ¼ãƒ æ›´æ–°", theme_content, "", alarm.get("character", default_char), days_ja, h, m, selected_ids[0]
def handle_timer_submission(timer_type, duration, work, brk, cycles, char, work_theme, brk_theme, api_key_name, normal_theme):
    if not char or not api_key_name:
        return "ã‚¨ãƒ©ãƒ¼ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
    try:
        timer = UnifiedTimer(timer_type, float(duration or 0), float(work or 0), float(brk or 0), int(cycles or 0), char, work_theme, brk_theme, api_key_name, normal_theme=normal_theme)
        timer.start()
        gr.Info(f"{timer_type}ã‚’é–‹å§‹ã—ã¾ã—ãŸ.")
        return f"{timer_type}ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚"
    except Exception as e:
        return f"ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}"
def handle_rag_update_button_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"):
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    gr.Info(f"ã€Œ{character_name}ã€ã®RAGç´¢å¼•ã®æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã™...")
    import rag_manager
    threading.Thread(target=lambda: rag_manager.create_or_update_index(character_name, api_key)).start()
def _run_core_memory_update(character_name: str, api_key: str):
    print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ (Character: {character_name}) ---")
    try:
        result = memory_tools.summarize_and_save_core_memory.func(character_name=character_name, api_key=api_key)
        print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†å®Œäº† --- çµæœ: {result}")
    except Exception as e:
        print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¨ãƒ©ãƒ¼] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ ---")
        traceback.print_exc()
def handle_core_memory_update_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"):
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    gr.Info(f"ã€Œ{character_name}ã€ã®ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹ã—ã¾ã—ãŸã€‚")
    threading.Thread(target=_run_core_memory_update, args=(character_name, api_key)).start()
def update_model_state(model):
    config_manager.save_config("last_model", model)
    return model
def update_api_key_state(api_key_name):
    config_manager.save_config("last_api_key_name", api_key_name)
    gr.Info(f"APIã‚­ãƒ¼ã‚’ '{api_key_name}' ã«è¨­å®šã—ã¾ã—ãŸã€‚")
    return api_key_name
def update_timestamp_state(checked):
    config_manager.save_config("add_timestamp", bool(checked))
def update_send_thoughts_state(checked):
    config_manager.save_config("last_send_thoughts_to_api", bool(checked))
    return bool(checked)
def update_send_notepad_state(checked: bool): return checked
def update_use_common_prompt_state(checked: bool): return checked
def update_send_core_memory_state(checked: bool): return bool(checked)
def update_send_scenery_state(checked: bool): return bool(checked)
def update_api_history_limit_state_and_reload_chat(limit_ui_val: str, character_name: Optional[str]):
    key = next((k for k, v in config_manager.API_HISTORY_LIMIT_OPTIONS.items() if v == limit_ui_val), "all")
    config_manager.save_config("last_api_history_limit_option", key)
    return key, reload_chat_log(character_name, key), gr.State()
def reload_chat_log(character_name: Optional[str], api_history_limit_value: str):
    if not character_name: return []
    log_f,_,_,_,_ = get_character_files_paths(character_name)
    if not log_f or not os.path.exists(log_f): return []
    display_turns = _get_display_history_count(api_history_limit_value)
    history = utils.format_history_for_gradio(utils.load_chat_log(log_f, character_name)[-(display_turns*2):])
    return history
def update_token_count(*args):
    (current_character_name, current_model_name, textbox_content, file_input_list, api_history_limit_state, current_api_key_name_state, send_notepad_state, use_common_prompt_state, add_timestamp_state, send_thoughts_state, send_core_memory_state, send_scenery_state) = args
    parts_for_api = []
    if textbox_content:
        parts_for_api.append(textbox_content.strip())
    if file_input_list:
        for file_obj in file_input_list:
            filepath = file_obj.name
            try:
                kind = filetype.guess(filepath)
                mime_type = kind.mime if kind else None
                if mime_type and mime_type.startswith("image/"):
                    parts_for_api.append(Image.open(filepath))
                elif mime_type and (mime_type.startswith("audio/") or mime_type.startswith("video/") or mime_type == "application/pdf"):
                    with open(filepath, "rb") as f:
                        file_data = base64.b64encode(f.read()).decode("utf-8")
                        parts_for_api.append({"type": "media", "mime_type": mime_type, "data": file_data})
                else:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        text_content = f.read()
                        parts_for_api.append(f"--- æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{os.path.basename(filepath)}ã€ã®å†…å®¹ ---\n{text_content}\n--- ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã“ã“ã¾ã§ ---")
            except Exception as e:
                print(f"è­¦å‘Š: ãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    try:
        token_count = gemini_api.count_input_tokens(current_character_name, current_model_name, parts_for_api, api_history_limit_state, current_api_key_name_state, send_notepad_state, use_common_prompt_state, add_timestamp_state, send_thoughts_state, send_core_memory_state, send_scenery_state)
        if token_count == -1: return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: (APIã‚­ãƒ¼/ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼)"
        api_key = config_manager.API_KEYS.get(current_api_key_name_state)
        limit_info = gemini_api.get_model_token_limits(current_model_name, api_key)
        if limit_info and 'input' in limit_info:
            return f"å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {token_count} / {limit_info['input']}"
        else:
            return f"å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {token_count}"
    except Exception as e:
        print(f"ãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨ˆç®—UIãƒãƒ³ãƒ‰ãƒ©ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: (ä¾‹å¤–ç™ºç”Ÿ)"
def handle_prime_for_deletion(chatbot_history: List[Dict[str, str]], evt: gr.SelectData):
    """ğŸ—‘ï¸ã‚¢ã‚¤ã‚³ãƒ³ã‚¯ãƒªãƒƒã‚¯ã‚’æ¤œçŸ¥ã—ã€å‰Šé™¤ã®æº–å‚™ï¼ˆãƒ—ãƒ©ã‚¤ãƒŸãƒ³ã‚°ï¼‰ã‚’è¡Œã†ã€‚"""
    if not evt.value:
        return -1, gr.update(visible=False), ""

    try:
        # href='#delete_action' ã‚’æŒã¤ãƒªãƒ³ã‚¯ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸå ´åˆã®ã¿ç¶šè¡Œ
        if '#delete_action' not in evt.value:
            # ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚ã€ãƒ—ãƒ©ã‚¤ãƒ çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ä½•ã‚‚ã—ãªã„
            return -1, gr.update(visible=False), ""

        clicked_index = evt.index if isinstance(evt.index, int) else evt.index[0]

        raw_content = chatbot_history[clicked_index].get('content', '')
        preview_content = re.sub('<[^<]+?>', '', raw_content).strip()
        preview_text = (preview_content[:20] + '...') if len(preview_content) > 20 else preview_content

        confirmation_text = f"âš ï¸ **ã€Œ{html.escape(preview_text)}ã€**ã‚’æœ¬å½“ã«å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ"

        return clicked_index, gr.update(visible=True), confirmation_text

    except Exception as e:
        print(f"å‰Šé™¤æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return -1, gr.update(visible=False), ""

def handle_confirm_delete(primed_index: int, character_name: str, api_history_limit: str):
    """ã€Œã¯ã„ã€å‰Šé™¤ã—ã¾ã™ã€ãƒœã‚¿ãƒ³ã®å‡¦ç†ã€‚"""
    if primed_index < 0:
        return gr.update(), gr.update(visible=False), -1

    log_f, _, _, _, _ = get_character_files_paths(character_name)
    raw_history = utils.load_chat_log(log_f, character_name)
    display_turns = _get_display_history_count(api_history_limit)
    visible_history = raw_history[-(display_turns*2):]

    if 0 <= primed_index < len(visible_history):
        message_to_delete = visible_history[primed_index]
        success = utils.delete_message_from_log(log_f, message_to_delete)
        if success:
            gr.Info("ç™ºè¨€ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
        else:
            gr.Error("ç™ºè¨€ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    else:
        gr.Error("å‰Šé™¤å¯¾è±¡ã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    new_raw_history = utils.load_chat_log(log_f, character_name)
    new_display_history = utils.format_history_for_gradio(new_raw_history[-(display_turns*2):])

    return new_display_history, gr.update(visible=False), -1

def handle_cancel_delete():
    """ã€Œã„ã„ãˆã€ã‚„ã‚ã¾ã™ã€ãƒœã‚¿ãƒ³ã®å‡¦ç†ã€‚"""
    gr.Info("å‰Šé™¤ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
    return gr.update(visible=False), -1
