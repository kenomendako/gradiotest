import shutil
import pandas as pd
import json
import traceback
import hashlib
import os
import re
from typing import List, Optional, Dict, Any, Tuple
import gradio as gr
import datetime
from PIL import Image
import threading
import filetype
import base64
import io
import uuid
from tools.image_tools import generate_image as generate_image_tool_func
import pytz


import gemini_api, config_manager, alarm_manager, character_manager, utils, constants
from agent.graph import generate_scenery_context
from timers import UnifiedTimer
from character_manager import get_character_files_paths, get_world_settings_path
from memory_manager import load_memory_data_safe, save_memory_data
from world_builder import get_world_data, save_world_data

DAY_MAP_EN_TO_JA = {"mon": "æœˆ", "tue": "ç«", "wed": "æ°´", "thu": "æœ¨", "fri": "é‡‘", "sat": "åœŸ", "sun": "æ—¥"}
DAY_MAP_JA_TO_EN = {v: k for k, v in DAY_MAP_EN_TO_JA.items()}


def _get_location_choices_for_ui(character_name: str) -> list:
    """
    UIã®ç§»å‹•å…ˆDropdownç”¨ã®ã€ã‚¨ãƒªã‚¢ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸé¸æŠè‚¢ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if not character_name: return []

    world_settings_path = get_world_settings_path(character_name)
    world_data = utils.parse_world_file(world_settings_path)

    if not world_data: return []

    choices = []
    for area_name in sorted(world_data.keys()):
        # ã‚¨ãƒªã‚¢è¦‹å‡ºã—ã‚’è¿½åŠ  (é¸æŠä¸å¯ã«ã™ã‚‹ãŸã‚å€¤ã¯å°‚ç”¨ID)
        choices.append((f"[{area_name}]", f"__AREA_HEADER_{area_name}"))

        places = world_data[area_name]
        for place_name in sorted(places.keys()):
            if place_name.startswith("__"): continue
            # ã‚·ãƒ³ãƒ—ãƒ«ãªå³çŸ¢å°è¨˜å·ã«å¤‰æ›´
            choices.append((f"\u00A0\u00A0â†’ {place_name}", place_name))

    return choices

def handle_initial_load():
    print("--- UIåˆæœŸåŒ–å‡¦ç†(handle_initial_load)ã‚’é–‹å§‹ã—ã¾ã™ ---")
    df_with_ids = render_alarms_as_dataframe()
    display_df, feedback_text = get_display_df(df_with_ids), "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„"
    char_dependent_outputs = handle_character_change(config_manager.initial_character_global, config_manager.initial_api_key_name_global)
    return (display_df, df_with_ids, feedback_text) + char_dependent_outputs

def handle_character_change(character_name: str, api_key_name: str):
    if not character_name:
        char_list = character_manager.get_character_list()
        character_name = char_list[0] if char_list else "Default"

    print(f"--- UIæ›´æ–°å¸ä»¤å¡”(handle_character_change)å®Ÿè¡Œ: {character_name} ---")
    config_manager.save_config("last_character", character_name)

    chat_history, mapping_list = reload_chat_log(character_name, config_manager.initial_api_history_limit_option_global)

    _, _, img_p, mem_p, notepad_p = get_character_files_paths(character_name)

    memory_str = json.dumps(load_memory_data_safe(mem_p), indent=2, ensure_ascii=False)
    profile_image = img_p if img_p and os.path.exists(img_p) else None
    notepad_content = load_notepad_content(character_name)
    api_key = config_manager.API_KEYS.get(api_key_name)

    # â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ãŒä¿®æ­£ã®æ ¸å¿ƒ â–¼â–¼â–¼
    # ã¾ãšã€UIã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ç§»å‹•å…ˆãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹
    locations_for_ui = _get_location_choices_for_ui(character_name)
    valid_location_ids = [value for _name, value in locations_for_ui]

    # æ¬¡ã«ã€ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ç¾åœ¨åœ°ã‚’å–å¾—
    current_location_from_file = utils.get_current_location(character_name)
    location_dd_val = current_location_from_file

    # å®‰å…¨è£…ç½®ï¼šä¿å­˜ã•ã‚Œã¦ã„ãŸå ´æ‰€ãŒã€ç¾åœ¨ã®æœ‰åŠ¹ãªå ´æ‰€ãƒªã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if current_location_from_file and current_location_from_file not in valid_location_ids:
        gr.Warning(f"æœ€å¾Œã«ã„ãŸå ´æ‰€ã€Œ{current_location_from_file}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç§»å‹•å…ˆã‚’é¸æŠã—ç›´ã—ã¦ãã ã•ã„ã€‚")
        # ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã®é¸æŠã‚’ä¸€æ—¦ãƒªã‚»ãƒƒãƒˆ
        location_dd_val = None

    # æƒ…æ™¯æå†™ã¨ç”»åƒã¯ã€UIã«è¨­å®šã™ã‚‹æœ‰åŠ¹ãªå ´æ‰€IDã«åŸºã¥ã„ã¦å–å¾—ã™ã‚‹
    current_location_name, _, scenery_text = generate_scenery_context(character_name, api_key)
    scenery_image_path = utils.find_scenery_image(character_name, location_dd_val)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    effective_settings = config_manager.get_effective_settings(character_name)
    all_models = ["ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"] + config_manager.AVAILABLE_MODELS_GLOBAL
    model_val = effective_settings["model_name"] if effective_settings["model_name"] != config_manager.initial_model_global else "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"
    voice_display_name = config_manager.SUPPORTED_VOICES.get(effective_settings.get("voice_id", "vindemiatrix"), list(config_manager.SUPPORTED_VOICES.values())[0])
    voice_style_prompt_val = effective_settings.get("voice_style_prompt", "")

    return (
        character_name, chat_history, mapping_list, "", profile_image, memory_str,
        character_name, character_name, notepad_content,
        gr.update(choices=locations_for_ui, value=location_dd_val), # UIç”¨ã®ãƒªã‚¹ãƒˆã¨ã€æ¤œè¨¼æ¸ˆã¿ã®å€¤ã‚’è¨­å®š
        current_location_name, scenery_text,
        gr.update(choices=all_models, value=model_val),
        voice_display_name, voice_style_prompt_val,
        effective_settings["add_timestamp"], effective_settings["send_thoughts"],
        effective_settings["send_notepad"], effective_settings["use_common_prompt"],
        effective_settings["send_core_memory"], effective_settings["send_scenery"],
        f"â„¹ï¸ *ç¾åœ¨é¸æŠä¸­ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{character_name}ã€ã«ã®ã¿é©ç”¨ã•ã‚Œã‚‹è¨­å®šã§ã™ã€‚*", scenery_image_path
    )

def handle_save_char_settings(character_name: str, model_name: str, voice_name: str, voice_style_prompt: str, add_timestamp: bool, send_thoughts: bool, send_notepad: bool, use_common_prompt: bool, send_core_memory: bool, send_scenery: bool):
    if not character_name: gr.Warning("è¨­å®šã‚’ä¿å­˜ã™ã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return
    new_settings = {
        "model_name": model_name if model_name != "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ" else None,
        "voice_id": next((k for k, v in config_manager.SUPPORTED_VOICES.items() if v == voice_name), None),
        "voice_style_prompt": voice_style_prompt.strip(),
        "add_timestamp": bool(add_timestamp), "send_thoughts": bool(send_thoughts), "send_notepad": bool(send_notepad),
        "use_common_prompt": bool(use_common_prompt), "send_core_memory": bool(send_core_memory), "send_scenery": bool(send_scenery),
    }
    try:
        char_config_path = os.path.join(constants.CHARACTERS_DIR, character_name, "character_config.json")
        config = {}
        if os.path.exists(char_config_path) and os.path.getsize(char_config_path) > 0:
            with open(char_config_path, "r", encoding="utf-8") as f: config = json.load(f)
        if "override_settings" not in config: config["override_settings"] = {}
        config["override_settings"].update(new_settings)
        config["last_updated"] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with open(char_config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        gr.Info(f"ã€Œ{character_name}ã€ã®å€‹åˆ¥è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e: gr.Error(f"å€‹åˆ¥è¨­å®šã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); traceback.print_exc()

def handle_context_settings_change(character_name: str, api_key_name: str, api_history_limit: str, add_timestamp: bool, send_thoughts: bool, send_notepad: bool, use_common_prompt: bool, send_core_memory: bool, send_scenery: bool):
    if not character_name or not api_key_name: return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: -"
    return gemini_api.count_input_tokens(
        character_name=character_name, api_key_name=api_key_name, parts=[],
        api_history_limit=api_history_limit,
        add_timestamp=add_timestamp, send_thoughts=send_thoughts, send_notepad=send_notepad,
        use_common_prompt=use_common_prompt, send_core_memory=send_core_memory, send_scenery=send_scenery
    )

def update_token_count_on_input(character_name: str, api_key_name: str, api_history_limit: str, textbox_content: str, file_list: list, add_timestamp: bool, send_thoughts: bool, send_notepad: bool, use_common_prompt: bool, send_core_memory: bool, send_scenery: bool):
    if not character_name or not api_key_name: return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: -"
    parts_for_api = []
    if textbox_content: parts_for_api.append(textbox_content)
    if file_list:
        for file_obj in file_list: parts_for_api.append(Image.open(file_obj.name))
    return gemini_api.count_input_tokens(
        character_name=character_name, api_key_name=api_key_name, parts=parts_for_api,
        api_history_limit=api_history_limit,
        add_timestamp=add_timestamp, send_thoughts=send_thoughts, send_notepad=send_notepad,
        use_common_prompt=use_common_prompt, send_core_memory=send_core_memory, send_scenery=send_scenery
    )

def handle_message_submission(*args: Any):
    (textbox_content, current_character_name, current_api_key_name_state,
     file_input_list, api_history_limit_state, debug_mode_state) = args
    user_prompt_from_textbox = textbox_content.strip() if textbox_content else ""
    if not user_prompt_from_textbox and not file_input_list:
        chatbot_history, mapping_list = reload_chat_log(current_character_name, api_history_limit_state)
        return chatbot_history, mapping_list, gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update()

    effective_settings = config_manager.get_effective_settings(current_character_name)
    add_timestamp_checkbox = effective_settings.get("add_timestamp", False)

    chatbot_history, _ = reload_chat_log(current_character_name, api_history_limit_state)

    log_message_parts = []
    if user_prompt_from_textbox:
        timestamp = f"\n\n{datetime.datetime.now().strftime('%Y-%m-%d (%a) %H:%M:%S')}" if add_timestamp_checkbox else ""
        processed_user_message = user_prompt_from_textbox + timestamp
        chatbot_history.append((processed_user_message, None))
        log_message_parts.append(processed_user_message)
    if file_input_list:
        for file_obj in file_input_list:
            filepath, filename = file_obj.name, os.path.basename(file_obj.name)
            chatbot_history.append(((filepath, filename), None))
            log_message_parts.append(f"[ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜: {filepath}]")

    chatbot_history.append((None, "æ€è€ƒä¸­... â–Œ"))

    yield (chatbot_history, [], gr.update(value=""), gr.update(value=None), gr.update(), gr.update(), gr.update(), gr.update(), gr.update())

    response_data = {}
    try:
        agent_args = (
            textbox_content, current_character_name, current_api_key_name_state,
            file_input_list, api_history_limit_state, debug_mode_state
        )
        response_data = gemini_api.invoke_nexus_agent(*agent_args)
    except Exception as e:
        traceback.print_exc()
        response_data = {"response": f"[UIãƒãƒ³ãƒ‰ãƒ©ã‚¨ãƒ©ãƒ¼: {e}]", "location_name": "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰", "scenery": "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"}

    final_response_text = response_data.get("response", "")
    location_name, scenery_text = response_data.get("location_name", "ï¼ˆå–å¾—å¤±æ•—ï¼‰"), response_data.get("scenery", "ï¼ˆå–å¾—å¤±æ•—ï¼‰")

    if not final_response_text or not final_response_text.strip():
        print("--- è­¦å‘Š: AIã‹ã‚‰ã®å¿œç­”ãŒç©ºã®ãŸã‚ã€å¾Œç¶šå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ ---")
        formatted_history, new_mapping_list = reload_chat_log(current_character_name, api_history_limit_state)
        new_alarm_df_with_ids = render_alarms_as_dataframe()
        new_display_df = get_display_df(new_alarm_df_with_ids)

        current_location_id = utils.get_current_location(current_character_name)
        scenery_image_path = utils.find_scenery_image(current_character_name, current_location_id)

        yield (formatted_history, new_mapping_list, gr.update(), gr.update(value=None),
               location_name, scenery_text, new_alarm_df_with_ids,
               new_display_df, scenery_image_path)
        return

    scenery_image_path = None
    if not location_name.startswith("ï¼ˆ"):
        # save_scenery_cache ã®å‘¼ã³å‡ºã—ã‚’å‰Šé™¤ã€‚ä¿å­˜ã¯ generate_scenery_context ãŒè²¬ä»»ã‚’æŒã¤ã€‚
        current_location_id = utils.get_current_location(current_character_name)
        scenery_image_path = utils.find_scenery_image(current_character_name, current_location_id)

    log_f, _, _, _, _ = get_character_files_paths(current_character_name)
    final_log_message = "\n\n".join(log_message_parts).strip()
    if final_log_message:
        user_header = utils._get_user_header_from_log(log_f, current_character_name)
        utils.save_message_to_log(log_f, user_header, final_log_message)

    utils.save_message_to_log(log_f, f"## {current_character_name}:", final_response_text)

    formatted_history, new_mapping_list = reload_chat_log(current_character_name, api_history_limit_state)
    new_alarm_df_with_ids = render_alarms_as_dataframe()
    new_display_df = get_display_df(new_alarm_df_with_ids)

    yield (formatted_history, new_mapping_list, gr.update(), gr.update(value=None),
           location_name, scenery_text, new_alarm_df_with_ids,
           new_display_df, scenery_image_path)

def handle_scenery_refresh(character_name: str, api_key_name: str) -> Tuple[str, str, Optional[str]]:
    """ã€Œæƒ…æ™¯ã‚’æ›´æ–°ã€ãƒœã‚¿ãƒ³å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«å†ç”Ÿæˆã™ã‚‹ã€‚"""
    if not character_name or not api_key_name:
        return "ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªé¸æŠã§ã™ï¼‰", "ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªé¸æŠã§ã™ï¼‰", None

    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key:
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", None

    gr.Info(f"ã€Œ{character_name}ã€ã®ç¾åœ¨ã®æƒ…æ™¯ã‚’å¼·åˆ¶çš„ã«å†ç”Ÿæˆã—ã¦ã„ã¾ã™...")

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šè²¬å‹™ã‚’ agent/graph.py ã«å§”è­² â–¼â–¼â–¼
    location_name, _, scenery_text = generate_scenery_context(character_name, api_key, force_regenerate=True)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    if not location_name.startswith("ï¼ˆ"):
        gr.Info("æƒ…æ™¯ã‚’å†ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        scenery_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))
    else:
        gr.Error("æƒ…æ™¯ã®å†ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        scenery_image_path = None

    return location_name, scenery_text, scenery_image_path

def handle_location_change(character_name: str, selected_value: str, api_key_name: str) -> Tuple[str, str, Optional[str]]:
    # â–¼â–¼â–¼ ä¿®æ­£ãƒ–ãƒ­ãƒƒã‚¯ã“ã“ã‹ã‚‰ â–¼â–¼â–¼
    if not selected_value or selected_value.startswith("__AREA_HEADER_"):
        # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã‹ã€å€¤ãŒãªã„å ´åˆã¯ä½•ã‚‚ã—ãªã„
        # ç¾åœ¨ã®çŠ¶æ…‹ã‚’ãã®ã¾ã¾è¿”ã™
        location_name, _, scenery_text = generate_scenery_context(character_name, config_manager.API_KEYS.get(api_key_name))
        scenery_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))
        return location_name, scenery_text, scenery_image_path

    location_id = selected_value
    # â–²â–²â–² ä¿®æ­£ãƒ–ãƒ­ãƒƒã‚¯ã“ã“ã¾ã§ â–²â–²â–²

    from tools.space_tools import set_current_location
    print(f"--- UIã‹ã‚‰ã®å ´æ‰€å¤‰æ›´å‡¦ç†é–‹å§‹: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼='{character_name}', ç§»å‹•å…ˆID='{location_id}' ---")

    # ç¾åœ¨ã®è¡¨ç¤ºå†…å®¹ã‚’ä¸€æ™‚çš„ã«å–å¾—
    scenery_cache = utils.load_scenery_cache(character_name)
    current_loc_name = scenery_cache.get("location_name", "ï¼ˆå ´æ‰€ä¸æ˜ï¼‰")
    scenery_text = scenery_cache.get("scenery_text", "ï¼ˆæƒ…æ™¯ä¸æ˜ï¼‰")
    current_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))

    if not character_name or not location_id:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ç§»å‹•å…ˆã®å ´æ‰€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return current_loc_name, scenery_text, current_image_path

    # ã¾ãšå ´æ‰€ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ã‚’æ›´æ–°
    result = set_current_location.func(location_id=location_id, character_name=character_name)
    if "Success" not in result:
        gr.Error(f"å ´æ‰€ã®å¤‰æ›´ã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
        return current_loc_name, scenery_text, current_image_path

    gr.Info(f"å ´æ‰€ã‚’ã€Œ{location_id}ã€ã«ç§»å‹•ã—ã¾ã—ãŸã€‚æƒ…æ™¯ã‚’æ›´æ–°ã—ã¾ã™...")

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒ â–¼â–¼â–¼
    # ç§»å‹•å¾Œã«ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è€ƒæ…®ã—ãŸæƒ…æ™¯å–å¾—é–¢æ•°ã‚’å‘¼ã³å‡ºã™
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key:
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", None

    new_location_name, _, new_scenery_text = generate_scenery_context(character_name, api_key)
    new_image_path = utils.find_scenery_image(character_name, location_id)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    return new_location_name, new_scenery_text, new_image_path

def handle_add_new_character(character_name: str):
    char_list = character_manager.get_character_list()
    if not character_name or not character_name.strip():
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    safe_name = re.sub(r'[\\/*?:"<>|]', "", character_name).strip()
    if not safe_name:
        gr.Warning("ç„¡åŠ¹ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§ã™ã€‚"); return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    if character_manager.ensure_character_files(safe_name):
        gr.Info(f"æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã•ã‚“ã‚’è¿ãˆã¾ã—ãŸï¼"); new_char_list = character_manager.get_character_list(); return gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(value="")
    else:
        gr.Error(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"); return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value=character_name)

def _get_display_history_count(api_history_limit_value: str) -> int: return int(api_history_limit_value) if api_history_limit_value.isdigit() else constants.UI_HISTORY_MAX_LIMIT

def handle_chatbot_selection(character_name: str, api_history_limit_state: str, mapping_list: list, evt: gr.SelectData):
    if not character_name or evt.index is None or not mapping_list: return None, gr.update(visible=False)
    try:
        clicked_ui_index = evt.index[0]
        if not (0 <= clicked_ui_index < len(mapping_list)):
            gr.Warning(f"ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ (UI index {clicked_ui_index} out of bounds for mapping list size {len(mapping_list)})."); return None, gr.update(visible=False)

        log_f, _, _, _, _ = get_character_files_paths(character_name)
        raw_history = utils.load_chat_log(log_f, character_name)
        display_turns = _get_display_history_count(api_history_limit_state)
        visible_raw_history = raw_history[-(display_turns * 2):]

        original_log_index = mapping_list[clicked_ui_index]
        if 0 <= original_log_index < len(visible_raw_history):
            return visible_raw_history[original_log_index], gr.update(visible=True)
        else:
            gr.Warning(f"ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ (Original log index {original_log_index} out of bounds for visible history size {len(visible_raw_history)})."); return None, gr.update(visible=False)
    except Exception as e:
        print(f"ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆé¸æŠä¸­ã®ã‚¨ãƒ©ãƒ¼: {e}"); traceback.print_exc()
        return None, gr.update(visible=False)

def handle_delete_button_click(message_to_delete: Optional[Dict[str, str]], character_name: str, api_history_limit: str):
    if not message_to_delete:
        return gr.update(), gr.update(), None, gr.update(visible=False)

    log_f, _, _, _, _ = get_character_files_paths(character_name)
    if utils.delete_message_from_log(log_f, message_to_delete, character_name):
        gr.Info("ãƒ­ã‚°ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
    else:
        gr.Error("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    history, mapping_list = reload_chat_log(character_name, api_history_limit)
    return history, mapping_list, None, gr.update(visible=False)

def reload_chat_log(character_name: Optional[str], api_history_limit_value: str):
    if not character_name:
        return [], []

    log_f,_,_,_,_ = get_character_files_paths(character_name)
    if not log_f or not os.path.exists(log_f):
        return [], []

    full_raw_history = utils.load_chat_log(log_f, character_name)
    display_turns = _get_display_history_count(api_history_limit_value)
    visible_history = full_raw_history[-(display_turns * 2):]
    history, mapping_list = utils.format_history_for_gradio(visible_history, character_name)
    return history, mapping_list

def handle_save_memory_click(character_name, json_string_data):
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return gr.update()
    try: return save_memory_data(character_name, json_string_data)
    except Exception as e: gr.Error(f"è¨˜æ†¶ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return gr.update()

def handle_reload_memory(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return "{}"
    gr.Info(f"ã€Œ{character_name}ã€ã®è¨˜æ†¶ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚"); _, _, _, memory_json_path, _ = get_character_files_paths(character_name); return json.dumps(load_memory_data_safe(memory_json_path), indent=2, ensure_ascii=False)

def load_notepad_content(character_name: str) -> str:
    if not character_name: return ""
    _, _, _, _, notepad_path = get_character_files_paths(character_name)
    if notepad_path and os.path.exists(notepad_path):
        with open(notepad_path, "r", encoding="utf-8") as f: return f.read()
    return ""

def handle_save_notepad_click(character_name: str, content: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return content
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path: gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚"); return content
    lines = [f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}] {line.strip()}" if line.strip() and not re.match(r"^\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}\]", line.strip()) else line.strip() for line in content.strip().split('\n') if line.strip()]
    final_content = "\n".join(lines)
    try:
        with open(notepad_path, "w", encoding="utf-8") as f: f.write(final_content + ('\n' if final_content else ''))
        gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"); return final_content
    except Exception as e: gr.Error(f"ãƒ¡ãƒ¢å¸³ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"); return content

def handle_clear_notepad_click(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return ""
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path: gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚"); return ""
    try:
        with open(notepad_path, "w", encoding="utf-8") as f: f.write("")
        gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ç©ºã«ã—ã¾ã—ãŸã€‚"); return ""
    except Exception as e: gr.Error(f"ãƒ¡ãƒ¢å¸³ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}"); return f"ã‚¨ãƒ©ãƒ¼: {e}"

def handle_reload_notepad(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return ""
    content = load_notepad_content(character_name); gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚"); return content

def render_alarms_as_dataframe():
    alarms = sorted(alarm_manager.load_alarms(), key=lambda x: x.get("time", "")); all_rows = []
    for a in alarms:
        schedule_display = "å˜ç™º"
        if a.get("date"):
            try:
                date_obj, today = datetime.datetime.strptime(a["date"], "%Y-%m-%d").date(), datetime.date.today()
                if date_obj == today: schedule_display = "ä»Šæ—¥"
                elif date_obj == today + datetime.timedelta(days=1): schedule_display = "æ˜æ—¥"
                else: schedule_display = date_obj.strftime("%m/%d")
            except: schedule_display = "æ—¥ä»˜ä¸å®š"
        elif a.get("days"): schedule_display = ",".join([DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in a["days"]])
        all_rows.append({"ID": a.get("id"), "çŠ¶æ…‹": a.get("enabled", False), "æ™‚åˆ»": a.get("time"), "äºˆå®š": schedule_display, "ã‚­ãƒ£ãƒ©": a.get("character"), "å†…å®¹": a.get("context_memo") or ""})
    return pd.DataFrame(all_rows, columns=["ID", "çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])

def get_display_df(df_with_id: pd.DataFrame):
    if df_with_id is None or df_with_id.empty: return pd.DataFrame(columns=["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])
    return df_with_id[["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"]] if 'ID' in df_with_id.columns else df_with_id

def handle_alarm_selection(evt: gr.SelectData, df_with_id: pd.DataFrame) -> List[str]:
    if not hasattr(evt, 'index') or evt.index is None or df_with_id is None or df_with_id.empty: return []
    indices = evt.index if isinstance(evt.index, list) else [evt.index]
    return [str(df_with_id.iloc[r[0] if isinstance(r, tuple) else r]['ID']) for r in indices if isinstance(r, (int, tuple)) and 0 <= (r[0] if isinstance(r, tuple) else r) < len(df_with_id)]

def handle_alarm_selection_for_all_updates(evt: gr.SelectData, df_with_id: pd.DataFrame):
    selected_ids = handle_alarm_selection(evt, df_with_id)
    feedback_text = "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„" if not selected_ids else f"{len(selected_ids)} ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠä¸­"
    all_chars, default_char = character_manager.get_character_list(), "Default"
    if all_chars: default_char = all_chars[0]
    if len(selected_ids) == 1:
        alarm = next((a for a in alarm_manager.load_alarms() if a.get("id") == selected_ids[0]), None)
        if alarm:
            h, m = alarm.get("time", "08:00").split(":")
            days_ja = [DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in alarm.get("days", [])]
            form_updates = ("ã‚¢ãƒ©ãƒ¼ãƒ æ›´æ–°", alarm.get("context_memo", ""), "", alarm.get("character", default_char), days_ja, alarm.get("is_emergency", False), h, m, selected_ids[0])
        else: form_updates = ("ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", default_char, [], False, "08", "00", None)
    else: form_updates = ("ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", default_char, [], False, "08", "00", None)
    return (selected_ids, feedback_text) + form_updates

def toggle_selected_alarms_status(selected_ids: list, target_status: bool):
    if not selected_ids: gr.Warning("çŠ¶æ…‹ã‚’å¤‰æ›´ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        current_alarms = alarm_manager.load_alarms()
        modified = any(a.get("id") in selected_ids and a.update({"enabled": target_status}) is None for a in current_alarms)
        if modified:
            alarm_manager.alarms_data_global = current_alarms; alarm_manager.save_alarms()
            gr.Info(f"{len(selected_ids)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã®çŠ¶æ…‹ã‚’ã€Œ{'æœ‰åŠ¹' if target_status else 'ç„¡åŠ¹'}ã€ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚")
    new_df_with_ids = render_alarms_as_dataframe(); return new_df_with_ids, get_display_df(new_df_with_ids)

def handle_delete_selected_alarms(selected_ids: list):
    if not selected_ids: gr.Warning("å‰Šé™¤ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        for sid in selected_ids: alarm_manager.delete_alarm(str(sid))
    new_df_with_ids = render_alarms_as_dataframe(); return new_df_with_ids, get_display_df(new_df_with_ids)

def handle_add_or_update_alarm(editing_id, h, m, char, theme, prompt, days_ja, is_emergency):
    from tools.alarm_tools import set_personal_alarm
    context = theme or prompt or "æ™‚é–“ã«ãªã‚Šã¾ã—ãŸ"; days_en = [DAY_MAP_JA_TO_EN.get(d) for d in days_ja if d in DAY_MAP_JA_TO_EN]
    if editing_id: alarm_manager.delete_alarm(editing_id); gr.Info(f"ã‚¢ãƒ©ãƒ¼ãƒ ID:{editing_id}ã‚’æ›´æ–°ã—ã¾ã™ã€‚")
    set_personal_alarm.func(time=f"{h}:{m}", context_memo=context, character_name=char, days=days_en, date=None, is_emergency=is_emergency)
    new_df_with_ids, all_chars = render_alarms_as_dataframe(), character_manager.get_character_list()
    default_char = all_chars[0] if all_chars else "Default"
    return new_df_with_ids, get_display_df(new_df_with_ids), "ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", gr.update(choices=all_chars, value=default_char), [], False, "08", "00", None

def handle_timer_submission(timer_type, duration, work, brk, cycles, char, work_theme, brk_theme, api_key_name, normal_theme):
    if not char or not api_key_name: return "ã‚¨ãƒ©ãƒ¼ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
    try:
        timer = UnifiedTimer(timer_type, float(duration or 0), float(work or 0), float(brk or 0), int(cycles or 0), char, work_theme, brk_theme, api_key_name, normal_theme=normal_theme)
        timer.start(); gr.Info(f"{timer_type}ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚"); return f"{timer_type}ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚"
    except Exception as e: return f"ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}"

def handle_rag_update_button_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); return
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"): gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    gr.Info(f"ã€Œ{character_name}ã€ã®RAGç´¢å¼•ã®æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã™...")
    import rag_manager
    threading.Thread(target=lambda: rag_manager.create_or_update_index(character_name, api_key)).start()

def _run_core_memory_update(character_name: str, api_key: str):
    print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ (Character: {character_name}) ---")
    try:
        from tools import memory_tools
        result = memory_tools.summarize_and_save_core_memory.func(character_name=character_name, api_key=api_key)
        print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†å®Œäº† --- çµæœ: {result}")
    except Exception: print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¨ãƒ©ãƒ¼] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ ---"); traceback.print_exc()

def handle_core_memory_update_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); return
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"): gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    gr.Info(f"ã€Œ{character_name}ã€ã®ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹ã—ã¾ã—ãŸã€‚")
    threading.Thread(target=_run_core_memory_update, args=(character_name, api_key)).start()

def update_model_state(model): config_manager.save_config("last_model", model); return model

def update_api_key_state(api_key_name):
    config_manager.save_config("last_api_key_name", api_key_name)
    gr.Info(f"APIã‚­ãƒ¼ã‚’ '{api_key_name}' ã«è¨­å®šã—ã¾ã—ãŸã€‚")
    return api_key_name

def update_api_history_limit_state_and_reload_chat(limit_ui_val: str, character_name: Optional[str]):
    key = next((k for k, v in constants.API_HISTORY_LIMIT_OPTIONS.items() if v == limit_ui_val), "all")
    config_manager.save_config("last_api_history_limit_option", key)
    history, mapping_list = reload_chat_log(character_name, key)
    return key, history, mapping_list

def handle_play_audio_button_click(selected_message: Optional[Dict[str, str]], character_name: str, api_key_name: str):
    if not selected_message:
        gr.Warning("å†ç”Ÿã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        # â˜… ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã¯å¤‰æ›´ã—ãªã„ã®ã§ã€å…ƒã®çŠ¶æ…‹ã‚’è¿”ã™
        yield gr.update(visible=False), gr.update(interactive=True), gr.update(interactive=True)
        return

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šyield ã‚’ä½¿ã£ãŸæ®µéšçš„ãªUIæ›´æ–° â–¼â–¼â–¼
    # 1. ã¾ãšã€Œç”Ÿæˆä¸­ã€ã®çŠ¶æ…‹ã‚’UIã«å³æ™‚åæ˜ ã•ã›ã‚‹
    yield (
        gr.update(visible=False), # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ä¸€æ—¦éš ã™
        gr.update(value="éŸ³å£°ç”Ÿæˆä¸­... â–Œ", interactive=False), # å†ç”Ÿãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–
        gr.update(interactive=False)  # è©¦è´ãƒœã‚¿ãƒ³ã‚‚ç„¡åŠ¹åŒ–
    )

    try:
        raw_text = utils.extract_raw_text_from_html(selected_message.get("content"))
        text_to_speak = utils.remove_thoughts_from_text(raw_text)
        if not text_to_speak:
            gr.Info("ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯éŸ³å£°ã§å†ç”Ÿã§ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        effective_settings = config_manager.get_effective_settings(character_name)
        voice_id, voice_style_prompt = effective_settings.get("voice_id", "iapetus"), effective_settings.get("voice_style_prompt", "")
        api_key = config_manager.API_KEYS.get(api_key_name)
        if not api_key:
            gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return

        from audio_manager import generate_audio_from_text
        gr.Info(f"ã€Œ{character_name}ã€ã®å£°ã§éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        audio_filepath = generate_audio_from_text(text_to_speak, api_key, voice_id, voice_style_prompt)

        if audio_filepath:
            gr.Info("å†ç”Ÿã—ã¾ã™ã€‚")
            # 2. æˆåŠŸã—ãŸã‚‰ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¡¨ç¤ºã—ã¦å†ç”Ÿã‚’é–‹å§‹
            yield gr.update(value=audio_filepath, visible=True), gr.update(), gr.update()
        else:
            gr.Error("éŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    finally:
        # 3. æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšã€å¿…ãšæœ€å¾Œã«ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’å…ƒã«æˆ»ã™
        yield (
            gr.update(), # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®çŠ¶æ…‹ã¯ãã®ã¾ã¾
            gr.update(value="ğŸ”Š é¸æŠã—ãŸç™ºè¨€ã‚’å†ç”Ÿ", interactive=True), # å†ç”Ÿãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
            gr.update(interactive=True)  # è©¦è´ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
        )

def handle_voice_preview(selected_voice_name: str, voice_style_prompt: str, text_to_speak: str, api_key_name: str):
    if not selected_voice_name or not text_to_speak or not api_key_name:
        gr.Warning("å£°ã€ãƒ†ã‚­ã‚¹ãƒˆã€APIã‚­ãƒ¼ãŒã™ã¹ã¦é¸æŠã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        yield gr.update(visible=False), gr.update(interactive=True), gr.update(interactive=True)
        return

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šyield ã‚’ä½¿ã£ãŸæ®µéšçš„ãªUIæ›´æ–° â–¼â–¼â–¼
    yield (
        gr.update(visible=False),
        gr.update(interactive=False),
        gr.update(value="ç”Ÿæˆä¸­...", interactive=False)
    )

    try:
        voice_id = next((key for key, value in config_manager.SUPPORTED_VOICES.items() if value == selected_voice_name), None)
        api_key = config_manager.API_KEYS.get(api_key_name)
        if not voice_id or not api_key:
            gr.Warning("å£°ã¾ãŸã¯APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚")
            return

        from audio_manager import generate_audio_from_text
        gr.Info(f"å£°ã€Œ{selected_voice_name}ã€ã§éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        audio_filepath = generate_audio_from_text(text_to_speak, api_key, voice_id, voice_style_prompt)

        if audio_filepath:
            gr.Info("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å†ç”Ÿã—ã¾ã™ã€‚")
            yield gr.update(value=audio_filepath, visible=True), gr.update(), gr.update()
        else:
            gr.Error("éŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    finally:
        # æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšã€å¿…ãšæœ€å¾Œã«ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’å…ƒã«æˆ»ã™
        yield (
            gr.update(),
            gr.update(interactive=True),
            gr.update(value="è©¦è´", interactive=True)
        )

def handle_generate_or_regenerate_scenery_image(character_name: str, api_key_name: str, style_choice: str) -> Optional[str]:
    """ã€Œæƒ…æ™¯ç”»åƒã‚’ç”Ÿæˆ/æ›´æ–°ã€ãƒœã‚¿ãƒ³å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ã€‚å¸¸ã«åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«åã§ä¸Šæ›¸ãä¿å­˜ã™ã‚‹ã€‚"""
    if not character_name or not api_key_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return None

    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key:
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

    # â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ãŒä¿®æ­£ã®æ ¸å¿ƒ â–¼â–¼â–¼
    location_id = utils.get_current_location(character_name)
    existing_image_path = utils.find_scenery_image(character_name, location_id)

    if not location_id:
        gr.Warning("ç¾åœ¨åœ°ãŒç‰¹å®šã§ãã¾ã›ã‚“ã€‚")
        # æ—¢å­˜ã®ç”»åƒãŒã‚ã‚Œã°ãã‚Œã‚’è¿”ã—ã€ãªã‘ã‚Œã°Noneã‚’è¿”ã™
        return existing_image_path
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    # --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã®ãƒ­ã‚¸ãƒƒã‚¯ ---
    char_base_path = os.path.join(constants.CHARACTERS_DIR, character_name)
    world_settings_path = character_manager.get_world_settings_path(character_name)
    prompt_cache_path = os.path.join(char_base_path, "cache", "image_prompts.json")
    structural_prompt = ""

    try:
        # ä¸–ç•Œè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒ.txtã«å¤‰æ›´ã•ã‚ŒãŸã“ã¨ã‚’æƒ³å®šã—ã€æ–°ã—ã„ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½¿ã†
        world_settings = utils.parse_world_file(world_settings_path)
        if not world_settings:
            gr.Error("ä¸–ç•Œè¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return existing_image_path

        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‹ã‚‰å ´æ‰€ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹
        space_text = None
        for area, places in world_settings.items():
            if location_id in places:
                space_text = places[location_id]
                break

        if not space_text:
            gr.Error("ç¾åœ¨ã®å ´æ‰€ã®å®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return existing_image_path

        current_hash = hashlib.md5(space_text.encode('utf-8')).hexdigest()

        with open(prompt_cache_path, 'r', encoding='utf-8') as f:
            prompt_cache = json.load(f)

        cached_entry = prompt_cache.get("prompts", {}).get(location_id, {})
        cached_hash = cached_entry.get("source_hash")

        if current_hash == cached_hash and cached_entry.get("prompt_text"):
            structural_prompt = cached_entry["prompt_text"]
            print(f"--- [ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥HIT] å ´æ‰€ '{location_id}' ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ä½¿ç”¨ã—ã¾ã™ ---")
        else:
            print(f"--- [ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥MISS] å ´æ‰€ '{location_id}' ã®å®šç¾©ãŒå¤‰æ›´ã•ã‚ŒãŸãŸã‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†ç”Ÿæˆã—ã¾ã™ ---")
            from agent.graph import get_configured_llm
            translator_llm = get_configured_llm("gemini-2.5-flash", api_key)

            translation_prompt_text = (
                "You are a professional translator for an image generation AI. "
                "Your task is to read the following free-form text, which describes a location, "
                "and convert it into a concise, visually descriptive paragraph in English. "
                "Focus strictly on physical, visible attributes like structure, objects, materials, and lighting. "
                "Do not include any narrative, story elements, or metaphors. Output only the resulting English paragraph.\n\n"
                f"Location Description:\n{space_text}"
            )

            structural_prompt = translator_llm.invoke(translation_prompt_text).content.strip()

            if "prompts" not in prompt_cache: prompt_cache["prompts"] = {}
            prompt_cache["prompts"][location_id] = { "source_hash": current_hash, "prompt_text": structural_prompt }
            with open(prompt_cache_path, 'w', encoding='utf-8') as f:
                json.dump(prompt_cache, f, indent=2, ensure_ascii=False)
            print(f"  - å ´æ‰€ '{location_id}' ã®æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        gr.Error(f"ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()
        return existing_image_path

    if not structural_prompt:
        gr.Error("ç”»åƒç”Ÿæˆã®å…ƒã¨ãªã‚‹æ§‹é€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return existing_image_path

    # --- æœ€çµ‚çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®çµ„ã¿ç«‹ã¦ã¨ç”»åƒç”Ÿæˆ ---
    now = datetime.datetime.now()
    time_of_day = utils.get_time_of_day(now.hour); season = utils.get_season(now.month)
    dynamic_prompt = f"The current season is {season}, and the time of day is {time_of_day}."

    style_prompts = {
        "å†™çœŸé¢¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)": "An ultra-detailed, photorealistic masterpiece with cinematic lighting.",
        "ã‚¤ãƒ©ã‚¹ãƒˆé¢¨": "A beautiful and detailed anime-style illustration, pixiv contest winner.",
        "ã‚¢ãƒ‹ãƒ¡é¢¨": "A high-quality screenshot from a modern animated film.",
        "æ°´å½©ç”»é¢¨": "A gentle and emotional watercolor painting."
    }
    base_prompt = style_prompts.get(style_choice, style_prompts["å†™çœŸé¢¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)"])
    negative_prompt = "Absolutely no text, letters, characters, signatures, or watermarks of any kind should be present in the image. Do not include people."

    prompt = f"{base_prompt} {negative_prompt} Depict the following scene: {structural_prompt} {dynamic_prompt}"
    gr.Info(f"ã€Œ{style_choice}ã€ã§ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™...")

    result = generate_image_tool_func.func(prompt=prompt, character_name=character_name, api_key=api_key)

    # --- ç”Ÿæˆç”»åƒã®ä¿å­˜ã¨UIæ›´æ–° ---
    if "Generated Image:" in result:
        generated_path = result.replace("[Generated Image: ", "").replace("]", "").strip()
        if os.path.exists(generated_path):
            save_dir = os.path.join(constants.CHARACTERS_DIR, character_name, "spaces", "images")
            now = datetime.datetime.now()

            cache_key = f"{location_id}_{utils.get_season(now.month)}_{utils.get_time_of_day(now.hour)}"
            specific_filename = f"{cache_key}.png"
            specific_path = os.path.join(save_dir, specific_filename)

            if os.path.exists(specific_path):
                os.remove(specific_path)

            shutil.move(generated_path, specific_path)
            print(f"--- æƒ…æ™¯ç”»åƒã‚’ç”Ÿæˆã—ã€ä¿å­˜ã—ã¾ã—ãŸ: {specific_path} ---")

            gr.Info("ç”»åƒã‚’ç”Ÿæˆ/æ›´æ–°ã—ã¾ã—ãŸã€‚")
            return specific_path
        else:
            gr.Error("ç”»åƒã®ç”Ÿæˆã«ã¯æˆåŠŸã—ã¾ã—ãŸãŒã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return existing_image_path
    else:
        gr.Error(f"ç”»åƒã®ç”Ÿæˆ/æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIã®å¿œç­”: {result}")
        return existing_image_path

def handle_api_connection_test(api_key_name: str):
    """APIã‚­ãƒ¼ã‚’ä½¿ã£ã¦ã€Nexus ArkãŒå¿…è¦ã¨ã™ã‚‹å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹"""
    if not api_key_name:
        gr.Warning("ãƒ†ã‚¹ãƒˆã™ã‚‹APIã‚­ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"):
        gr.Error(f"APIã‚­ãƒ¼ '{api_key_name}' ã¯ç„¡åŠ¹ã§ã™ã€‚config.jsonã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    gr.Info(f"APIã‚­ãƒ¼ '{api_key_name}' ã‚’ä½¿ã£ã¦ã€å¿…é ˆãƒ¢ãƒ‡ãƒ«ã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã„ã¾ã™...")

    # ã“ã“ã§ã¯gemini_apiã‚’ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹
    import google.generativeai as genai

    # ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
    required_models = {
        "models/gemini-1.5-pro-latest": "é€šå¸¸ãƒãƒ£ãƒƒãƒˆ",
        "models/gemini-1.5-flash-latest": "æƒ…æ™¯æå†™ç”Ÿæˆ",
        "models/gemini-1.0-pro-vision-latest": "ç”»åƒç”Ÿæˆ" # ä»®
    }

    results = []
    all_ok = True

    try:
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã¯ä¸€åº¦ã ã‘è¡Œã†
        genai.configure(api_key=api_key)

        for model_name, purpose in required_models.items():
            try:
                # å„ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’å–å¾—ã—ã‚ˆã†ã¨è©¦ã¿ã‚‹
                genai.get_model(model_name)
                results.append(f"âœ… **{purpose} ({model_name.split('/')[-1]})**: åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
            except Exception as model_e:
                results.append(f"âŒ **{purpose} ({model_name.split('/')[-1]})**: åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
                print(f"--- ãƒ¢ãƒ‡ãƒ« '{model_name}' ã®ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—: {model_e} ---")
                all_ok = False

        # æœ€çµ‚çš„ãªçµæœã‚’é€šçŸ¥
        result_message = "\n\n".join(results)
        if all_ok:
            gr.Info(f"âœ… **å…¨ã¦ã®å¿…é ˆãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™ï¼**\n\n{result_message}")
        else:
            gr.Warning(f"âš ï¸ **ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚**\n\n{result_message}\n\nGoogle AI Studioã¾ãŸã¯Google Cloudã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    except Exception as e:
        error_message = f"âŒ **APIã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šè‡ªä½“ã«å¤±æ•—ã—ã¾ã—ãŸã€‚**\n\nAPIã‚­ãƒ¼ãŒç„¡åŠ¹ã‹ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nè©³ç´°: {str(e)}"
        print(f"--- APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ ---\n{traceback.format_exc()}")
        gr.Error(error_message)

#
# ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ»ãƒ“ãƒ«ãƒ€ãƒ¼é–¢é€£ã®æ–°ã—ã„ãƒãƒ³ãƒ‰ãƒ©ç¾¤
#
from world_builder import get_world_data, save_world_data

def handle_world_builder_load(character_name: str):
    """ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ»ãƒ“ãƒ«ãƒ€ãƒ¼ã‚¿ãƒ–ãŒé¸æŠã•ã‚ŒãŸæ™‚ã‚„ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒå¤‰æ›´ã•ã‚ŒãŸæ™‚ã®åˆæœŸåŒ–å‡¦ç†ã€‚"""
    if not character_name:
        return {}, gr.update(choices=[], value=None), gr.update(choices=[], value=None), ""

    world_data = get_world_data(character_name)
    area_choices = sorted(world_data.keys())

    return (
        world_data,
        gr.update(choices=area_choices, value=None),
        gr.update(choices=[], value=None),
        "" # content_editor
    )

def handle_character_change_for_all_tabs(character_name: str, api_key_name: str):
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ›´æ™‚ã«ã™ã¹ã¦ã®ã‚¿ãƒ–ã‚’æ›´æ–°ã™ã‚‹å¸ä»¤å¡”ã€‚"""
    print(f"--- UIå¸ä»¤å¡”(handle_character_change_for_all_tabs)å®Ÿè¡Œ: {character_name} ---")
    chat_tab_updates = handle_character_change(character_name, api_key_name)
    world_builder_updates = handle_world_builder_load(character_name)
    return chat_tab_updates + world_builder_updates


def handle_wb_area_select(world_data: Dict, area_name: str):
    """ã‚¨ãƒªã‚¢ãŒé¸æŠã•ã‚ŒãŸæ™‚ã€å ´æ‰€ã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‚’æ›´æ–°ã™ã‚‹ã€‚"""
    if not area_name or area_name not in world_data:
        return gr.update(choices=[], value=None), ""

    places = sorted(world_data[area_name].keys())
    return gr.update(choices=places, value=None), ""

def handle_wb_place_select(world_data: Dict, area_name: str, place_name: str):
    """å ´æ‰€ãŒé¸æŠã•ã‚ŒãŸæ™‚ã€å†…å®¹ã‚¨ãƒ‡ã‚£ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã€‚"""
    if not area_name or not place_name:
        return ""

    content = world_data.get(area_name, {}).get(place_name, "")
    return content

def handle_wb_save(character_name: str, world_data: Dict, area_name: str, place_name: str, content: str):
    """ä¿å­˜ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if not character_name or not area_name or not place_name:
        gr.Warning("ä¿å­˜ã™ã‚‹ã«ã¯ã‚¨ãƒªã‚¢ã¨å ´æ‰€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return world_data

    # world_data stateã‚’æ›´æ–°
    if area_name in world_data and place_name in world_data[area_name]:
        world_data[area_name][place_name] = content
        save_world_data(character_name, world_data)
        gr.Info("ä¸–ç•Œè¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        gr.Error("ä¿å­˜å¯¾è±¡ã®ã‚¨ãƒªã‚¢ã¾ãŸã¯å ´æ‰€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    return world_data

def handle_wb_add_area(character_name: str, world_data: Dict, area_name: Optional[str]):
    """ã‚¨ãƒªã‚¢è¿½åŠ ãƒœã‚¿ãƒ³"""
    if not area_name:
        gr.Warning("æ–°ã—ã„ã‚¨ãƒªã‚¢åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update()
    if area_name in world_data:
        gr.Warning(f"ã‚¨ãƒªã‚¢ '{area_name}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
        return world_data, gr.update()

    world_data[area_name] = {}
    save_world_data(character_name, world_data)
    gr.Info(f"æ–°ã—ã„ã‚¨ãƒªã‚¢ '{area_name}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

    area_choices = sorted(world_data.keys())
    return world_data, gr.update(choices=area_choices, value=area_name)

def handle_wb_add_place(character_name: str, world_data: Dict, area_name: str, place_name: Optional[str]):
    """å ´æ‰€è¿½åŠ ãƒœã‚¿ãƒ³"""
    if not area_name:
        gr.Warning("å ´æ‰€ã‚’è¿½åŠ ã™ã‚‹ã‚¨ãƒªã‚¢ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update()
    if not place_name:
        gr.Warning("æ–°ã—ã„å ´æ‰€åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update()
    if place_name in world_data.get(area_name, {}):
        gr.Warning(f"å ´æ‰€ '{place_name}' ã¯ã‚¨ãƒªã‚¢ '{area_name}' ã«æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
        return world_data, gr.update()

    world_data[area_name][place_name] = "æ–°ã—ã„å ´æ‰€ã§ã™ã€‚èª¬æ˜ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚"
    save_world_data(character_name, world_data)
    gr.Info(f"ã‚¨ãƒªã‚¢ '{area_name}' ã«æ–°ã—ã„å ´æ‰€ '{place_name}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

    place_choices = sorted(world_data[area_name].keys())
    return world_data, gr.update(choices=place_choices, value=place_name)

def handle_wb_delete_area(character_name: str, world_data: Dict, area_name: str):
    """ã‚¨ãƒªã‚¢å‰Šé™¤ãƒœã‚¿ãƒ³"""
    if not area_name:
        gr.Warning("å‰Šé™¤ã™ã‚‹ã‚¨ãƒªã‚¢ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update(), gr.update(), ""
    if area_name not in world_data:
        gr.Warning(f"ã‚¨ãƒªã‚¢ '{area_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return world_data, gr.update(), gr.update(), ""

    del world_data[area_name]
    save_world_data(character_name, world_data)
    gr.Info(f"ã‚¨ãƒªã‚¢ '{area_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    area_choices = sorted(world_data.keys())
    return world_data, gr.update(choices=area_choices, value=None), gr.update(choices=[], value=None), ""

def handle_wb_delete_place(character_name: str, world_data: Dict, area_name: str, place_name: str):
    """å ´æ‰€å‰Šé™¤ãƒœã‚¿ãƒ³"""
    if not area_name or not place_name:
        gr.Warning("å‰Šé™¤ã™ã‚‹ã‚¨ãƒªã‚¢ã¨å ´æ‰€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update(), ""
    if area_name not in world_data or place_name not in world_data[area_name]:
        gr.Warning(f"å ´æ‰€ '{place_name}' ãŒã‚¨ãƒªã‚¢ '{area_name}' ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return world_data, gr.update(), ""

    del world_data[area_name][place_name]
    save_world_data(character_name, world_data)
    gr.Info(f"å ´æ‰€ '{place_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    place_choices = sorted(world_data[area_name].keys())
    return world_data, gr.update(choices=place_choices, value=None), ""
