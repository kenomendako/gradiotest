import shutil
import pandas as pd
import json
import traceback
import hashlib
import os
import re
from typing import List, Optional, Dict, Any, Tuple
import gradio as gr
import datetime
from PIL import Image
import threading
import filetype
import base64
import io
import uuid
from tools.image_tools import generate_image as generate_image_tool_func
import pytz


import gemini_api, config_manager, alarm_manager, character_manager, utils, constants
# â–¼â–¼â–¼ æ–°ã—ã„ã‚¿ã‚¤ãƒãƒ¼ãƒ„ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â–¼â–¼â–¼
from tools import timer_tools
from agent.graph import generate_scenery_context
# from timers import UnifiedTimer # UnifiedTimerã¯ç›´æ¥ä½¿ã‚ãªããªã‚‹ã®ã§å‰Šé™¤
from character_manager import get_character_files_paths, get_world_settings_path
from memory_manager import load_memory_data_safe, save_memory_data
from world_builder import get_world_data, save_world_data

DAY_MAP_EN_TO_JA = {"mon": "æœˆ", "tue": "ç«", "wed": "æ°´", "thu": "æœ¨", "fri": "é‡‘", "sat": "åœŸ", "sun": "æ—¥"}
DAY_MAP_JA_TO_EN = {v: k for k, v in DAY_MAP_EN_TO_JA.items()}


def _get_location_choices_for_ui(character_name: str) -> list:
    """
    UIã®ç§»å‹•å…ˆDropdownç”¨ã®ã€ã‚¨ãƒªã‚¢ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸé¸æŠè‚¢ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if not character_name: return []

    world_settings_path = get_world_settings_path(character_name)
    world_data = utils.parse_world_file(world_settings_path)

    if not world_data: return []

    choices = []
    for area_name in sorted(world_data.keys()):
        # ã‚¨ãƒªã‚¢è¦‹å‡ºã—ã‚’è¿½åŠ  (é¸æŠä¸å¯ã«ã™ã‚‹ãŸã‚å€¤ã¯å°‚ç”¨ID)
        choices.append((f"[{area_name}]", f"__AREA_HEADER_{area_name}"))

        places = world_data[area_name]
        for place_name in sorted(places.keys()):
            if place_name.startswith("__"): continue
            # ã‚·ãƒ³ãƒ—ãƒ«ãªå³çŸ¢å°è¨˜å·ã«å¤‰æ›´
            choices.append((f"\u00A0\u00A0â†’ {place_name}", place_name))

    return choices

def handle_initial_load():
    print("--- UIåˆæœŸåŒ–å‡¦ç†(handle_initial_load)ã‚’é–‹å§‹ã—ã¾ã™ ---")
    df_with_ids = render_alarms_as_dataframe()
    display_df, feedback_text = get_display_df(df_with_ids), "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„"
    char_dependent_outputs = handle_character_change(config_manager.initial_character_global, config_manager.initial_api_key_name_global)
    return (display_df, df_with_ids, feedback_text) + char_dependent_outputs

def handle_character_change(character_name: str, api_key_name: str):
    if not character_name:
        char_list = character_manager.get_character_list()
        character_name = char_list[0] if char_list else "Default"

    print(f"--- UIæ›´æ–°å¸ä»¤å¡”(handle_character_change)å®Ÿè¡Œ: {character_name} ---")
    config_manager.save_config("last_character", character_name)

    chat_history, mapping_list = reload_chat_log(character_name, config_manager.initial_api_history_limit_option_global)

    _, _, img_p, mem_p, notepad_p = get_character_files_paths(character_name)

    memory_str = json.dumps(load_memory_data_safe(mem_p), indent=2, ensure_ascii=False)
    profile_image = img_p if img_p and os.path.exists(img_p) else None
    notepad_content = load_notepad_content(character_name)
    api_key = config_manager.GEMINI_API_KEYS.get(api_key_name)

    # â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ãŒä¿®æ­£ã®æ ¸å¿ƒ â–¼â–¼â–¼
    # ã¾ãšã€UIã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ç§»å‹•å…ˆãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹
    locations_for_ui = _get_location_choices_for_ui(character_name)
    valid_location_ids = [value for _name, value in locations_for_ui]

    # æ¬¡ã«ã€ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ç¾åœ¨åœ°ã‚’å–å¾—
    current_location_from_file = utils.get_current_location(character_name)
    location_dd_val = current_location_from_file

    # å®‰å…¨è£…ç½®ï¼šä¿å­˜ã•ã‚Œã¦ã„ãŸå ´æ‰€ãŒã€ç¾åœ¨ã®æœ‰åŠ¹ãªå ´æ‰€ãƒªã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if current_location_from_file and current_location_from_file not in valid_location_ids:
        gr.Warning(f"æœ€å¾Œã«ã„ãŸå ´æ‰€ã€Œ{current_location_from_file}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç§»å‹•å…ˆã‚’é¸æŠã—ç›´ã—ã¦ãã ã•ã„ã€‚")
        # ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã®é¸æŠã‚’ä¸€æ—¦ãƒªã‚»ãƒƒãƒˆ
        location_dd_val = None

    # æƒ…æ™¯æå†™ã¨ç”»åƒã¯ã€UIã«è¨­å®šã™ã‚‹æœ‰åŠ¹ãªå ´æ‰€IDã«åŸºã¥ã„ã¦å–å¾—ã™ã‚‹
    current_location_name, _, scenery_text = generate_scenery_context(character_name, api_key)
    scenery_image_path = utils.find_scenery_image(character_name, location_dd_val)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    effective_settings = config_manager.get_effective_settings(character_name)
    all_models = ["ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"] + config_manager.AVAILABLE_MODELS_GLOBAL
    model_val = effective_settings["model_name"] if effective_settings["model_name"] != config_manager.initial_model_global else "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"
    voice_display_name = config_manager.SUPPORTED_VOICES.get(effective_settings.get("voice_id", "vindemiatrix"), list(config_manager.SUPPORTED_VOICES.values())[0])
    voice_style_prompt_val = effective_settings.get("voice_style_prompt", "")

    # handle_character_change é–¢æ•°ã®æœ€å¾Œã«ã‚ã‚‹ return æ–‡ã‚’ä»¥ä¸‹ã«ç½®ãæ›ãˆã‚‹
    return (
        character_name, chat_history, mapping_list, "", profile_image,
        # â†“â†“â†“ 3ã¤ã®ã‚¨ãƒ‡ã‚£ã‚¿ã«åˆæœŸå€¤ã‚’è¨­å®šã™ã‚‹éƒ¨åˆ† â†“â†“â†“
        memory_str, notepad_content, load_system_prompt_content(character_name),
        character_name, character_name,
        gr.update(choices=locations_for_ui, value=location_dd_val),
        current_location_name, scenery_text,
        gr.update(choices=all_models, value=model_val),
        voice_display_name, voice_style_prompt_val,
        effective_settings["add_timestamp"], effective_settings["send_thoughts"],
        effective_settings["send_notepad"], effective_settings["use_common_prompt"],
        effective_settings["send_core_memory"], effective_settings["send_scenery"],
        f"â„¹ï¸ *ç¾åœ¨é¸æŠä¸­ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{character_name}ã€ã«ã®ã¿é©ç”¨ã•ã‚Œã‚‹è¨­å®šã§ã™ã€‚*", scenery_image_path
    )

def handle_save_char_settings(character_name: str, model_name: str, voice_name: str, voice_style_prompt: str, add_timestamp: bool, send_thoughts: bool, send_notepad: bool, use_common_prompt: bool, send_core_memory: bool, send_scenery: bool):
    if not character_name: gr.Warning("è¨­å®šã‚’ä¿å­˜ã™ã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return
    new_settings = {
        "model_name": model_name if model_name != "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ" else None,
        "voice_id": next((k for k, v in config_manager.SUPPORTED_VOICES.items() if v == voice_name), None),
        "voice_style_prompt": voice_style_prompt.strip(),
        "add_timestamp": bool(add_timestamp), "send_thoughts": bool(send_thoughts), "send_notepad": bool(send_notepad),
        "use_common_prompt": bool(use_common_prompt), "send_core_memory": bool(send_core_memory), "send_scenery": bool(send_scenery),
    }
    try:
        char_config_path = os.path.join(constants.CHARACTERS_DIR, character_name, "character_config.json")
        config = {}
        if os.path.exists(char_config_path) and os.path.getsize(char_config_path) > 0:
            with open(char_config_path, "r", encoding="utf-8") as f: config = json.load(f)
        if "override_settings" not in config: config["override_settings"] = {}
        config["override_settings"].update(new_settings)
        config["last_updated"] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with open(char_config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        gr.Info(f"ã€Œ{character_name}ã€ã®å€‹åˆ¥è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e: gr.Error(f"å€‹åˆ¥è¨­å®šã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); traceback.print_exc()

def handle_context_settings_change(character_name: str, api_key_name: str, api_history_limit: str, add_timestamp: bool, send_thoughts: bool, send_notepad: bool, use_common_prompt: bool, send_core_memory: bool, send_scenery: bool):
    if not character_name or not api_key_name: return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: -"
    return gemini_api.count_input_tokens(
        character_name=character_name, api_key_name=api_key_name, parts=[],
        api_history_limit=api_history_limit,
        add_timestamp=add_timestamp, send_thoughts=send_thoughts, send_notepad=send_notepad,
        use_common_prompt=use_common_prompt, send_core_memory=send_core_memory, send_scenery=send_scenery
    )

def update_token_count_on_input(character_name: str, api_key_name: str, api_history_limit: str, textbox_content: str, file_list: list, add_timestamp: bool, send_thoughts: bool, send_notepad: bool, use_common_prompt: bool, send_core_memory: bool, send_scenery: bool):
    if not character_name or not api_key_name: return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: -"
    parts_for_api = []
    if textbox_content: parts_for_api.append(textbox_content)
    if file_list:
        for file_obj in file_list: parts_for_api.append(Image.open(file_obj.name))
    return gemini_api.count_input_tokens(
        character_name=character_name, api_key_name=api_key_name, parts=parts_for_api,
        api_history_limit=api_history_limit,
        add_timestamp=add_timestamp, send_thoughts=send_thoughts, send_notepad=send_notepad,
        use_common_prompt=use_common_prompt, send_core_memory=send_core_memory, send_scenery=send_scenery
    )

def handle_message_submission(*args: Any):
    (textbox_content, current_character_name, current_api_key_name_state,
     file_input_list, api_history_limit_state, debug_mode_state) = args
    user_prompt_from_textbox = textbox_content.strip() if textbox_content else ""
    if not user_prompt_from_textbox and not file_input_list:
        chatbot_history, mapping_list = reload_chat_log(current_character_name, api_history_limit_state)
        # æˆ»ã‚Šå€¤ã®æ•°ã‚’10å€‹ã«æƒãˆã‚‹
        return chatbot_history, mapping_list, gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update()

    effective_settings = config_manager.get_effective_settings(current_character_name)
    add_timestamp_checkbox = effective_settings.get("add_timestamp", False)

    chatbot_history, _ = reload_chat_log(current_character_name, api_history_limit_state)

    log_message_parts = []
    if user_prompt_from_textbox:
        timestamp = f"\n\n{datetime.datetime.now().strftime('%Y-%m-%d (%a) %H:%M:%S')}" if add_timestamp_checkbox else ""
        processed_user_message = user_prompt_from_textbox + timestamp
        chatbot_history.append((processed_user_message, None))
        log_message_parts.append(processed_user_message)
    if file_input_list:
        for file_obj in file_input_list:
            filepath, filename = file_obj.name, os.path.basename(file_obj.name)
            chatbot_history.append(((filepath, filename), None))
            log_message_parts.append(f"[ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜: {filepath}]")

    chatbot_history.append((None, "æ€è€ƒä¸­... â–Œ"))

    # â–¼â–¼â–¼ ä¿®æ­£ç®‡æ‰€1: yieldã§è¿”ã™å€¤ã®æ•°ã‚’10å€‹ã«ã™ã‚‹ â–¼â–¼â–¼
    yield (chatbot_history, [], gr.update(value=""), gr.update(value=None), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update())

    response_data = {}
    try:
        agent_args = (
            textbox_content, current_character_name, current_api_key_name_state,
            file_input_list, api_history_limit_state, debug_mode_state
        )
        response_data = gemini_api.invoke_nexus_agent(*agent_args)
    except Exception as e:
        traceback.print_exc()
        response_data = {"response": f"[UIãƒãƒ³ãƒ‰ãƒ©ã‚¨ãƒ©ãƒ¼: {e}]", "location_name": "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰", "scenery": "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"}

    # â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ãŒä¿®æ­£ã®æ ¸å¿ƒ â–¼â–¼â–¼
    # è¿”ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨å±¥æ­´ã‚’å–å¾—ã—ã€ã‚¢ãƒ©ãƒ¼ãƒˆã¨ã—ã¦è¡¨ç¤º
    tools_used = response_data.get("tools_used", [])
    if tools_used:
        for tool_info in tools_used:
            gr.Info(tool_info)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²
    final_response_text = response_data.get("response", "")
    location_name, scenery_text = response_data.get("location_name", "ï¼ˆå–å¾—å¤±æ•—ï¼‰"), response_data.get("scenery", "ï¼ˆå–å¾—å¤±æ•—ï¼‰")

    if final_response_text and final_response_text.strip():
        log_f, _, _, _, _ = get_character_files_paths(current_character_name)
        final_log_message = "\n\n".join(log_message_parts).strip()
        if final_log_message:
            user_header = utils._get_user_header_from_log(log_f, current_character_name)
            utils.save_message_to_log(log_f, user_header, final_log_message)
        utils.save_message_to_log(log_f, f"## {current_character_name}:", final_response_text)

    # å¿œç­”å‡¦ç†ãŒå®Œäº†ã—ãŸå¾Œã®æœ€çµ‚çŠ¶æ…‹ã§UIã‚’æ›´æ–°
    formatted_history, new_mapping_list = reload_chat_log(current_character_name, api_history_limit_state)
    new_alarm_df_with_ids = render_alarms_as_dataframe()
    new_display_df = get_display_df(new_alarm_df_with_ids)
    scenery_image_path = utils.find_scenery_image(current_character_name, utils.get_current_location(current_character_name))

    # â–¼â–¼â–¼ ä¿®æ­£ç®‡æ‰€2: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å†è¨ˆç®—ã—ã¦è¿½åŠ ã™ã‚‹ â–¼â–¼â–¼
    token_count_text = gemini_api.count_input_tokens(
        character_name=current_character_name,
        api_key_name=current_api_key_name_state,
        api_history_limit=api_history_limit_state,
        parts=[], # å…¥åŠ›ãƒœãƒƒã‚¯ã‚¹ã¯ç©ºãªã®ã§ç©ºãƒªã‚¹ãƒˆã‚’æ¸¡ã™
        add_timestamp=effective_settings["add_timestamp"], send_thoughts=effective_settings["send_thoughts"],
        send_notepad=effective_settings["send_notepad"], use_common_prompt=effective_settings["use_common_prompt"],
        send_core_memory=effective_settings["send_core_memory"], send_scenery=effective_settings["send_scenery"]
    )
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    # â–¼â–¼â–¼ ä¿®æ­£ç®‡æ‰€3: æˆ»ã‚Šå€¤ã®ã‚¿ãƒ—ãƒ«ã« token_count_text ã‚’å«ã‚ã‚‹ â–¼â–¼â–¼
    yield (formatted_history, new_mapping_list, gr.update(), gr.update(value=None),
           token_count_text, location_name, scenery_text, new_alarm_df_with_ids,
           new_display_df, scenery_image_path)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

def handle_scenery_refresh(character_name: str, api_key_name: str) -> Tuple[str, str, Optional[str]]:
    """ã€Œæƒ…æ™¯ã‚’æ›´æ–°ã€ãƒœã‚¿ãƒ³å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«å†ç”Ÿæˆã™ã‚‹ã€‚"""
    if not character_name or not api_key_name:
        return "ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªé¸æŠã§ã™ï¼‰", "ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªé¸æŠã§ã™ï¼‰", None

    api_key = config_manager.GEMINI_API_KEYS.get(api_key_name)
    if not api_key:
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", None

    gr.Info(f"ã€Œ{character_name}ã€ã®ç¾åœ¨ã®æƒ…æ™¯ã‚’å¼·åˆ¶çš„ã«å†ç”Ÿæˆã—ã¦ã„ã¾ã™...")

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šè²¬å‹™ã‚’ agent/graph.py ã«å§”è­² â–¼â–¼â–¼
    location_name, _, scenery_text = generate_scenery_context(character_name, api_key, force_regenerate=True)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    if not location_name.startswith("ï¼ˆ"):
        gr.Info("æƒ…æ™¯ã‚’å†ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        scenery_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))
    else:
        gr.Error("æƒ…æ™¯ã®å†ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        scenery_image_path = None

    return location_name, scenery_text, scenery_image_path

def handle_location_change(character_name: str, selected_value: str, api_key_name: str) -> Tuple[str, str, Optional[str]]:
    # â–¼â–¼â–¼ ä¿®æ­£ãƒ–ãƒ­ãƒƒã‚¯ã“ã“ã‹ã‚‰ â–¼â–¼â–¼
    if not selected_value or selected_value.startswith("__AREA_HEADER_"):
        # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã‹ã€å€¤ãŒãªã„å ´åˆã¯ä½•ã‚‚ã—ãªã„
        # ç¾åœ¨ã®çŠ¶æ…‹ã‚’ãã®ã¾ã¾è¿”ã™
        location_name, _, scenery_text = generate_scenery_context(character_name, config_manager.GEMINI_API_KEYS.get(api_key_name))
        scenery_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))
        return location_name, scenery_text, scenery_image_path

    location_id = selected_value
    # â–²â–²â–² ä¿®æ­£ãƒ–ãƒ­ãƒƒã‚¯ã“ã“ã¾ã§ â–²â–²â–²

    from tools.space_tools import set_current_location
    print(f"--- UIã‹ã‚‰ã®å ´æ‰€å¤‰æ›´å‡¦ç†é–‹å§‹: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼='{character_name}', ç§»å‹•å…ˆID='{location_id}' ---")

    # ç¾åœ¨ã®è¡¨ç¤ºå†…å®¹ã‚’ä¸€æ™‚çš„ã«å–å¾—
    scenery_cache = utils.load_scenery_cache(character_name)
    current_loc_name = scenery_cache.get("location_name", "ï¼ˆå ´æ‰€ä¸æ˜ï¼‰")
    scenery_text = scenery_cache.get("scenery_text", "ï¼ˆæƒ…æ™¯ä¸æ˜ï¼‰")
    current_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))

    if not character_name or not location_id:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ç§»å‹•å…ˆã®å ´æ‰€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return current_loc_name, scenery_text, current_image_path

    # ã¾ãšå ´æ‰€ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ã‚’æ›´æ–°
    result = set_current_location.func(location_id=location_id, character_name=character_name)
    if "Success" not in result:
        gr.Error(f"å ´æ‰€ã®å¤‰æ›´ã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
        return current_loc_name, scenery_text, current_image_path

    gr.Info(f"å ´æ‰€ã‚’ã€Œ{location_id}ã€ã«ç§»å‹•ã—ã¾ã—ãŸã€‚æƒ…æ™¯ã‚’æ›´æ–°ã—ã¾ã™...")

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒ â–¼â–¼â–¼
    # ç§»å‹•å¾Œã«ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è€ƒæ…®ã—ãŸæƒ…æ™¯å–å¾—é–¢æ•°ã‚’å‘¼ã³å‡ºã™
    api_key = config_manager.GEMINI_API_KEYS.get(api_key_name)
    if not api_key:
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", None

    new_location_name, _, new_scenery_text = generate_scenery_context(character_name, api_key)
    new_image_path = utils.find_scenery_image(character_name, location_id)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    return new_location_name, new_scenery_text, new_image_path

def handle_add_new_character(character_name: str):
    char_list = character_manager.get_character_list()
    if not character_name or not character_name.strip():
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    safe_name = re.sub(r'[\\/*?:"<>|]', "", character_name).strip()
    if not safe_name:
        gr.Warning("ç„¡åŠ¹ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§ã™ã€‚"); return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    if character_manager.ensure_character_files(safe_name):
        gr.Info(f"æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã•ã‚“ã‚’è¿ãˆã¾ã—ãŸï¼"); new_char_list = character_manager.get_character_list(); return gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(value="")
    else:
        gr.Error(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"); return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value=character_name)

def _get_display_history_count(api_history_limit_value: str) -> int: return int(api_history_limit_value) if api_history_limit_value.isdigit() else constants.UI_HISTORY_MAX_LIMIT

def handle_chatbot_selection(character_name: str, api_history_limit_state: str, mapping_list: list, evt: gr.SelectData):
    if not character_name or evt.index is None or not mapping_list: return None, gr.update(visible=False)
    try:
        clicked_ui_index = evt.index[0]
        if not (0 <= clicked_ui_index < len(mapping_list)):
            gr.Warning(f"ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ (UI index {clicked_ui_index} out of bounds for mapping list size {len(mapping_list)})."); return None, gr.update(visible=False)

        log_f, _, _, _, _ = get_character_files_paths(character_name)
        raw_history = utils.load_chat_log(log_f, character_name)
        display_turns = _get_display_history_count(api_history_limit_state)
        visible_raw_history = raw_history[-(display_turns * 2):]

        original_log_index = mapping_list[clicked_ui_index]
        if 0 <= original_log_index < len(visible_raw_history):
            return visible_raw_history[original_log_index], gr.update(visible=True)
        else:
            gr.Warning(f"ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ (Original log index {original_log_index} out of bounds for visible history size {len(visible_raw_history)})."); return None, gr.update(visible=False)
    except Exception as e:
        print(f"ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆé¸æŠä¸­ã®ã‚¨ãƒ©ãƒ¼: {e}"); traceback.print_exc()
        return None, gr.update(visible=False)

def handle_delete_button_click(message_to_delete: Optional[Dict[str, str]], character_name: str, api_history_limit: str):
    if not message_to_delete:
        return gr.update(), gr.update(), None, gr.update(visible=False)

    log_f, _, _, _, _ = get_character_files_paths(character_name)
    if utils.delete_message_from_log(log_f, message_to_delete, character_name):
        gr.Info("ãƒ­ã‚°ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
    else:
        gr.Error("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    history, mapping_list = reload_chat_log(character_name, api_history_limit)
    return history, mapping_list, None, gr.update(visible=False)

def reload_chat_log(character_name: Optional[str], api_history_limit_value: str):
    if not character_name:
        return [], []

    log_f,_,_,_,_ = get_character_files_paths(character_name)
    if not log_f or not os.path.exists(log_f):
        return [], []

    full_raw_history = utils.load_chat_log(log_f, character_name)
    display_turns = _get_display_history_count(api_history_limit_value)
    visible_history = full_raw_history[-(display_turns * 2):]
    history, mapping_list = utils.format_history_for_gradio(visible_history, character_name)
    return history, mapping_list

def handle_wb_add_place_button_click(area_selector_value: Optional[str]):
    """å ´æ‰€è¿½åŠ ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã€ã‚¨ãƒªã‚¢ãŒé¸æŠã•ã‚Œã¦ã„ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤ºã™ã‚‹"""
    if not area_selector_value:
        gr.Warning("ã¾ãšã€å ´æ‰€ã‚’è¿½åŠ ã—ãŸã„ã‚¨ãƒªã‚¢ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        # ãƒ•ã‚©ãƒ¼ãƒ ã¯è¡¨ç¤ºã—ãªã„
        return "place", gr.update(visible=False), "#### æ–°ã—ã„å ´æ‰€ã®ä½œæˆ"

    # ã‚¨ãƒªã‚¢ãŒé¸æŠã•ã‚Œã¦ã„ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤ºã™ã‚‹
    return "place", gr.update(visible=True), "#### æ–°ã—ã„å ´æ‰€ã®ä½œæˆ"

def handle_save_memory_click(character_name, json_string_data):
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return gr.update()
    try: return save_memory_data(character_name, json_string_data)
    except Exception as e: gr.Error(f"è¨˜æ†¶ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return gr.update()

def handle_reload_memory(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return "{}"
    gr.Info(f"ã€Œ{character_name}ã€ã®è¨˜æ†¶ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚"); _, _, _, memory_json_path, _ = get_character_files_paths(character_name); return json.dumps(load_memory_data_safe(memory_json_path), indent=2, ensure_ascii=False)

def load_notepad_content(character_name: str) -> str:
    if not character_name: return ""
    _, _, _, _, notepad_path = get_character_files_paths(character_name)
    if notepad_path and os.path.exists(notepad_path):
        with open(notepad_path, "r", encoding="utf-8") as f: return f.read()
    return ""

def handle_save_notepad_click(character_name: str, content: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return content
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path: gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚"); return content
    lines = [f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}] {line.strip()}" if line.strip() and not re.match(r"^\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}\]", line.strip()) else line.strip() for line in content.strip().split('\n') if line.strip()]
    final_content = "\n".join(lines)
    try:
        with open(notepad_path, "w", encoding="utf-8") as f: f.write(final_content + ('\n' if final_content else ''))
        gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"); return final_content
    except Exception as e: gr.Error(f"ãƒ¡ãƒ¢å¸³ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"); return content

def handle_clear_notepad_click(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return ""
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path: gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚"); return ""
    try:
        with open(notepad_path, "w", encoding="utf-8") as f: f.write("")
        gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ç©ºã«ã—ã¾ã—ãŸã€‚"); return ""
    except Exception as e: gr.Error(f"ãƒ¡ãƒ¢å¸³ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}"); return f"ã‚¨ãƒ©ãƒ¼: {e}"

def handle_reload_notepad(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return ""
    content = load_notepad_content(character_name); gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚"); return content

def render_alarms_as_dataframe():
    alarms = sorted(alarm_manager.load_alarms(), key=lambda x: x.get("time", "")); all_rows = []
    for a in alarms:
        schedule_display = "å˜ç™º"
        if a.get("date"):
            try:
                date_obj, today = datetime.datetime.strptime(a["date"], "%Y-%m-%d").date(), datetime.date.today()
                if date_obj == today: schedule_display = "ä»Šæ—¥"
                elif date_obj == today + datetime.timedelta(days=1): schedule_display = "æ˜æ—¥"
                else: schedule_display = date_obj.strftime("%m/%d")
            except: schedule_display = "æ—¥ä»˜ä¸å®š"
        elif a.get("days"): schedule_display = ",".join([DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in a["days"]])
        all_rows.append({"ID": a.get("id"), "çŠ¶æ…‹": a.get("enabled", False), "æ™‚åˆ»": a.get("time"), "äºˆå®š": schedule_display, "ã‚­ãƒ£ãƒ©": a.get("character"), "å†…å®¹": a.get("context_memo") or ""})
    return pd.DataFrame(all_rows, columns=["ID", "çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])

def get_display_df(df_with_id: pd.DataFrame):
    if df_with_id is None or df_with_id.empty: return pd.DataFrame(columns=["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])
    return df_with_id[["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"]] if 'ID' in df_with_id.columns else df_with_id

def handle_alarm_selection(evt: gr.SelectData, df_with_id: pd.DataFrame) -> List[str]:
    """
    Dataframeã®é¸æŠã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«å‡¦ç†ã—ã€é¸æŠã•ã‚ŒãŸè¡Œã®IDã‚’è¿”ã™ã€‚
    """
    # ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã€ç‰¹ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    if not hasattr(evt, 'index') or evt.index is None or df_with_id is None or df_with_id.empty:
        return []

    # Gradioã®SelectDataã‹ã‚‰è¡Œç•ªå·ã‚’å–å¾— (evt.indexã¯ (è¡Œ, åˆ—) ã®ã‚¿ãƒ—ãƒ«)
    row_index = evt.index[0]

    # è¡Œç•ªå·ãŒæœ‰åŠ¹ãªç¯„å›²ã«ã‚ã‚‹ã‹ç¢ºèª
    if 0 <= row_index < len(df_with_id):
        # æ­£ã—ã„è¡Œã®IDã‚’æŠ½å‡ºã—ã€ãƒªã‚¹ãƒˆã«å…¥ã‚Œã¦è¿”ã™
        selected_id = str(df_with_id.iloc[row_index]['ID'])
        return [selected_id]

    # æœ‰åŠ¹ãªè¡Œã§ãªã‘ã‚Œã°ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    return []

def handle_alarm_selection_for_all_updates(evt: gr.SelectData, df_with_id: pd.DataFrame):
    selected_ids = handle_alarm_selection(evt, df_with_id)
    feedback_text = "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„" if not selected_ids else f"{len(selected_ids)} ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠä¸­"

    all_chars = character_manager.get_character_list()
    default_char = all_chars[0] if all_chars else "Default"

    if len(selected_ids) == 1:
        alarm = next((a for a in alarm_manager.load_alarms() if a.get("id") == selected_ids[0]), None)
        if alarm:
            h, m = alarm.get("time", "08:00").split(":")
            days_ja = [DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in alarm.get("days", [])]

            form_updates = (
                "ã‚¢ãƒ©ãƒ¼ãƒ æ›´æ–°", alarm.get("context_memo", ""), alarm.get("character", default_char),
                days_ja, alarm.get("is_emergency", False), h, m, selected_ids[0]
            )
            cancel_button_visibility = gr.update(visible=True) # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
        else: # å¿µã®ãŸã‚ã®å®‰å…¨ç­–
            form_updates = ("ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", default_char, [], False, "08", "00", None)
            cancel_button_visibility = gr.update(visible=False) # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã‚’éè¡¨ç¤º
    else: # é¸æŠè§£é™¤æ™‚
        form_updates = ("ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", default_char, [], False, "08", "00", None)
        cancel_button_visibility = gr.update(visible=False) # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã‚’éè¡¨ç¤º

    return (selected_ids, feedback_text) + form_updates + (cancel_button_visibility,)

def toggle_selected_alarms_status(selected_ids: list, target_status: bool):
    if not selected_ids: gr.Warning("çŠ¶æ…‹ã‚’å¤‰æ›´ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        current_alarms = alarm_manager.load_alarms()
        modified = any(a.get("id") in selected_ids and a.update({"enabled": target_status}) is None for a in current_alarms)
        if modified:
            alarm_manager.alarms_data_global = current_alarms; alarm_manager.save_alarms()
            gr.Info(f"{len(selected_ids)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã®çŠ¶æ…‹ã‚’ã€Œ{'æœ‰åŠ¹' if target_status else 'ç„¡åŠ¹'}ã€ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚")
    new_df_with_ids = render_alarms_as_dataframe(); return new_df_with_ids, get_display_df(new_df_with_ids)

# â–¼â–¼â–¼ ã“ã®é–¢æ•°ã‚’æ–°ã—ãè¿½åŠ  â–¼â–¼â–¼
def handle_delete_alarms_and_update_ui(selected_ids: list):
    """ã€å¸ä»¤å¡”ã€‘é¸æŠã•ã‚ŒãŸã‚¢ãƒ©ãƒ¼ãƒ ã‚’å‰Šé™¤ã—ã€UIå…¨ä½“ã‚’æ›´æ–°ã™ã‚‹ã€‚"""
    if not selected_ids:
        gr.Warning("å‰Šé™¤ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        df_with_ids = render_alarms_as_dataframe()
        return df_with_ids, get_display_df(df_with_ids), gr.update(), gr.update()

    deleted_count = 0
    for sid in selected_ids:
        if alarm_manager.delete_alarm(str(sid)):
            deleted_count += 1

    if deleted_count > 0:
        gr.Info(f"{deleted_count}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    new_df_with_ids = render_alarms_as_dataframe()
    display_df = get_display_df(new_df_with_ids)

    new_selected_ids = []
    feedback_text = "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„"

    return new_df_with_ids, display_df, new_selected_ids, feedback_text

def handle_cancel_alarm_edit():
    """ã‚¢ãƒ©ãƒ¼ãƒ ç·¨é›†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã€ãƒ•ã‚©ãƒ¼ãƒ ã‚’åˆæœŸçŠ¶æ…‹ã«æˆ»ã™"""
    all_chars = character_manager.get_character_list()
    default_char = all_chars[0] if all_chars else "Default"

    # ãƒ•ã‚©ãƒ¼ãƒ ã¨é¸æŠçŠ¶æ…‹ã‚’å®Œå…¨ã«ãƒªã‚»ãƒƒãƒˆ
    return (
        "ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", gr.update(choices=all_chars, value=default_char),
        [], False, "08", "00", None, [], "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„",
        gr.update(visible=False) # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³è‡ªèº«ã‚’éè¡¨ç¤ºã«
    )

def handle_add_or_update_alarm(editing_id, h, m, char, context, days_ja, is_emergency):
    from tools.alarm_tools import set_personal_alarm
    context_memo = context.strip() if context and context.strip() else "æ™‚é–“ã«ãªã‚Šã¾ã—ãŸ"
    days_en = [DAY_MAP_JA_TO_EN.get(d) for d in days_ja if d in DAY_MAP_JA_TO_EN]

    if editing_id:
        alarm_manager.delete_alarm(editing_id)
        gr.Info(f"ã‚¢ãƒ©ãƒ¼ãƒ ID:{editing_id} ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
    else:
        gr.Info(f"æ–°ã—ã„ã‚¢ãƒ©ãƒ¼ãƒ ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

    set_personal_alarm.func(time=f"{h}:{m}", context_memo=context_memo, character_name=char, days=days_en, date=None, is_emergency=is_emergency)

    new_df_with_ids = render_alarms_as_dataframe()
    all_chars = character_manager.get_character_list()
    default_char = all_chars[0] if all_chars else "Default"

    return (
        new_df_with_ids, get_display_df(new_df_with_ids),
        "ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", gr.update(choices=all_chars, value=default_char),
        [], False, "08", "00", None, [], "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„",
        gr.update(visible=False) # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã‚’éè¡¨ç¤º
    )

def handle_timer_submission(timer_type, duration, work, brk, cycles, char, work_theme, brk_theme, api_key_name, normal_theme):
    if not char or not api_key_name:
        return "ã‚¨ãƒ©ãƒ¼ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"

    try:
        if timer_type == "é€šå¸¸ã‚¿ã‚¤ãƒãƒ¼":
            # â–¼â–¼â–¼ é€šå¸¸ã‚¿ã‚¤ãƒãƒ¼ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ â–¼â–¼â–¼
            result_message = timer_tools.set_timer.func(
                duration_minutes=int(duration),
                theme=normal_theme or "æ™‚é–“ã«ãªã‚Šã¾ã—ãŸï¼",
                character_name=char
            )
            gr.Info(f"é€šå¸¸ã‚¿ã‚¤ãƒãƒ¼ã‚’è¨­å®šã—ã¾ã—ãŸã€‚")
        elif timer_type == "ãƒãƒ¢ãƒ‰ãƒ¼ãƒ­ã‚¿ã‚¤ãƒãƒ¼":
            # â–¼â–¼â–¼ ãƒãƒ¢ãƒ‰ãƒ¼ãƒ­ã‚¿ã‚¤ãƒãƒ¼ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ â–¼â–¼â–¼
            result_message = timer_tools.set_pomodoro_timer.func(
                work_minutes=int(work),
                break_minutes=int(brk),
                cycles=int(cycles),
                work_theme=work_theme or "ä½œæ¥­çµ‚äº†ã®æ™‚é–“ã§ã™ã€‚",
                break_theme=brk_theme or "ä¼‘æ†©çµ‚äº†ã®æ™‚é–“ã§ã™ã€‚",
                character_name=char
            )
            gr.Info(f"ãƒãƒ¢ãƒ‰ãƒ¼ãƒ­ã‚¿ã‚¤ãƒãƒ¼ã‚’è¨­å®šã—ã¾ã—ãŸã€‚")
        else:
            result_message = "ã‚¨ãƒ©ãƒ¼: ä¸æ˜ãªã‚¿ã‚¤ãƒãƒ¼ç¨®åˆ¥ã§ã™ã€‚"

        # ãƒ„ãƒ¼ãƒ«ã‹ã‚‰ã®æˆåŠŸ/ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’UIã«è¡¨ç¤º
        return result_message

    except Exception as e:
        traceback.print_exc()
        return f"ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}"

def handle_rag_update_button_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); return
    api_key = config_manager.GEMINI_API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"): gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    gr.Info(f"ã€Œ{character_name}ã€ã®RAGç´¢å¼•ã®æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã™...")
    import rag_manager
    threading.Thread(target=lambda: rag_manager.create_or_update_index(character_name, api_key)).start()

def _run_core_memory_update(character_name: str, api_key: str):
    print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ (Character: {character_name}) ---")
    try:
        from tools import memory_tools
        result = memory_tools.summarize_and_save_core_memory.func(character_name=character_name, api_key=api_key)
        print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†å®Œäº† --- çµæœ: {result}")
    except Exception: print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¨ãƒ©ãƒ¼] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ ---"); traceback.print_exc()

def handle_core_memory_update_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); return
    api_key = config_manager.GEMINI_API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"): gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    gr.Info(f"ã€Œ{character_name}ã€ã®ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹ã—ã¾ã—ãŸã€‚")
    threading.Thread(target=_run_core_memory_update, args=(character_name, api_key)).start()

def update_model_state(model): config_manager.save_config("last_model", model); return model

def update_api_key_state(api_key_name):
    config_manager.save_config("last_api_key_name", api_key_name)
    gr.Info(f"APIã‚­ãƒ¼ã‚’ '{api_key_name}' ã«è¨­å®šã—ã¾ã—ãŸã€‚")
    return api_key_name

def update_api_history_limit_state_and_reload_chat(limit_ui_val: str, character_name: Optional[str]):
    key = next((k for k, v in constants.API_HISTORY_LIMIT_OPTIONS.items() if v == limit_ui_val), "all")
    config_manager.save_config("last_api_history_limit_option", key)
    history, mapping_list = reload_chat_log(character_name, key)
    return key, history, mapping_list

def handle_play_audio_button_click(selected_message: Optional[Dict[str, str]], character_name: str, api_key_name: str):
    if not selected_message:
        gr.Warning("å†ç”Ÿã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        # â˜… ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã¯å¤‰æ›´ã—ãªã„ã®ã§ã€å…ƒã®çŠ¶æ…‹ã‚’è¿”ã™
        yield gr.update(visible=False), gr.update(interactive=True), gr.update(interactive=True)
        return

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šyield ã‚’ä½¿ã£ãŸæ®µéšçš„ãªUIæ›´æ–° â–¼â–¼â–¼
    # 1. ã¾ãšã€Œç”Ÿæˆä¸­ã€ã®çŠ¶æ…‹ã‚’UIã«å³æ™‚åæ˜ ã•ã›ã‚‹
    yield (
        gr.update(visible=False), # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ä¸€æ—¦éš ã™
        gr.update(value="éŸ³å£°ç”Ÿæˆä¸­... â–Œ", interactive=False), # å†ç”Ÿãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–
        gr.update(interactive=False)  # è©¦è´ãƒœã‚¿ãƒ³ã‚‚ç„¡åŠ¹åŒ–
    )

    try:
        raw_text = utils.extract_raw_text_from_html(selected_message.get("content"))
        text_to_speak = utils.remove_thoughts_from_text(raw_text)
        if not text_to_speak:
            gr.Info("ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯éŸ³å£°ã§å†ç”Ÿã§ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        effective_settings = config_manager.get_effective_settings(character_name)
        voice_id, voice_style_prompt = effective_settings.get("voice_id", "iapetus"), effective_settings.get("voice_style_prompt", "")
        api_key = config_manager.GEMINI_API_KEYS.get(api_key_name)
        if not api_key:
            gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return

        from audio_manager import generate_audio_from_text
        gr.Info(f"ã€Œ{character_name}ã€ã®å£°ã§éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        audio_filepath = generate_audio_from_text(text_to_speak, api_key, voice_id, voice_style_prompt)

        if audio_filepath:
            gr.Info("å†ç”Ÿã—ã¾ã™ã€‚")
            # 2. æˆåŠŸã—ãŸã‚‰ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¡¨ç¤ºã—ã¦å†ç”Ÿã‚’é–‹å§‹
            yield gr.update(value=audio_filepath, visible=True), gr.update(), gr.update()
        else:
            gr.Error("éŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    finally:
        # 3. æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšã€å¿…ãšæœ€å¾Œã«ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’å…ƒã«æˆ»ã™
        yield (
            gr.update(), # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®çŠ¶æ…‹ã¯ãã®ã¾ã¾
            gr.update(value="ğŸ”Š é¸æŠã—ãŸç™ºè¨€ã‚’å†ç”Ÿ", interactive=True), # å†ç”Ÿãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
            gr.update(interactive=True)  # è©¦è´ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
        )

def handle_voice_preview(selected_voice_name: str, voice_style_prompt: str, text_to_speak: str, api_key_name: str):
    if not selected_voice_name or not text_to_speak or not api_key_name:
        gr.Warning("å£°ã€ãƒ†ã‚­ã‚¹ãƒˆã€APIã‚­ãƒ¼ãŒã™ã¹ã¦é¸æŠã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        yield gr.update(visible=False), gr.update(interactive=True), gr.update(interactive=True)
        return

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šyield ã‚’ä½¿ã£ãŸæ®µéšçš„ãªUIæ›´æ–° â–¼â–¼â–¼
    yield (
        gr.update(visible=False),
        gr.update(interactive=False),
        gr.update(value="ç”Ÿæˆä¸­...", interactive=False)
    )

    try:
        voice_id = next((key for key, value in config_manager.SUPPORTED_VOICES.items() if value == selected_voice_name), None)
        api_key = config_manager.GEMINI_API_KEYS.get(api_key_name)
        if not voice_id or not api_key:
            gr.Warning("å£°ã¾ãŸã¯APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚")
            return

        from audio_manager import generate_audio_from_text
        gr.Info(f"å£°ã€Œ{selected_voice_name}ã€ã§éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        audio_filepath = generate_audio_from_text(text_to_speak, api_key, voice_id, voice_style_prompt)

        if audio_filepath:
            gr.Info("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å†ç”Ÿã—ã¾ã™ã€‚")
            yield gr.update(value=audio_filepath, visible=True), gr.update(), gr.update()
        else:
            gr.Error("éŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    finally:
        # æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšã€å¿…ãšæœ€å¾Œã«ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’å…ƒã«æˆ»ã™
        yield (
            gr.update(),
            gr.update(interactive=True),
            gr.update(value="è©¦è´", interactive=True)
        )

def handle_generate_or_regenerate_scenery_image(character_name: str, api_key_name: str, style_choice: str) -> Optional[str]:
    """ã€Œæƒ…æ™¯ç”»åƒã‚’ç”Ÿæˆ/æ›´æ–°ã€ãƒœã‚¿ãƒ³å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ã€‚ã‚·ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼AIã‚’èµ·å‹•ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    if not character_name or not api_key_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return None

    api_key = config_manager.GEMINI_API_KEYS.get(api_key_name)
    if not api_key:
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

    location_id = utils.get_current_location(character_name)
    existing_image_path = utils.find_scenery_image(character_name, location_id)

    if not location_id:
        gr.Warning("ç¾åœ¨åœ°ãŒç‰¹å®šã§ãã¾ã›ã‚“ã€‚")
        return existing_image_path

    final_prompt = ""
    # --- ã‚·ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼AIã«ã‚ˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ ---
    gr.Info("ã‚·ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼AIãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹æˆã—ã¦ã„ã¾ã™...")
    try:
        # 1. ç¾åœ¨ã®çŠ¶æ³ã‚’å®šç¾©ã™ã‚‹
        now = datetime.datetime.now()
        time_of_day = utils.get_time_of_day(now.hour)
        season = utils.get_season(now.month)
        style_prompts = {
            "å†™çœŸé¢¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)": "An ultra-detailed, photorealistic masterpiece with cinematic lighting.",
            "ã‚¤ãƒ©ã‚¹ãƒˆé¢¨": "A beautiful and detailed anime-style illustration, pixiv contest winner.",
            "ã‚¢ãƒ‹ãƒ¡é¢¨": "A high-quality screenshot from a modern animated film.",
            "æ°´å½©ç”»é¢¨": "A gentle and emotional watercolor painting."
        }
        style_choice_text = style_prompts.get(style_choice, style_prompts["å†™çœŸé¢¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)"])

        # 2. å ´æ‰€ã®åŸºæœ¬è¨­å®šãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        world_settings_path = character_manager.get_world_settings_path(character_name)
        world_settings = utils.parse_world_file(world_settings_path)
        if not world_settings:
            gr.Error("ä¸–ç•Œè¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return existing_image_path

        space_text = None
        for area, places in world_settings.items():
            if location_id in places:
                space_text = places[location_id]
                break

        if not space_text:
            gr.Error("ç¾åœ¨ã®å ´æ‰€ã®å®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return existing_image_path

        # 3. ã‚·ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼AIï¼ˆgemini-2.5-flashï¼‰ã‚’æº–å‚™
        from agent.graph import get_configured_llm
        scene_director_llm = get_configured_llm("gemini-2.5-flash", api_key)

        # 4. AIã¸ã®æŒ‡ç¤ºæ›¸ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ä½œæˆ
        director_prompt = f"""
You are a master scene director AI for a high-end image generation model.
Your sole purpose is to synthesize all available information into a single, cohesive, and flawless prompt.

**Objective:**
Generate one final, masterful prompt for an image generation AI.

**Core Principles:**
1.  **Foundation First (Absolute Priority):** The 'Base Location Description' is the undeniable truth of the world. Your final prompt **must be a faithful and accurate visual representation** of all objects, furniture, materials, and architectural structures described within it. Do not omit, add, or change these fundamental elements.
2.  **Synthesize, Don't Contradict:** Read the 'Base Location Description' and the 'Current Scene Conditions'. Your final prompt must logically integrate both. If there are contradictions (e.g., the description mentions 'natural light' but the condition is 'night'), you MUST resolve them by prioritizing the 'Current Scene Conditions' while upholding Principle #1.
3.  **Strictly Visual:** The output must be a purely visual and descriptive paragraph in English. Exclude any narrative, metaphors, sounds, or non-visual elements.
4.  **Mandatory Inclusions:** Your final prompt MUST incorporate the specified 'Aspect Ratio' and adhere to the 'Style Definition'.
5.  **Absolute Prohibitions:** Strictly enforce all 'Negative Prompts'.
6.  **Output Format:** Output ONLY the final, single-paragraph prompt. Do not include any of your own thoughts, acknowledgments, or conversational text.

---
**Information Dossier:**

**1. Base Location Description (The ground truth for all structures and objects):**
{space_text}

**2. Current Scene Conditions (This defines the current atmosphere and overrides conflicting light sources):**
- Time of Day: {time_of_day}
- Season: {season}

**3. Style Definition (Incorporate this aesthetic):**
- {style_choice_text}

**4. Mandatory Technical Specs:**
- Aspect Ratio: The final image must have a 16:9 landscape aspect ratio.

**5. Negative Prompts (Strictly enforce these exclusions):**
- Absolutely no text, letters, characters, signatures, or watermarks. Do not include people.
---

**Final Master Prompt:**
"""

        # 5. AIã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚’ä¾é ¼
        final_prompt = scene_director_llm.invoke(director_prompt).content.strip()

    except Exception as e:
        gr.Error(f"ã‚·ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼AIã«ã‚ˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()
        return existing_image_path

    if not final_prompt:
        gr.Error("ã‚·ãƒ¼ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼AIãŒæœ‰åŠ¹ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return existing_image_path

    # --- ç”»åƒç”ŸæˆAIã¸ã®æœ€çµ‚çš„ãªä¾é ¼ ---
    gr.Info(f"ã€Œ{style_choice}ã€ã§ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™...")
    result = generate_image_tool_func.func(prompt=final_prompt, character_name=character_name, api_key=api_key)

    # --- ç”Ÿæˆç”»åƒã®ä¿å­˜ã¨UIæ›´æ–° ---
    if "Generated Image:" in result:
        generated_path = result.replace("[Generated Image: ", "").replace("]", "").strip()
        if os.path.exists(generated_path):
            save_dir = os.path.join(constants.CHARACTERS_DIR, character_name, "spaces", "images")
            now = datetime.datetime.now()

            cache_key = f"{location_id}_{utils.get_season(now.month)}_{utils.get_time_of_day(now.hour)}"
            specific_filename = f"{cache_key}.png"
            specific_path = os.path.join(save_dir, specific_filename)

            if os.path.exists(specific_path):
                os.remove(specific_path)

            shutil.move(generated_path, specific_path)
            print(f"--- æƒ…æ™¯ç”»åƒã‚’ç”Ÿæˆã—ã€ä¿å­˜ã—ã¾ã—ãŸ: {specific_path} ---")

            gr.Info("ç”»åƒã‚’ç”Ÿæˆ/æ›´æ–°ã—ã¾ã—ãŸã€‚")
            return specific_path
        else:
            gr.Error("ç”»åƒã®ç”Ÿæˆã«ã¯æˆåŠŸã—ã¾ã—ãŸãŒã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return existing_image_path
    else:
        gr.Error(f"ç”»åƒã®ç”Ÿæˆ/æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIã®å¿œç­”: {result}")
        return existing_image_path

def handle_api_connection_test(api_key_name: str):
    """APIã‚­ãƒ¼ã‚’ä½¿ã£ã¦ã€Nexus ArkãŒå¿…è¦ã¨ã™ã‚‹å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹"""
    if not api_key_name:
        gr.Warning("ãƒ†ã‚¹ãƒˆã™ã‚‹APIã‚­ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    api_key = config_manager.GEMINI_API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"):
        gr.Error(f"APIã‚­ãƒ¼ '{api_key_name}' ã¯ç„¡åŠ¹ã§ã™ã€‚config.jsonã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    gr.Info(f"APIã‚­ãƒ¼ '{api_key_name}' ã‚’ä½¿ã£ã¦ã€å¿…é ˆãƒ¢ãƒ‡ãƒ«ã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã„ã¾ã™...")

    # æ­£ã—ã„SDKã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    import google.genai as genai

    # ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’ã€ç¾åœ¨ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä»•æ§˜ã«æ›´æ–°
    required_models = {
        "models/gemini-2.5-pro": "ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (agent_node)",
        "models/gemini-2.5-flash": "é«˜é€Ÿå‡¦ç† (context_generator)",
        # æ³¨æ„: ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ 'generate_content' APIã§ã¯ãƒ†ã‚¹ãƒˆã§ããªã„ãŸã‚ã€ãƒªã‚¹ãƒˆã‹ã‚‰é™¤å¤–ã€‚
        # ä»£ã‚ã‚Šã«ã€ä¸»è¦ãªãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ä¿è¨¼ã—ã¾ã™ã€‚
    }

    results = []
    all_ok = True

    try:
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã¯ä¸€åº¦ã ã‘è¡Œã†
        client = genai.Client(api_key=api_key)

        for model_name, purpose in required_models.items():
            try:
                # å„ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’å–å¾—ã—ã‚ˆã†ã¨è©¦ã¿ã‚‹
                client.models.get(model=model_name)
                results.append(f"âœ… **{purpose} ({model_name.split('/')[-1]})**: åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
            except Exception as model_e:
                results.append(f"âŒ **{purpose} ({model_name.split('/')[-1]})**: åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
                print(f"--- ãƒ¢ãƒ‡ãƒ« '{model_name}' ã®ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—: {model_e} ---")
                all_ok = False

        # æœ€çµ‚çš„ãªçµæœã‚’é€šçŸ¥
        result_message = "\n\n".join(results)
        if all_ok:
            gr.Info(f"âœ… **å…¨ã¦ã®å¿…é ˆãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™ï¼**\n\n{result_message}")
        else:
            gr.Warning(f"âš ï¸ **ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚**\n\n{result_message}\n\nGoogle AI Studioã¾ãŸã¯Google Cloudã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    except Exception as e:
        error_message = f"âŒ **APIã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šè‡ªä½“ã«å¤±æ•—ã—ã¾ã—ãŸã€‚**\n\nAPIã‚­ãƒ¼ãŒç„¡åŠ¹ã‹ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nè©³ç´°: {str(e)}"
        print(f"--- APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ ---\n{traceback.format_exc()}")
        gr.Error(error_message)

#
# ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ»ãƒ“ãƒ«ãƒ€ãƒ¼é–¢é€£ã®æ–°ã—ã„ãƒãƒ³ãƒ‰ãƒ©ç¾¤
#
from world_builder import get_world_data, save_world_data

def handle_world_builder_load(character_name: str):
    """ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ»ãƒ“ãƒ«ãƒ€ãƒ¼ã‚¿ãƒ–ãŒé¸æŠã•ã‚ŒãŸæ™‚ã‚„ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒå¤‰æ›´ã•ã‚ŒãŸæ™‚ã®åˆæœŸåŒ–å‡¦ç†ã€‚"""
    if not character_name:
        return {}, gr.update(choices=[], value=None) # è¿”ã‚Šå€¤ã®æ•°ã‚’2ã¤ã«ä¿®æ­£

    world_data = get_world_data(character_name)
    area_choices = sorted(world_data.keys())

    # UIã®æœŸå¾…é€šã‚Šã€2ã¤ã®å€¤ã ã‘ã‚’è¿”ã™
    return world_data, gr.update(choices=area_choices, value=None)

def handle_character_change_for_all_tabs(character_name: str, api_key_name: str):
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ›´æ™‚ã«ã™ã¹ã¦ã®ã‚¿ãƒ–ã‚’æ›´æ–°ã™ã‚‹å¸ä»¤å¡”ã€‚"""
    print(f"--- UIå¸ä»¤å¡”(handle_character_change_for_all_tabs)å®Ÿè¡Œ: {character_name} ---")
    chat_tab_updates = handle_character_change(character_name, api_key_name)
    world_builder_updates = handle_world_builder_load(character_name)
    return chat_tab_updates + world_builder_updates


def handle_wb_area_select(world_data: Dict, area_name: str):
    """ã‚¨ãƒªã‚¢ãŒé¸æŠã•ã‚ŒãŸæ™‚ã€å ´æ‰€ã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‚’æ›´æ–°ã™ã‚‹ã€‚"""
    if not area_name or area_name not in world_data:
        return gr.update(choices=[], value=None)

    places = sorted(world_data[area_name].keys())
    return gr.update(choices=places, value=None)

def handle_wb_place_select(world_data: Dict, area_name: str, place_name: str):
    """å ´æ‰€ãŒé¸æŠã•ã‚ŒãŸæ™‚ã€å†…å®¹ã‚¨ãƒ‡ã‚£ã‚¿ã‚’æ›´æ–°ã—ã€ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    if not area_name or not place_name:
        # å ´æ‰€ãŒé¸æŠã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ã‚¨ãƒ‡ã‚£ã‚¿ã¨ãƒœã‚¿ãƒ³ã‚’éš ã™
        return gr.update(value="", visible=False), gr.update(visible=False), gr.update(visible=False)

    # å ´æ‰€ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
    content = world_data.get(area_name, {}).get(place_name, "")

    # UIã®æœŸå¾…é€šã‚Šã€3ã¤ã®å€¤ã‚’ã‚¿ãƒ—ãƒ«ã§è¿”ã™
    return (
        gr.update(value=content, visible=True),  # 1. content_editor ã®å†…å®¹ã‚’æ›´æ–°ã—ã€è¡¨ç¤ºã™ã‚‹
        gr.update(visible=True),                 # 2. save_button_row ã‚’è¡¨ç¤º
        gr.update(visible=True)                  # 3. delete_place_button ã‚’è¡¨ç¤º
    )

def handle_wb_save(character_name: str, world_data: Dict, area_name: str, place_name: str, content: str):
    """ä¿å­˜ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if not character_name or not area_name or not place_name:
        gr.Warning("ä¿å­˜ã™ã‚‹ã«ã¯ã‚¨ãƒªã‚¢ã¨å ´æ‰€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return world_data

    # world_data stateã‚’æ›´æ–°
    if area_name in world_data and place_name in world_data[area_name]:
        world_data[area_name][place_name] = content
        save_world_data(character_name, world_data)
        gr.Info("ä¸–ç•Œè¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        gr.Error("ä¿å­˜å¯¾è±¡ã®ã‚¨ãƒªã‚¢ã¾ãŸã¯å ´æ‰€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    return world_data

def handle_wb_add_area(character_name: str, world_data: Dict, area_name: Optional[str]):
    """ã‚¨ãƒªã‚¢è¿½åŠ ãƒœã‚¿ãƒ³"""
    if not area_name:
        gr.Warning("æ–°ã—ã„ã‚¨ãƒªã‚¢åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update()
    if area_name in world_data:
        gr.Warning(f"ã‚¨ãƒªã‚¢ '{area_name}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
        return world_data, gr.update()

    world_data[area_name] = {}
    save_world_data(character_name, world_data)
    gr.Info(f"æ–°ã—ã„ã‚¨ãƒªã‚¢ '{area_name}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

    area_choices = sorted(world_data.keys())
    return world_data, gr.update(choices=area_choices, value=area_name)

def handle_wb_add_place(character_name: str, world_data: Dict, area_name: str, place_name: Optional[str]):
    """å ´æ‰€è¿½åŠ ãƒœã‚¿ãƒ³"""
    if not area_name:
        gr.Warning("å ´æ‰€ã‚’è¿½åŠ ã™ã‚‹ã‚¨ãƒªã‚¢ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update()
    if not place_name:
        gr.Warning("æ–°ã—ã„å ´æ‰€åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update()
    if place_name in world_data.get(area_name, {}):
        gr.Warning(f"å ´æ‰€ '{place_name}' ã¯ã‚¨ãƒªã‚¢ '{area_name}' ã«æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
        return world_data, gr.update()

    world_data[area_name][place_name] = "æ–°ã—ã„å ´æ‰€ã§ã™ã€‚èª¬æ˜ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚"
    save_world_data(character_name, world_data)
    gr.Info(f"ã‚¨ãƒªã‚¢ '{area_name}' ã«æ–°ã—ã„å ´æ‰€ '{place_name}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

    place_choices = sorted(world_data[area_name].keys())
    return world_data, gr.update(choices=place_choices, value=place_name)

def handle_wb_delete_area(character_name: str, world_data: Dict, area_name: str):
    """ã‚¨ãƒªã‚¢å‰Šé™¤ãƒœã‚¿ãƒ³"""
    if not area_name:
        gr.Warning("å‰Šé™¤ã™ã‚‹ã‚¨ãƒªã‚¢ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update(), gr.update(), ""
    if area_name not in world_data:
        gr.Warning(f"ã‚¨ãƒªã‚¢ '{area_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return world_data, gr.update(), gr.update(), ""

    del world_data[area_name]
    save_world_data(character_name, world_data)
    gr.Info(f"ã‚¨ãƒªã‚¢ '{area_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    area_choices = sorted(world_data.keys())
    return world_data, gr.update(choices=area_choices, value=None), gr.update(choices=[], value=None), ""

def handle_wb_delete_place(character_name: str, world_data: Dict, area_name: str, place_name: str):
    """å ´æ‰€å‰Šé™¤ãƒœã‚¿ãƒ³"""
    if not area_name or not place_name:
        gr.Warning("å‰Šé™¤ã™ã‚‹ã‚¨ãƒªã‚¢ã¨å ´æ‰€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update(), ""
    if area_name not in world_data or place_name not in world_data[area_name]:
        gr.Warning(f"å ´æ‰€ '{place_name}' ãŒã‚¨ãƒªã‚¢ '{area_name}' ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return world_data, gr.update(), ""

    del world_data[area_name][place_name]
    save_world_data(character_name, world_data)
    gr.Info(f"å ´æ‰€ '{place_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    place_choices = sorted(world_data[area_name].keys())
    return world_data, gr.update(choices=place_choices, value=None), ""

def handle_wb_confirm_add(character_name: str, world_data: Dict, selected_area: str, item_type: str, item_name: str):
    """ã‚¨ãƒªã‚¢ã¾ãŸã¯å ´æ‰€ã®è¿½åŠ ã‚’ç¢ºå®šã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©ã€‚"""
    if not character_name or not item_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ãªã„ã‹ã€åå‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return world_data, gr.update(), gr.update(), gr.update(visible=True), item_name

    item_name = item_name.strip()
    if not item_name:
        gr.Warning("åå‰ãŒç©ºã§ã™ã€‚")
        return world_data, gr.update(), gr.update(), gr.update(visible=True), item_name

    if item_type == "area":
        if item_name in world_data:
            gr.Warning(f"ã‚¨ãƒªã‚¢ '{item_name}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
            return world_data, gr.update(), gr.update(), gr.update(visible=True), item_name

        world_data[item_name] = {}
        save_world_data(character_name, world_data)
        gr.Info(f"æ–°ã—ã„ã‚¨ãƒªã‚¢ '{item_name}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

        area_choices = sorted(world_data.keys())
        return world_data, gr.update(choices=area_choices, value=item_name), gr.update(choices=[], value=None), gr.update(visible=False), ""

    elif item_type == "place":
        if not selected_area:
            gr.Warning("å ´æ‰€ã‚’è¿½åŠ ã™ã‚‹ã‚¨ãƒªã‚¢ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            return world_data, gr.update(), gr.update(), gr.update(visible=True), item_name

        if item_name in world_data.get(selected_area, {}):
            gr.Warning(f"å ´æ‰€ '{item_name}' ã¯ã‚¨ãƒªã‚¢ '{selected_area}' ã«æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
            return world_data, gr.update(), gr.update(), gr.update(visible=True), item_name

        world_data[selected_area][item_name] = "æ–°ã—ã„å ´æ‰€ã§ã™ã€‚èª¬æ˜ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚"
        save_world_data(character_name, world_data)
        gr.Info(f"ã‚¨ãƒªã‚¢ '{selected_area}' ã«æ–°ã—ã„å ´æ‰€ '{item_name}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

        place_choices = sorted(world_data[selected_area].keys())
        return world_data, gr.update(), gr.update(choices=place_choices, value=item_name), gr.update(visible=False), ""

    else:
        gr.Error(f"ä¸æ˜ãªã‚¢ã‚¤ãƒ†ãƒ ã‚¿ã‚¤ãƒ—ã§ã™: {item_type}")
        return world_data, gr.update(), gr.update(), gr.update(visible=False), ""

def handle_save_gemini_key(key_name, key_value):
    if not key_name or not key_value:
        gr.Warning("ã‚­ãƒ¼ã®åå‰ã¨å€¤ã®ä¸¡æ–¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return gr.update(), gr.update()

    config_manager.add_or_update_gemini_key(key_name, key_value)
    gr.Info(f"Gemini APIã‚­ãƒ¼ã€Œ{key_name}ã€ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

    new_keys = list(config_manager.GEMINI_API_KEYS.keys())
    return pd.DataFrame(new_keys, columns=["Geminiã‚­ãƒ¼å"]), gr.update(choices=new_keys)

def handle_delete_gemini_key(key_name):
    if not key_name:
        gr.Warning("å‰Šé™¤ã™ã‚‹ã‚­ãƒ¼ã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return gr.update(), gr.update()

    config_manager.delete_gemini_key(key_name)
    gr.Info(f"Gemini APIã‚­ãƒ¼ã€Œ{key_name}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    new_keys = list(config_manager.GEMINI_API_KEYS.keys())
    return pd.DataFrame(new_keys, columns=["Geminiã‚­ãƒ¼å"]), gr.update(choices=new_keys, value=new_keys[0] if new_keys else None)

def handle_save_pushover_config(user_key, app_token):
    config_manager.update_pushover_config(user_key, app_token)
    gr.Info("Pushoverè¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

def handle_save_tavily_key(api_key):
    config_manager.update_tavily_key(api_key)
    gr.Info("Tavily APIã‚­ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

def handle_notification_service_change(service_choice: str):
    """é€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­å®šã‚’ä¿å­˜ã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©"""
    if service_choice in ["Discord", "Pushover"]:
        config_manager.save_config("notification_service", service_choice.lower())
        gr.Info(f"é€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã€Œ{service_choice}ã€ã«è¨­å®šã—ã¾ã—ãŸã€‚")
    return service_choice.lower()

def handle_save_discord_webhook(webhook_url: str):
    """Discord Webhook URLã‚’ä¿å­˜ã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©"""
    config_manager.save_config("notification_webhook_url", webhook_url)
    gr.Info("Discord Webhook URLã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

def load_system_prompt_content(character_name: str) -> str:
    """SystemPrompt.txtã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€"""
    if not character_name: return ""
    _, system_prompt_path, _, _, _ = get_character_files_paths(character_name)
    if system_prompt_path and os.path.exists(system_prompt_path):
        with open(system_prompt_path, "r", encoding="utf-8") as f:
            return f.read()
    return ""

def handle_save_system_prompt(character_name: str, content: str) -> None:
    """SystemPrompt.txtã®å†…å®¹ã‚’ä¿å­˜ã™ã‚‹"""
    if not character_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    _, system_prompt_path, _, _, _ = get_character_files_paths(character_name)
    if not system_prompt_path:
        gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚")
        return
    try:
        with open(system_prompt_path, "w", encoding="utf-8") as f:
            f.write(content)
        gr.Info(f"ã€Œ{character_name}ã€ã®äººæ ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        gr.Error(f"äººæ ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def handle_reload_system_prompt(character_name: str) -> str:
    """SystemPrompt.txtã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã‚¨ãƒ‡ã‚£ã‚¿ã«è¡¨ç¤ºã™ã‚‹"""
    if not character_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return ""
    content = load_system_prompt_content(character_name)
    gr.Info(f"ã€Œ{character_name}ã€ã®äººæ ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚")
    return content

# â–¼â–¼â–¼ ã“ã®é–¢æ•°ã‚’æ–°ã—ãè¿½åŠ  â–¼â–¼â–¼
def handle_rerun_button_click(
    selected_message: Optional[Dict[str, str]],
    character_name: str,
    api_key_name: str,
    file_list: Optional[List],
    api_history_limit: str,
    debug_mode: bool
):
    """
    ã€Œå†ç”Ÿæˆã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸéš›ã®å‡¦ç†ã€‚
    é¸æŠã•ã‚ŒãŸAIã®å¿œç­”ã¨ãã®ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å‰Šé™¤ã—ã€å†åº¦AIã«å¿œç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚
    """
    if not selected_message or not character_name:
        gr.Warning("å†ç”Ÿæˆã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        # ä½•ã‚‚ã›ãšã«ç¾åœ¨ã®ãƒãƒ£ãƒƒãƒˆçŠ¶æ…‹ã‚’è¿”ã™
        history, mapping_list = reload_chat_log(character_name, api_history_limit)
        # æˆ»ã‚Šå€¤ã®æ•°ã‚’æƒãˆã‚‹
        return (history, mapping_list, gr.update(), gr.update(), gr.update(),
                gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
                gr.update(visible=False))

    log_f, _, _, _, _ = get_character_files_paths(character_name)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›å†…å®¹ã‚’å¾©å…ƒã—ã€é–¢é€£ã™ã‚‹ãƒ­ã‚°ã‚’å‰Šé™¤
    restored_input_text = utils.delete_and_get_previous_user_input(log_f, selected_message, character_name)

    if restored_input_text is None:
        gr.Error("å†ç”Ÿæˆã®å…ƒã¨ãªã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        history, mapping_list = reload_chat_log(character_name, api_history_limit)
        return (history, mapping_list, gr.update(), gr.update(), gr.update(),
                gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
                gr.update(visible=False))

    gr.Info("å¿œç­”ã‚’å†ç”Ÿæˆã—ã¾ã™...")

    # handle_message_submission ã®éåŒæœŸå‡¦ç†ã‚’æ¨¡å€£
    # ã¾ãšã€UIã‚’ã€Œæ€è€ƒä¸­ã€ã®çŠ¶æ…‹ã«æ›´æ–°
    chatbot_history, _ = reload_chat_log(character_name, api_history_limit)
    chatbot_history.append((restored_input_text, "æ€è€ƒä¸­... â–Œ"))

    # handle_message_submission ã«å‡¦ç†ã‚’å§”è­²
    # yield from ã‚’ä½¿ã£ã¦ã€handle_message_submission ã® yield ã‚’ä¸­ç¶™ã™ã‚‹
    yield from handle_message_submission(
        restored_input_text, # å¾©å…ƒã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
        character_name,
        api_key_name,
        None, # å†å®Ÿè¡Œæ™‚ã¯ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ã‚’ã‚µãƒãƒ¼ãƒˆã—ãªã„
        api_history_limit,
        debug_mode
    )
