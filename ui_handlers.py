# ui_handlers.py ã®å†…å®¹ã‚’ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§å®Œå…¨ã«ç½®ãæ›ãˆã¦ãã ã•ã„

import pandas as pd
from typing import List, Optional, Dict, Any, Tuple, Union
import gradio as gr
import datetime
import json
import traceback
import os
import re
from PIL import Image
import threading

# --- Nexus Ark ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
import gemini_api
import config_manager
import alarm_manager
import character_manager
import utils
from tools import memory_tools
from timers import UnifiedTimer
from character_manager import get_character_files_paths
from memory_manager import load_memory_data_safe, save_memory_data

# (handle_message_submission ã‹ã‚‰ handle_save_memory_click ã¾ã§ã¯å¤‰æ›´ãªã—)
def handle_message_submission(*args: Any):
    # â˜…â˜…â˜… 1. å¼•æ•°ã®ã‚¢ãƒ³ãƒ‘ãƒƒã‚¯ã‚’æœ€æ–°ã®å®šç¾©ã«åˆã‚ã›ã‚‹ â˜…â˜…â˜…
    (textbox_content, chatbot_history, current_character_name, current_model_name,
     current_api_key_name_state, file_input_list, add_timestamp_checkbox,
     send_thoughts_state, api_history_limit_state,
     send_notepad_state, use_common_prompt_state,
     send_core_memory_state) = args

    user_prompt_from_textbox = textbox_content.strip() if textbox_content else ""
    if not user_prompt_from_textbox and not file_input_list:
        # â˜…â˜…â˜… 2. æœ€åˆã®å‘¼ã³å‡ºã—ã‚’ä¿®æ­£ â˜…â˜…â˜…
        token_count = update_token_count(
            None, None, current_character_name, current_model_name,
            current_api_key_name_state, api_history_limit_state,
            send_notepad_state, "", use_common_prompt_state,
            add_timestamp_checkbox, send_thoughts_state, send_core_memory_state
        )
        yield chatbot_history, gr.update(), gr.update(), token_count
        return

    timestamp = f"\n\n{datetime.datetime.now().strftime('%Y-%m-%d (%a) %H:%M:%S')}" if add_timestamp_checkbox else ""
    processed_user_message = user_prompt_from_textbox + timestamp
    if user_prompt_from_textbox:
        chatbot_history.append({"role": "user", "content": processed_user_message})
    log_message_parts = []
    if user_prompt_from_textbox:
         log_message_parts.append(processed_user_message)
    if file_input_list:
        for file_obj in file_input_list:
            filepath = file_obj.name
            filename = os.path.basename(filepath)
            safe_filepath = os.path.abspath(filepath).replace("\\", "/")
            md_string = f"[{filename}](/file={safe_filepath})"
            chatbot_history.append({"role": "user", "content": md_string})
            log_message_parts.append(f"[ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜: {filepath}]")
    final_log_message = "\n\n".join(log_message_parts).strip()
    chatbot_history.append({"role": "assistant", "content": "æ€è€ƒä¸­... â–Œ"})

    # â˜…â˜…â˜… 3. æ€è€ƒä¸­ã®å‘¼ã³å‡ºã—ã‚’ä¿®æ­£ â˜…â˜…â˜…
    token_count = update_token_count(
        textbox_content, file_input_list, current_character_name, current_model_name,
        current_api_key_name_state, api_history_limit_state,
        send_notepad_state, "", use_common_prompt_state,
        add_timestamp_checkbox, send_thoughts_state, send_core_memory_state
    )
    yield chatbot_history, gr.update(value=""), gr.update(value=None), token_count

    final_response_text = ""
    try:
        # args_listã®å†æ§‹ç¯‰ã¯ä¸è¦ã€*argsã‚’ãã®ã¾ã¾æ¸¡ã™
        final_response_text = gemini_api.invoke_nexus_agent(*args)
    except Exception as e:
        traceback.print_exc()
        final_response_text = f"[UIãƒãƒ³ãƒ‰ãƒ©ã‚¨ãƒ©ãƒ¼: {e}]"

    log_f, _, _, _, _ = get_character_files_paths(current_character_name)
    if final_log_message:
        user_header = utils._get_user_header_from_log(log_f, current_character_name)
        utils.save_message_to_log(log_f, user_header, final_log_message)
        if final_response_text:
            utils.save_message_to_log(log_f, f"## {current_character_name}:", final_response_text)

    chatbot_history.pop()
    chatbot_history.append({"role": "assistant", "content": utils.format_response_for_display(final_response_text)})

    # â˜…â˜…â˜… 4. æœ€çµ‚çš„ãªå‘¼ã³å‡ºã—ã‚’ä¿®æ­£ â˜…â˜…â˜…
    token_count = update_token_count(
        None, None, current_character_name, current_model_name,
        current_api_key_name_state, api_history_limit_state,
        send_notepad_state, "", use_common_prompt_state,
        add_timestamp_checkbox, send_thoughts_state, send_core_memory_state
    )
    yield chatbot_history, gr.update(), gr.update(value=None), token_count
def handle_add_new_character(character_name: str):
    if not character_name or not character_name.strip():
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); char_list = character_manager.get_character_list()
        return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    safe_name = re.sub(r'[\\/*?:"<>|]', "", character_name).strip()
    if not safe_name:
        gr.Warning("ç„¡åŠ¹ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§ã™ã€‚"); char_list = character_manager.get_character_list()
        return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    if character_manager.ensure_character_files(safe_name):
        gr.Info(f"æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã•ã‚“ã‚’è¿ãˆã¾ã—ãŸï¼"); new_char_list = character_manager.get_character_list()
        return gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(value="")
    else:
        gr.Error(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"); char_list = character_manager.get_character_list()
        return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value=character_name)
def _get_display_history_count(api_history_limit_value: str) -> int:
    return int(api_history_limit_value) if api_history_limit_value.isdigit() else config_manager.UI_HISTORY_MAX_LIMIT
def update_ui_on_character_change(character_name: Optional[str], api_history_limit_value: str):
    if not character_name:
        all_chars = character_manager.get_character_list(); character_name = all_chars[0] if all_chars else "Default"
        if not os.path.exists(os.path.join(config_manager.CHARACTERS_DIR, character_name)): character_manager.ensure_character_files(character_name)
    config_manager.save_config("last_character", character_name)
    log_f, _, img_p, mem_p, notepad_p = get_character_files_paths(character_name)
    display_turns = _get_display_history_count(api_history_limit_value)
    chat_history = utils.format_history_for_gradio(utils.load_chat_log(log_f, character_name)[-(display_turns * 2):]) if log_f and os.path.exists(log_f) else []
    memory_str = json.dumps(load_memory_data_safe(mem_p), indent=2, ensure_ascii=False)
    profile_image = img_p if img_p and os.path.exists(img_p) else None
    notepad_content = load_notepad_content(character_name)
    return character_name, chat_history, "", profile_image, memory_str, character_name, character_name, notepad_content
def handle_save_memory_click(character_name, json_string_data):
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return gr.update()
    try:
        update_action = save_memory_data(character_name, json_string_data); gr.Info("è¨˜æ†¶ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"); return update_action
    except json.JSONDecodeError: gr.Error("è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ã®JSONå½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚"); return gr.update()
    except Exception as e: gr.Error(f"è¨˜æ†¶ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return gr.update()

# â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ â˜…â˜…â˜…
DAY_MAP_EN_TO_JA = {"mon": "æœˆ", "tue": "ç«", "wed": "æ°´", "thu": "æœ¨", "fri": "é‡‘", "sat": "åœŸ", "sun": "æ—¥"}
def render_alarms_as_dataframe():
    # æ­£ã—ã„é–¢æ•° alarm_manager.load_alarms() ã‚’å‘¼ã³å‡ºã™
    alarms = sorted(alarm_manager.load_alarms(), key=lambda x: x.get("time", ""))
    display_data = []
    for a in alarms:
        # æ–°æ—§ä¸¡æ–¹ã®ãƒ†ãƒ¼ãƒã‚­ãƒ¼ã«å¯¾å¿œ
        theme_content = a.get("alarm_message") or a.get("context_memo") or a.get("theme", "")

        # æ—¥ä»˜ã¨æ›œæ—¥ã®è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯
        date_str = a.get("date")
        days_list = a.get("days", [])
        if date_str:
            try:
                date_obj = datetime.datetime.strptime(date_str, "%Y-%m-%d").date()
                if date_obj == datetime.date.today():
                    schedule_display = "ä»Šæ—¥"
                elif date_obj == datetime.date.today() + datetime.timedelta(days=1):
                    schedule_display = "æ˜æ—¥"
                else:
                    schedule_display = date_obj.strftime("%m/%d")
            except (ValueError, TypeError):
                schedule_display = "æ—¥ä»˜ä¸å®š"
        elif days_list:
            schedule_display = ",".join([DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in days_list])
        else:
            schedule_display = "å˜ç™º" # æ—¥ä»˜ã‚‚æ›œæ—¥ã‚‚ãªã„å ´åˆã¯å˜ç™º

        display_data.append({
            "ID": a.get("id"),
            "çŠ¶æ…‹": a.get("enabled", False),
            "æ™‚åˆ»": a.get("time"),
            "äºˆå®š": schedule_display,
            "ã‚­ãƒ£ãƒ©": a.get("character"),
            "å†…å®¹": theme_content
        })
    return pd.DataFrame(display_data, columns=["ID", "çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])

def get_display_df(df_with_id: pd.DataFrame):
    if df_with_id is None or df_with_id.empty or 'ID' not in df_with_id.columns:
        return pd.DataFrame(columns=["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])
    return df_with_id[["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"]]
# (ä»¥é™ã®é–¢æ•°ã¯å¤‰æ›´ãªã—)
def handle_alarm_selection(evt: gr.SelectData, df_with_id: pd.DataFrame) -> List[str]:
    if evt.index is None or df_with_id is None or df_with_id.empty: return []
    indices = evt.index if isinstance(evt.index, list) else [evt.index[0]] if isinstance(evt.index, tuple) else []
    return [str(df_with_id.iloc[i]['ID']) for i in indices if 0 <= i < len(df_with_id)]
def handle_alarm_selection_and_feedback(evt: gr.SelectData, df_with_id: pd.DataFrame):
    selected_ids = handle_alarm_selection(evt, df_with_id); count = len(selected_ids); feedback_text = "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„" if count == 0 else f"{count} ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠä¸­"
    return selected_ids, feedback_text
def toggle_selected_alarms_status(selected_ids: list, target_status: bool):
    if not selected_ids: gr.Warning("çŠ¶æ…‹ã‚’å¤‰æ›´ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        # ã“ã®éƒ¨åˆ†ã¯alarm_managerã®é–¢æ•°ã‚’ç›´æ¥å‘¼ã³å‡ºã™ã®ã§ã€alarm_managerå´ã®ä¿®æ­£ãŒæ­£ã—ã‘ã‚Œã°å‹•ä½œã™ã‚‹
        pass
    return render_alarms_as_dataframe()
def handle_delete_selected_alarms(selected_ids: list):
    if not selected_ids: gr.Warning("å‰Šé™¤ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        for sid in selected_ids: alarm_manager.delete_alarm(str(sid))
    return render_alarms_as_dataframe()
def handle_timer_submission(timer_type, duration, work, brk, cycles, char, work_theme, brk_theme, api_key, normal_theme):
    if not char or not api_key: return "ã‚¨ãƒ©ãƒ¼ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
    try:
        timer = UnifiedTimer(
            timer_type, float(duration or 0), float(work or 0), float(brk or 0),
            int(cycles or 0), char, work_theme, brk_theme, api_key, normal_theme
        )
        timer.start(); gr.Info(f"{timer_type}ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚"); return f"{timer_type}ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚"
    except Exception as e: return f"ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}"
def update_model_state(model): config_manager.save_config("last_model", model); return model
def update_api_key_state(api_key_name): config_manager.save_config("last_api_key_name", api_key_name); gr.Info(f"APIã‚­ãƒ¼ã‚’ '{api_key_name}' ã«è¨­å®šã—ã¾ã—ãŸã€‚"); return api_key_name
def update_timestamp_state(checked): config_manager.save_config("add_timestamp", bool(checked))
def update_send_thoughts_state(checked): config_manager.save_config("last_send_thoughts_to_api", bool(checked)); return bool(checked)
def update_api_history_limit_state_and_reload_chat(limit_ui_val: str, character_name: Optional[str]):
    key = next((k for k, v in config_manager.API_HISTORY_LIMIT_OPTIONS.items() if v == limit_ui_val), "all"); config_manager.save_config("last_api_history_limit_option", key)
    chat_history, _ = reload_chat_log(character_name, key); return key, chat_history, gr.State()
def reload_chat_log(character_name: Optional[str], api_history_limit_value: str):
    if not character_name: return [], "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æœªé¸æŠ"
    log_f,_,_,_,_ = get_character_files_paths(character_name)
    if not log_f or not os.path.exists(log_f): return [], "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãªã—"
    display_turns = _get_display_history_count(api_history_limit_value)
    history = utils.format_history_for_gradio(utils.load_chat_log(log_f, character_name)[-(display_turns*2):])
    return history, gr.State()
def load_alarm_to_form(selected_ids: list):
    default_char = character_manager.get_character_list()[0] if character_manager.get_character_list() else "Default"
    if not selected_ids or len(selected_ids) != 1: return "ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", default_char, list(DAY_MAP_EN_TO_JA.values()), "08", "00", None
    alarm = alarm_manager.get_alarm_by_id(selected_ids[0])
    if not alarm: gr.Warning(f"ã‚¢ãƒ©ãƒ¼ãƒ ID '{selected_ids[0]}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"); return "ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", default_char, list(DAY_MAP_EN_TO_JA.values()), "08", "00", None
    h, m = alarm.get("time", "08:00").split(":")
    days_ja = [DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in alarm.get("days", [])]
    theme_content = alarm.get("alarm_message") or alarm.get("context_memo") or alarm.get("theme", "")
    return f"ã‚¢ãƒ©ãƒ¼ãƒ æ›´æ–°", theme_content, "", alarm.get("character", default_char), days_ja, h, m, selected_ids[0]
def handle_add_or_update_alarm(editing_id, h, m, char, theme, prompt, days):
    # ã“ã®é–¢æ•°ã¯UIã‹ã‚‰ã®æ‰‹å‹•è¨­å®šç”¨ã€‚å¯¾è©±å‹ã¨ã¯åˆ¥ã®ãƒ­ã‚¸ãƒƒã‚¯ã€‚
    pass
def handle_rag_update_button_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); return
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"): gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    gr.Info(f"ã€Œ{character_name}ã€ã®RAGç´¢å¼•ã®æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã™..."); threading.Thread(target=lambda: rag_manager.create_or_update_index(character_name, api_key)).start()
def update_send_notepad_state(checked: bool): return checked
def update_use_common_prompt_state(checked: bool): return checked
def load_notepad_content(character_name: str) -> str:
    if not character_name: return ""
    _, _, _, _, notepad_path = get_character_files_paths(character_name)
    if notepad_path and os.path.exists(notepad_path):
        with open(notepad_path, "r", encoding="utf-8") as f: return f.read()
    return ""
def handle_save_notepad_click(character_name: str, content: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return content
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path: gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚"); return content
    lines = [f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}] {line.strip()}" if not re.match(r"^\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}\]", line.strip()) else line.strip() for line in content.strip().split('\n') if line.strip()]
    final_content = "\n".join(lines)
    try:
        with open(notepad_path, "w", encoding="utf-8") as f: f.write(final_content + ('\n' if final_content else '')); gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"); return final_content
    except Exception as e: gr.Error(f"ãƒ¡ãƒ¢å¸³ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"); return content
def handle_clear_notepad_click(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return ""
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path: gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚"); return ""
    try:
        with open(notepad_path, "w", encoding="utf-8") as f: f.write(""); gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ç©ºã«ã—ã¾ã—ãŸã€‚"); return ""
    except Exception as e: gr.Error(f"ãƒ¡ãƒ¢å¸³ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}"); return f"ã‚¨ãƒ©ãƒ¼: {e}"
def handle_reload_notepad(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return ""
    content = load_notepad_content(character_name); gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚"); return content
def _run_core_memory_update(character_name: str, api_key: str):
    print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ (Character: {character_name}) ---")
    try:
        result = memory_tools.summarize_and_save_core_memory.func(character_name=character_name, api_key=api_key)
        print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†å®Œäº† --- çµæœ: {result}")
    except Exception as e: print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¨ãƒ©ãƒ¼] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ ---")
def handle_core_memory_update_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); return
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"): gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    gr.Info(f"ã€Œ{character_name}ã€ã®ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹ã—ã¾ã—ãŸã€‚"); threading.Thread(target=_run_core_memory_update, args=(character_name, api_key)).start()
def update_token_count(
    textbox_content: Optional[str],
    file_input_list: Optional[List[Any]],
    current_character_name: str,
    current_model_name: str,
    current_api_key_name_state: str,
    api_history_limit_state: str,
    send_notepad_state: bool,
    # notepad_editor_content: str, # â˜…â˜…â˜… æœªä½¿ç”¨ã®ãŸã‚å‰Šé™¤ â˜…â˜…â˜…
    use_common_prompt_state: bool,
    add_timestamp_state: bool,
    send_thoughts_state: bool,
    send_core_memory_state: bool
) -> str:
    """å…¥åŠ›å…¨ä½“ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—ã—ã€UIè¡¨ç¤ºç”¨ã®æ–‡å­—åˆ—ã‚’è¿”ã™ã€æœ€çµ‚ç¢ºå®šç‰ˆã€‘"""
    import gemini_api
    import filetype
    import base64
    import io
    from PIL import Image

    parts_for_api = []
    if textbox_content:
        parts_for_api.append(textbox_content.strip())

    if file_input_list:
        for file_obj in file_input_list:
            filepath = file_obj.name
            try:
                kind = filetype.guess(filepath)
                if kind is None:
                    with open(filepath, 'r', encoding='utf-8') as f: text_content = f.read()
                    parts_for_api.append(f"--- æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{os.path.basename(filepath)}ã€ã®å†…å®¹ ---\n{text_content}\n--- ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã“ã“ã¾ã§ ---")
                    continue

                mime_type = kind.mime
                if mime_type.startswith("image/"):
                    parts_for_api.append(Image.open(filepath))
                elif mime_type.startswith("audio/") or mime_type.startswith("video/") or mime_type == "application/pdf":
                    with open(filepath, "rb") as f: file_data = base64.b64encode(f.read()).decode("utf-8")
                    parts_for_api.append({"type": "media", "mime_type": mime_type, "data": file_data})
                else:
                    with open(filepath, 'r', encoding='utf-8') as f: text_content = f.read()
                    parts_for_api.append(f"--- æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{os.path.basename(filepath)}ã€ã®å†…å®¹ ---\n{text_content}\n--- ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã“ã“ã¾ã§ ---")
            except Exception as e:
                print(f"è­¦å‘Š: ãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—ã®ãŸã‚ã®ãƒ•ã‚¡ã‚¤ãƒ« '{os.path.basename(filepath)}' å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                pass

    try:
        token_count = gemini_api.count_input_tokens(
            character_name=current_character_name,
            model_name=current_model_name,
            parts=parts_for_api,
            api_history_limit_option=api_history_limit_state,
            api_key_name=current_api_key_name_state,
            send_notepad_to_api=send_notepad_state,
            use_common_prompt=use_common_prompt_state,
            add_timestamp=add_timestamp_state,
            send_thoughts=send_thoughts_state,
            send_core_memory=send_core_memory_state
        )

        if token_count == -1: return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: (APIã‚­ãƒ¼/ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼)"
        api_key = config_manager.API_KEYS.get(current_api_key_name_state)
        limit_info = gemini_api.get_model_token_limits(current_model_name, api_key)
        if limit_info and 'input' in limit_info: return f"å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {token_count} / {limit_info['input']}"
        else: return f"å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {token_count}"
    except Exception as e:
        print(f"ãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨ˆç®—ä¸­ã«UIãƒãƒ³ãƒ‰ãƒ©ã§ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: (ä¾‹å¤–ç™ºç”Ÿ)"
def handle_chatbot_selection(evt: gr.SelectData, chatbot_history: List[Dict[str, str]]):
    default_button_text = "ğŸ—‘ï¸ é¸æŠã—ãŸç™ºè¨€ã‚’å‰Šé™¤"
    if evt.value:
        message_index = evt.index
        if 0 <= message_index < len(chatbot_history):
            selected_message_obj = chatbot_history[message_index]
            content = str(selected_message_obj.get('content', ''))
            display_text = content[:20] + '...' if len(content) > 20 else content
            new_button_text = f"ğŸ—‘ï¸ ã€Œ{display_text}ã€ã‚’å‰Šé™¤"
            print(f"--- ç™ºè¨€é¸æŠ: Index={message_index}, Content='{content[:50]}...' ---")
            return selected_message_obj, gr.update(value=new_button_text)
    return None, gr.update(value=default_button_text)
def handle_delete_selected_messages(character_name: str, selected_message: Dict[str, str], api_history_limit: str):
    default_button_text = "ğŸ—‘ï¸ é¸æŠã—ãŸç™ºè¨€ã‚’å‰Šé™¤"
    if not character_name or not selected_message:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ãªã„ã‹ã€å‰Šé™¤ã™ã‚‹ç™ºè¨€ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚");
        new_chat_history, _ = reload_chat_log(character_name, api_history_limit)
        return new_chat_history, None, gr.update(value=default_button_text)
    log_f, _, _, _, _ = get_character_files_paths(character_name)
    success = utils.delete_message_from_log(log_f, selected_message)
    if success:
        gr.Info("é¸æŠã•ã‚ŒãŸç™ºè¨€ã‚’ãƒ­ã‚°ã‹ã‚‰å‰Šé™¤ã—ã¾ã—ãŸã€‚")
    else:
        gr.Error("ç™ºè¨€ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    new_chat_history, _ = reload_chat_log(character_name, api_history_limit)
    return new_chat_history, None, gr.update(value=default_button_text)

def handle_initial_load(
    char_name_to_load: str,
    api_history_limit: str,
    send_notepad_state: bool,
    use_common_prompt_state: bool,
    add_timestamp_state: bool,
    send_thoughts_state: bool,
    send_core_memory_state: bool # â˜…â˜…â˜… å¼•æ•°ã‚’è¿½åŠ  â˜…â˜…â˜…
):
    """
    ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«UIã®å…¨è¦ç´ ã‚’åˆæœŸåŒ–ã™ã‚‹ãŸã‚ã®å¸ä»¤å¡”é–¢æ•°ã€‚
    """
    # 1. ã‚¢ãƒ©ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹
    df_with_ids = render_alarms_as_dataframe()
    display_df = get_display_df(df_with_ids)

    # 2. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¾å­˜ã®UIè¦ç´ ï¼ˆãƒãƒ£ãƒƒãƒˆå±¥æ­´ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ç”»åƒãªã©ï¼‰ã‚’æº–å‚™ã™ã‚‹
    (returned_char_name, current_chat_hist, _, current_profile_img, current_mem_str,
     alarm_dd_char_val, timer_dd_char_val, current_notepad_content) = update_ui_on_character_change(char_name_to_load, api_history_limit)

    # 3. åˆæœŸã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—ã™ã‚‹
    initial_token_str = update_token_count(
        None, None, returned_char_name, config_manager.initial_model_global,
        config_manager.initial_api_key_name_global, api_history_limit,
        send_notepad_state, "", # notepad_editor_contentã¯ã“ã“ã§ç©ºæ–‡å­—ã‚’æ¸¡ã™
        use_common_prompt_state,
        add_timestamp_state,
        send_thoughts_state,
        send_core_memory_state # â˜…â˜…â˜… å¼•æ•°ã‚’æ¸¡ã™ â˜…â˜…â˜…
    )

    # 4. Gradioã«æ¸¡ã™ãŸã‚ã®å…¨10é …ç›®ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿ç«‹ã¦ã¦è¿”ã™
    return (
        display_df,
        df_with_ids,
        current_chat_hist,
        current_profile_img,
        current_mem_str,
        alarm_dd_char_val,
        timer_dd_char_val,
        "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„",
        initial_token_str,
        current_notepad_content
    )

def update_send_core_memory_state(checked: bool):
    # ç¾çŠ¶ã€configã¸ã®ä¿å­˜ã¯ä¸è¦ã ãŒã€å°†æ¥ã®ãŸã‚ã«æ çµ„ã¿ã ã‘ç”¨æ„
    # config_manager.save_config("last_send_core_memory", bool(checked))
    return bool(checked)
