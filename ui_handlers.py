# ui_handlers.py

from world_builder import get_world_data, generate_details_markdown, convert_data_to_yaml_str
import yaml
from typing import Dict, Any, Optional, Tuple, List
import character_manager
import gradio as gr
import json
import shutil
from yaml.constructor import ConstructorError

# Keep all other existing imports and functions from the original ui_handlers.py
# For brevity, I'm only showing the new/changed functions.
# The `overwrite_file_with_block` will replace the whole file,
# so I need to reconstruct it with the old and new parts.

# [ ... all existing functions from the top of ui_handlers.py until the old world builder functions ... ]
# I will reconstruct the file from the last `read_file` output.
# ui_handlers.py (å®Œå…¨æœ€çµ‚ç‰ˆ)

import pandas as pd
import json
import traceback
import hashlib
import os
import re
from typing import List, Optional, Dict, Any, Tuple
import gradio as gr
import datetime
from PIL import Image
import threading
import filetype
import base64
import io
import uuid
from tools.image_tools import generate_image as generate_image_tool_func
from yaml.constructor import ConstructorError
import yaml
import pytz


import gemini_api, config_manager, alarm_manager, character_manager, utils, constants
from agent.graph import generate_scenery_context
from timers import UnifiedTimer
from character_manager import get_character_files_paths, get_world_settings_path
from memory_manager import load_memory_data_safe, save_memory_data
from world_builder import get_world_data, save_world_data, generate_details_markdown, convert_data_to_yaml_str

DAY_MAP_EN_TO_JA = {"mon": "æœˆ", "tue": "ç«", "wed": "æ°´", "thu": "æœ¨", "fri": "é‡‘", "sat": "åœŸ", "sun": "æ—¥"}
DAY_MAP_JA_TO_EN = {v: k for k, v in DAY_MAP_EN_TO_JA.items()}


def _get_location_choices_for_ui(character_name: str) -> list:
    """
    UIã®ç§»å‹•å…ˆDropdownç”¨ã®ã€ã‚¨ãƒªã‚¢ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸé¸æŠè‚¢ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã«ã‚ˆã‚‹ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã§éšå±¤ã‚’è¡¨ç¾ã™ã‚‹ã€‚
    """
    if not character_name: return []

    world_settings_path = get_world_settings_path(character_name)
    world_data = utils.parse_world_markdown(world_settings_path)

    if not world_data: return []

    choices = []
    sorted_area_ids = sorted(world_data.keys(), key=lambda k: world_data[k].get('name', k))

    for area_id in sorted_area_ids:
        area_data = world_data[area_id]
        if not isinstance(area_data, dict): continue

        area_name = area_data.get('name', area_id)
        # ã‚¨ãƒªã‚¢è¦‹å‡ºã—ã‚’è¿½åŠ  (é¸æŠä¸å¯ã«ã™ã‚‹ãŸã‚å€¤ã¯å°‚ç”¨ID)
        choices.append((f"[{area_name}]", f"__AREA_HEADER_{area_id}"))

        room_list = []
        for room_id, room_data in area_data.items():
            if isinstance(room_data, dict) and 'name' in room_data:
                room_list.append((room_data['name'], room_id))

        for room_name, room_id in sorted(room_list):
            # â–¼â–¼â–¼ ã“ã®è¡Œã‚’ä¿®æ­£ â–¼â–¼â–¼
            # ã‚·ãƒ³ãƒ—ãƒ«ãªå³çŸ¢å°è¨˜å·ã«å¤‰æ›´
            choices.append((f"\u00A0\u00A0â†’ {room_name}", room_id))

    return choices

def handle_initial_load():
    print("--- UIåˆæœŸåŒ–å‡¦ç†(handle_initial_load)ã‚’é–‹å§‹ã—ã¾ã™ ---")
    df_with_ids = render_alarms_as_dataframe()
    display_df, feedback_text = get_display_df(df_with_ids), "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„"
    char_dependent_outputs = handle_character_change(config_manager.initial_character_global, config_manager.initial_api_key_name_global)
    return (display_df, df_with_ids, feedback_text) + char_dependent_outputs

def handle_character_change(character_name: str, api_key_name: str):
    if not character_name:
        char_list = character_manager.get_character_list()
        character_name = char_list[0] if char_list else "Default"

    print(f"--- UIæ›´æ–°å¸ä»¤å¡”(handle_character_change)å®Ÿè¡Œ: {character_name} ---")
    config_manager.save_config("last_character", character_name)

    chat_history, mapping_list = reload_chat_log(character_name, config_manager.initial_api_history_limit_option_global)

    _, _, img_p, mem_p, notepad_p = get_character_files_paths(character_name)

    memory_str = json.dumps(load_memory_data_safe(mem_p), indent=2, ensure_ascii=False)
    profile_image = img_p if img_p and os.path.exists(img_p) else None
    notepad_content = load_notepad_content(character_name)

    # â–¼â–¼â–¼ ä¿®æ­£ãƒ–ãƒ­ãƒƒã‚¯ â–¼â–¼â–¼
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰ç„¡ã«é–¢ã‚ã‚‰ãšã€ä¸€åº¦APIã‚­ãƒ¼ã‚’å–å¾—ã™ã‚‹
    api_key = config_manager.API_KEYS.get(api_key_name)
    # å¸¸ã« generate_scenery_context ã‚’å‘¼ã³å‡ºã™ã“ã¨ã§ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ©æµã‚’å—ã‘ã‚‹
    current_location_name, _, scenery_text = generate_scenery_context(character_name, api_key)
    scenery_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))
    # â–²â–²â–² ä¿®æ­£ãƒ–ãƒ­ãƒƒã‚¯ã“ã“ã¾ã§ â–²â–²â–²

    locations = _get_location_choices_for_ui(character_name)
    location_dd_val = utils.get_current_location(character_name)

    effective_settings = config_manager.get_effective_settings(character_name)
    all_models = ["ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"] + config_manager.AVAILABLE_MODELS_GLOBAL
    model_val = effective_settings["model_name"] if effective_settings["model_name"] != config_manager.initial_model_global else "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"
    voice_display_name = config_manager.SUPPORTED_VOICES.get(effective_settings.get("voice_id", "vindemiatrix"), list(config_manager.SUPPORTED_VOICES.values())[0])
    voice_style_prompt_val = effective_settings.get("voice_style_prompt", "")

    return (
        character_name, chat_history, mapping_list, "", profile_image, memory_str,
        character_name, character_name, notepad_content,
        gr.update(choices=locations, value=location_dd_val),
        current_location_name, scenery_text,
        gr.update(choices=all_models, value=model_val),
        voice_display_name, voice_style_prompt_val,
        effective_settings["add_timestamp"], effective_settings["send_thoughts"],
        effective_settings["send_notepad"], effective_settings["use_common_prompt"],
        effective_settings["send_core_memory"], effective_settings["send_scenery"],
        f"â„¹ï¸ *ç¾åœ¨é¸æŠä¸­ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{character_name}ã€ã«ã®ã¿é©ç”¨ã•ã‚Œã‚‹è¨­å®šã§ã™ã€‚*", scenery_image_path
    )

def handle_save_char_settings(character_name: str, model_name: str, voice_name: str, voice_style_prompt: str, add_timestamp: bool, send_thoughts: bool, send_notepad: bool, use_common_prompt: bool, send_core_memory: bool, send_scenery: bool):
    if not character_name: gr.Warning("è¨­å®šã‚’ä¿å­˜ã™ã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return
    new_settings = {
        "model_name": model_name if model_name != "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ" else None,
        "voice_id": next((k for k, v in config_manager.SUPPORTED_VOICES.items() if v == voice_name), None),
        "voice_style_prompt": voice_style_prompt.strip(),
        "add_timestamp": bool(add_timestamp), "send_thoughts": bool(send_thoughts), "send_notepad": bool(send_notepad),
        "use_common_prompt": bool(use_common_prompt), "send_core_memory": bool(send_core_memory), "send_scenery": bool(send_scenery),
    }
    try:
        char_config_path = os.path.join(constants.CHARACTERS_DIR, character_name, "character_config.json")
        config = {}
        if os.path.exists(char_config_path) and os.path.getsize(char_config_path) > 0:
            with open(char_config_path, "r", encoding="utf-8") as f: config = json.load(f)
        if "override_settings" not in config: config["override_settings"] = {}
        config["override_settings"].update(new_settings)
        config["last_updated"] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with open(char_config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        gr.Info(f"ã€Œ{character_name}ã€ã®å€‹åˆ¥è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e: gr.Error(f"å€‹åˆ¥è¨­å®šã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); traceback.print_exc()

def handle_context_settings_change(character_name: str, api_key_name: str, api_history_limit: str, add_timestamp: bool, send_thoughts: bool, send_notepad: bool, use_common_prompt: bool, send_core_memory: bool, send_scenery: bool):
    if not character_name or not api_key_name: return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: -"
    return gemini_api.count_input_tokens(
        character_name=character_name, api_key_name=api_key_name, parts=[],
        api_history_limit=api_history_limit,
        add_timestamp=add_timestamp, send_thoughts=send_thoughts, send_notepad=send_notepad,
        use_common_prompt=use_common_prompt, send_core_memory=send_core_memory, send_scenery=send_scenery
    )

def update_token_count_on_input(character_name: str, api_key_name: str, api_history_limit: str, textbox_content: str, file_list: list, add_timestamp: bool, send_thoughts: bool, send_notepad: bool, use_common_prompt: bool, send_core_memory: bool, send_scenery: bool):
    if not character_name or not api_key_name: return "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: -"
    parts_for_api = []
    if textbox_content: parts_for_api.append(textbox_content)
    if file_list:
        for file_obj in file_list: parts_for_api.append(Image.open(file_obj.name))
    return gemini_api.count_input_tokens(
        character_name=character_name, api_key_name=api_key_name, parts=parts_for_api,
        api_history_limit=api_history_limit,
        add_timestamp=add_timestamp, send_thoughts=send_thoughts, send_notepad=send_notepad,
        use_common_prompt=use_common_prompt, send_core_memory=send_core_memory, send_scenery=send_scenery
    )

def handle_message_submission(*args: Any):
    (textbox_content, current_character_name, current_api_key_name_state,
     file_input_list, api_history_limit_state, debug_mode_state) = args
    user_prompt_from_textbox = textbox_content.strip() if textbox_content else ""
    if not user_prompt_from_textbox and not file_input_list:
        chatbot_history, mapping_list = reload_chat_log(current_character_name, api_history_limit_state)
        return chatbot_history, mapping_list, gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update()

    effective_settings = config_manager.get_effective_settings(current_character_name)
    add_timestamp_checkbox = effective_settings.get("add_timestamp", False)

    chatbot_history, _ = reload_chat_log(current_character_name, api_history_limit_state)

    log_message_parts = []
    if user_prompt_from_textbox:
        timestamp = f"\n\n{datetime.datetime.now().strftime('%Y-%m-%d (%a) %H:%M:%S')}" if add_timestamp_checkbox else ""
        processed_user_message = user_prompt_from_textbox + timestamp
        chatbot_history.append((processed_user_message, None))
        log_message_parts.append(processed_user_message)
    if file_input_list:
        for file_obj in file_input_list:
            filepath, filename = file_obj.name, os.path.basename(file_obj.name)
            chatbot_history.append(((filepath, filename), None))
            log_message_parts.append(f"[ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜: {filepath}]")

    chatbot_history.append((None, "æ€è€ƒä¸­... â–Œ"))

    yield (chatbot_history, [], gr.update(value=""), gr.update(value=None), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update())

    response_data = {}
    try:
        agent_args = (
            textbox_content, current_character_name, current_api_key_name_state,
            file_input_list, api_history_limit_state, debug_mode_state
        )
        response_data = gemini_api.invoke_nexus_agent(*agent_args)
    except Exception as e:
        traceback.print_exc()
        response_data = {"response": f"[UIãƒãƒ³ãƒ‰ãƒ©ã‚¨ãƒ©ãƒ¼: {e}]", "location_name": "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰", "scenery": "ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰"}

    final_response_text = response_data.get("response", "")
    location_name, scenery_text = response_data.get("location_name", "ï¼ˆå–å¾—å¤±æ•—ï¼‰"), response_data.get("scenery", "ï¼ˆå–å¾—å¤±æ•—ï¼‰")

    if not final_response_text or not final_response_text.strip():
        print("--- è­¦å‘Š: AIã‹ã‚‰ã®å¿œç­”ãŒç©ºã®ãŸã‚ã€å¾Œç¶šå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ ---")
        formatted_history, new_mapping_list = reload_chat_log(current_character_name, api_history_limit_state)
        new_alarm_df_with_ids = render_alarms_as_dataframe()
        new_display_df = get_display_df(new_alarm_df_with_ids)

        current_location_id = utils.get_current_location(current_character_name)
        scenery_image_path = utils.find_scenery_image(current_character_name, current_location_id)

        yield (formatted_history, new_mapping_list, gr.update(), gr.update(value=None),
               gr.update(), location_name, scenery_text, new_alarm_df_with_ids,
               new_display_df, scenery_image_path)
        return

    scenery_image_path = None
    if not location_name.startswith("ï¼ˆ"):
        # save_scenery_cache ã®å‘¼ã³å‡ºã—ã‚’å‰Šé™¤ã€‚ä¿å­˜ã¯ generate_scenery_context ãŒè²¬ä»»ã‚’æŒã¤ã€‚
        current_location_id = utils.get_current_location(current_character_name)
        scenery_image_path = utils.find_scenery_image(current_character_name, current_location_id)

    log_f, _, _, _, _ = get_character_files_paths(current_character_name)
    final_log_message = "\n\n".join(log_message_parts).strip()
    if final_log_message:
        user_header = utils._get_user_header_from_log(log_f, current_character_name)
        utils.save_message_to_log(log_f, user_header, final_log_message)

    utils.save_message_to_log(log_f, f"## {current_character_name}:", final_response_text)

    formatted_history, new_mapping_list = reload_chat_log(current_character_name, api_history_limit_state)
    new_alarm_df_with_ids = render_alarms_as_dataframe()
    new_display_df = get_display_df(new_alarm_df_with_ids)

    yield (formatted_history, new_mapping_list, gr.update(), gr.update(value=None),
           gr.update(), location_name, scenery_text, new_alarm_df_with_ids,
           new_display_df, scenery_image_path)

def handle_scenery_refresh(character_name: str, api_key_name: str) -> Tuple[str, str, Optional[str]]:
    """ã€Œæƒ…æ™¯ã‚’æ›´æ–°ã€ãƒœã‚¿ãƒ³å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«å†ç”Ÿæˆã™ã‚‹ã€‚"""
    if not character_name or not api_key_name:
        return "ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªé¸æŠã§ã™ï¼‰", "ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªé¸æŠã§ã™ï¼‰", None

    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key:
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", None

    gr.Info(f"ã€Œ{character_name}ã€ã®ç¾åœ¨ã®æƒ…æ™¯ã‚’å¼·åˆ¶çš„ã«å†ç”Ÿæˆã—ã¦ã„ã¾ã™...")

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šè²¬å‹™ã‚’ agent/graph.py ã«å§”è­² â–¼â–¼â–¼
    location_name, _, scenery_text = generate_scenery_context(character_name, api_key, force_regenerate=True)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    if not location_name.startswith("ï¼ˆ"):
        gr.Info("æƒ…æ™¯ã‚’å†ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        scenery_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))
    else:
        gr.Error("æƒ…æ™¯ã®å†ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        scenery_image_path = None

    return location_name, scenery_text, scenery_image_path

def handle_location_change(character_name: str, selected_value: str, api_key_name: str) -> Tuple[str, str, Optional[str]]:
    # â–¼â–¼â–¼ ä¿®æ­£ãƒ–ãƒ­ãƒƒã‚¯ã“ã“ã‹ã‚‰ â–¼â–¼â–¼
    if not selected_value or selected_value.startswith("__AREA_HEADER_"):
        # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã‹ã€å€¤ãŒãªã„å ´åˆã¯ä½•ã‚‚ã—ãªã„
        # ç¾åœ¨ã®çŠ¶æ…‹ã‚’ãã®ã¾ã¾è¿”ã™
        location_name, _, scenery_text = generate_scenery_context(character_name, config_manager.API_KEYS.get(api_key_name))
        scenery_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))
        return location_name, scenery_text, scenery_image_path

    location_id = selected_value
    # â–²â–²â–² ä¿®æ­£ãƒ–ãƒ­ãƒƒã‚¯ã“ã“ã¾ã§ â–²â–²â–²

    from tools.space_tools import set_current_location
    print(f"--- UIã‹ã‚‰ã®å ´æ‰€å¤‰æ›´å‡¦ç†é–‹å§‹: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼='{character_name}', ç§»å‹•å…ˆID='{location_id}' ---")

    # ç¾åœ¨ã®è¡¨ç¤ºå†…å®¹ã‚’ä¸€æ™‚çš„ã«å–å¾—
    scenery_cache = utils.load_scenery_cache(character_name)
    current_loc_name = scenery_cache.get("location_name", "ï¼ˆå ´æ‰€ä¸æ˜ï¼‰")
    scenery_text = scenery_cache.get("scenery_text", "ï¼ˆæƒ…æ™¯ä¸æ˜ï¼‰")
    current_image_path = utils.find_scenery_image(character_name, utils.get_current_location(character_name))

    if not character_name or not location_id:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ç§»å‹•å…ˆã®å ´æ‰€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return current_loc_name, scenery_text, current_image_path

    # ã¾ãšå ´æ‰€ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ã‚’æ›´æ–°
    result = set_current_location.func(location=location_id, character_name=character_name)
    if "Success" not in result:
        gr.Error(f"å ´æ‰€ã®å¤‰æ›´ã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
        return current_loc_name, scenery_text, current_image_path

    gr.Info(f"å ´æ‰€ã‚’ã€Œ{location_id}ã€ã«ç§»å‹•ã—ã¾ã—ãŸã€‚æƒ…æ™¯ã‚’æ›´æ–°ã—ã¾ã™...")

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒ â–¼â–¼â–¼
    # ç§»å‹•å¾Œã«ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è€ƒæ…®ã—ãŸæƒ…æ™¯å–å¾—é–¢æ•°ã‚’å‘¼ã³å‡ºã™
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key:
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", "ï¼ˆAPIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰", None

    new_location_name, _, new_scenery_text = generate_scenery_context(character_name, api_key)
    new_image_path = utils.find_scenery_image(character_name, location_id)
    # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

    return new_location_name, new_scenery_text, new_image_path

def handle_add_new_character(character_name: str):
    char_list = character_manager.get_character_list()
    if not character_name or not character_name.strip():
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    safe_name = re.sub(r'[\\/*?:"<>|]', "", character_name).strip()
    if not safe_name:
        gr.Warning("ç„¡åŠ¹ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§ã™ã€‚"); return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value="")
    if character_manager.ensure_character_files(safe_name):
        gr.Info(f"æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã•ã‚“ã‚’è¿ãˆã¾ã—ãŸï¼"); new_char_list = character_manager.get_character_list(); return gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(choices=new_char_list, value=safe_name), gr.update(value="")
    else:
        gr.Error(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{safe_name}ã€ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"); return gr.update(choices=char_list), gr.update(choices=char_list), gr.update(choices=char_list), gr.update(value=character_name)

def _get_display_history_count(api_history_limit_value: str) -> int: return int(api_history_limit_value) if api_history_limit_value.isdigit() else constants.UI_HISTORY_MAX_LIMIT

def handle_chatbot_selection(character_name: str, api_history_limit_state: str, mapping_list: list, evt: gr.SelectData):
    if not character_name or evt.index is None or not mapping_list: return None, gr.update(visible=False)
    try:
        clicked_ui_index = evt.index[0]
        if not (0 <= clicked_ui_index < len(mapping_list)):
            gr.Warning(f"ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ (UI index {clicked_ui_index} out of bounds for mapping list size {len(mapping_list)})."); return None, gr.update(visible=False)

        log_f, _, _, _, _ = get_character_files_paths(character_name)
        raw_history = utils.load_chat_log(log_f, character_name)
        display_turns = _get_display_history_count(api_history_limit_state)
        visible_raw_history = raw_history[-(display_turns * 2):]

        original_log_index = mapping_list[clicked_ui_index]
        if 0 <= original_log_index < len(visible_raw_history):
            return visible_raw_history[original_log_index], gr.update(visible=True)
        else:
            gr.Warning(f"ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ (Original log index {original_log_index} out of bounds for visible history size {len(visible_raw_history)})."); return None, gr.update(visible=False)
    except Exception as e:
        print(f"ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆé¸æŠä¸­ã®ã‚¨ãƒ©ãƒ¼: {e}"); traceback.print_exc()
        return None, gr.update(visible=False)

def handle_delete_button_click(message_to_delete: Optional[Dict[str, str]], character_name: str, api_history_limit: str):
    if not message_to_delete:
        return gr.update(), gr.update(), None, gr.update(visible=False)

    log_f, _, _, _, _ = get_character_files_paths(character_name)
    if utils.delete_message_from_log(log_f, message_to_delete, character_name):
        gr.Info("ãƒ­ã‚°ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
    else:
        gr.Error("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    history, mapping_list = reload_chat_log(character_name, api_history_limit)
    return history, mapping_list, None, gr.update(visible=False)

def reload_chat_log(character_name: Optional[str], api_history_limit_value: str):
    if not character_name:
        return [], []

    log_f,_,_,_,_ = get_character_files_paths(character_name)
    if not log_f or not os.path.exists(log_f):
        return [], []

    full_raw_history = utils.load_chat_log(log_f, character_name)
    display_turns = _get_display_history_count(api_history_limit_value)
    visible_history = full_raw_history[-(display_turns * 2):]
    history, mapping_list = utils.format_history_for_gradio(visible_history, character_name)
    return history, mapping_list

def handle_save_memory_click(character_name, json_string_data):
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return gr.update()
    try: return save_memory_data(character_name, json_string_data)
    except Exception as e: gr.Error(f"è¨˜æ†¶ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return gr.update()

def handle_reload_memory(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return "{}"
    gr.Info(f"ã€Œ{character_name}ã€ã®è¨˜æ†¶ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚"); _, _, _, memory_json_path, _ = get_character_files_paths(character_name); return json.dumps(load_memory_data_safe(memory_json_path), indent=2, ensure_ascii=False)

def load_notepad_content(character_name: str) -> str:
    if not character_name: return ""
    _, _, _, _, notepad_path = get_character_files_paths(character_name)
    if notepad_path and os.path.exists(notepad_path):
        with open(notepad_path, "r", encoding="utf-8") as f: return f.read()
    return ""

def handle_save_notepad_click(character_name: str, content: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return content
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path: gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚"); return content
    lines = [f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}] {line.strip()}" if line.strip() and not re.match(r"^\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}\]", line.strip()) else line.strip() for line in content.strip().split('\n') if line.strip()]
    final_content = "\n".join(lines)
    try:
        with open(notepad_path, "w", encoding="utf-8") as f: f.write(final_content + ('\n' if final_content else ''))
        gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"); return final_content
    except Exception as e: gr.Error(f"ãƒ¡ãƒ¢å¸³ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"); return content

def handle_clear_notepad_click(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return ""
    _, _, _, _, notepad_path = character_manager.get_character_files_paths(character_name)
    if not notepad_path: gr.Error(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ãƒ‘ã‚¹å–å¾—å¤±æ•—ã€‚"); return ""
    try:
        with open(notepad_path, "w", encoding="utf-8") as f: f.write("")
        gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’ç©ºã«ã—ã¾ã—ãŸã€‚"); return ""
    except Exception as e: gr.Error(f"ãƒ¡ãƒ¢å¸³ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}"); return f"ã‚¨ãƒ©ãƒ¼: {e}"

def handle_reload_notepad(character_name: str) -> str:
    if not character_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return ""
    content = load_notepad_content(character_name); gr.Info(f"ã€Œ{character_name}ã€ã®ãƒ¡ãƒ¢å¸³ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸã€‚"); return content

def render_alarms_as_dataframe():
    alarms = sorted(alarm_manager.load_alarms(), key=lambda x: x.get("time", "")); all_rows = []
    for a in alarms:
        schedule_display = "å˜ç™º"
        if a.get("date"):
            try:
                date_obj, today = datetime.datetime.strptime(a["date"], "%Y-%m-%d").date(), datetime.date.today()
                if date_obj == today: schedule_display = "ä»Šæ—¥"
                elif date_obj == today + datetime.timedelta(days=1): schedule_display = "æ˜æ—¥"
                else: schedule_display = date_obj.strftime("%m/%d")
            except: schedule_display = "æ—¥ä»˜ä¸å®š"
        elif a.get("days"): schedule_display = ",".join([DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in a["days"]])
        all_rows.append({"ID": a.get("id"), "çŠ¶æ…‹": a.get("enabled", False), "æ™‚åˆ»": a.get("time"), "äºˆå®š": schedule_display, "ã‚­ãƒ£ãƒ©": a.get("character"), "å†…å®¹": a.get("context_memo") or ""})
    return pd.DataFrame(all_rows, columns=["ID", "çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])

def get_display_df(df_with_id: pd.DataFrame):
    if df_with_id is None or df_with_id.empty: return pd.DataFrame(columns=["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"])
    return df_with_id[["çŠ¶æ…‹", "æ™‚åˆ»", "äºˆå®š", "ã‚­ãƒ£ãƒ©", "å†…å®¹"]] if 'ID' in df_with_id.columns else df_with_id

def handle_alarm_selection(evt: gr.SelectData, df_with_id: pd.DataFrame) -> List[str]:
    if not hasattr(evt, 'index') or evt.index is None or df_with_id is None or df_with_id.empty: return []
    indices = evt.index if isinstance(evt.index, list) else [evt.index]
    return [str(df_with_id.iloc[r[0] if isinstance(r, tuple) else r]['ID']) for r in indices if isinstance(r, (int, tuple)) and 0 <= (r[0] if isinstance(r, tuple) else r) < len(df_with_id)]

def handle_alarm_selection_for_all_updates(evt: gr.SelectData, df_with_id: pd.DataFrame):
    selected_ids = handle_alarm_selection(evt, df_with_id)
    feedback_text = "ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„" if not selected_ids else f"{len(selected_ids)} ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸æŠä¸­"
    all_chars, default_char = character_manager.get_character_list(), "Default"
    if all_chars: default_char = all_chars[0]
    if len(selected_ids) == 1:
        alarm = next((a for a in alarm_manager.load_alarms() if a.get("id") == selected_ids[0]), None)
        if alarm:
            h, m = alarm.get("time", "08:00").split(":")
            days_ja = [DAY_MAP_EN_TO_JA.get(d.lower(), d.upper()) for d in alarm.get("days", [])]
            form_updates = ("ã‚¢ãƒ©ãƒ¼ãƒ æ›´æ–°", alarm.get("context_memo", ""), "", alarm.get("character", default_char), days_ja, alarm.get("is_emergency", False), h, m, selected_ids[0])
        else: form_updates = ("ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", default_char, [], False, "08", "00", None)
    else: form_updates = ("ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", default_char, [], False, "08", "00", None)
    return (selected_ids, feedback_text) + form_updates

def toggle_selected_alarms_status(selected_ids: list, target_status: bool):
    if not selected_ids: gr.Warning("çŠ¶æ…‹ã‚’å¤‰æ›´ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        current_alarms = alarm_manager.load_alarms()
        modified = any(a.get("id") in selected_ids and a.update({"enabled": target_status}) is None for a in current_alarms)
        if modified:
            alarm_manager.alarms_data_global = current_alarms; alarm_manager.save_alarms()
            gr.Info(f"{len(selected_ids)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã®çŠ¶æ…‹ã‚’ã€Œ{'æœ‰åŠ¹' if target_status else 'ç„¡åŠ¹'}ã€ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚")
    new_df_with_ids = render_alarms_as_dataframe(); return new_df_with_ids, get_display_df(new_df_with_ids)

def handle_delete_selected_alarms(selected_ids: list):
    if not selected_ids: gr.Warning("å‰Šé™¤ã™ã‚‹ã‚¢ãƒ©ãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        for sid in selected_ids: alarm_manager.delete_alarm(str(sid))
    new_df_with_ids = render_alarms_as_dataframe(); return new_df_with_ids, get_display_df(new_df_with_ids)

def handle_add_or_update_alarm(editing_id, h, m, char, theme, prompt, days_ja, is_emergency):
    from tools.alarm_tools import set_personal_alarm
    context = theme or prompt or "æ™‚é–“ã«ãªã‚Šã¾ã—ãŸ"; days_en = [DAY_MAP_JA_TO_EN.get(d) for d in days_ja if d in DAY_MAP_JA_TO_EN]
    if editing_id: alarm_manager.delete_alarm(editing_id); gr.Info(f"ã‚¢ãƒ©ãƒ¼ãƒ ID:{editing_id}ã‚’æ›´æ–°ã—ã¾ã™ã€‚")
    set_personal_alarm.func(time=f"{h}:{m}", context_memo=context, character_name=char, days=days_en, date=None, is_emergency=is_emergency)
    new_df_with_ids, all_chars = render_alarms_as_dataframe(), character_manager.get_character_list()
    default_char = all_chars[0] if all_chars else "Default"
    return new_df_with_ids, get_display_df(new_df_with_ids), "ã‚¢ãƒ©ãƒ¼ãƒ è¿½åŠ ", "", "", gr.update(choices=all_chars, value=default_char), [], False, "08", "00", None

def handle_timer_submission(timer_type, duration, work, brk, cycles, char, work_theme, brk_theme, api_key_name, normal_theme):
    if not char or not api_key_name: return "ã‚¨ãƒ©ãƒ¼ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
    try:
        timer = UnifiedTimer(timer_type, float(duration or 0), float(work or 0), float(brk or 0), int(cycles or 0), char, work_theme, brk_theme, api_key_name, normal_theme=normal_theme)
        timer.start(); gr.Info(f"{timer_type}ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚"); return f"{timer_type}ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚"
    except Exception as e: return f"ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}"

def handle_rag_update_button_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); return
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"): gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    gr.Info(f"ã€Œ{character_name}ã€ã®RAGç´¢å¼•ã®æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã™...")
    import rag_manager
    threading.Thread(target=lambda: rag_manager.create_or_update_index(character_name, api_key)).start()

def _run_core_memory_update(character_name: str, api_key: str):
    print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ (Character: {character_name}) ---")
    try:
        from tools import memory_tools
        result = memory_tools.summarize_and_save_core_memory.func(character_name=character_name, api_key=api_key)
        print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†å®Œäº† --- çµæœ: {result}")
    except Exception: print(f"--- [ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¨ãƒ©ãƒ¼] ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ ---"); traceback.print_exc()

def handle_core_memory_update_click(character_name: str, api_key_name: str):
    if not character_name or not api_key_name: gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); return
    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"): gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    gr.Info(f"ã€Œ{character_name}ã€ã®ã‚³ã‚¢ãƒ¡ãƒ¢ãƒªæ›´æ–°ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹ã—ã¾ã—ãŸã€‚")
    threading.Thread(target=_run_core_memory_update, args=(character_name, api_key)).start()

def update_model_state(model): config_manager.save_config("last_model", model); return model

def update_api_key_state(api_key_name):
    config_manager.save_config("last_api_key_name", api_key_name)
    gr.Info(f"APIã‚­ãƒ¼ã‚’ '{api_key_name}' ã«è¨­å®šã—ã¾ã—ãŸã€‚")
    return api_key_name

def update_api_history_limit_state_and_reload_chat(limit_ui_val: str, character_name: Optional[str]):
    key = next((k for k, v in constants.API_HISTORY_LIMIT_OPTIONS.items() if v == limit_ui_val), "all")
    config_manager.save_config("last_api_history_limit_option", key)
    history, mapping_list = reload_chat_log(character_name, key)
    return key, history, mapping_list

def handle_play_audio_button_click(selected_message: Optional[Dict[str, str]], character_name: str, api_key_name: str):
    if not selected_message:
        gr.Warning("å†ç”Ÿã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        # â˜… ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã¯å¤‰æ›´ã—ãªã„ã®ã§ã€å…ƒã®çŠ¶æ…‹ã‚’è¿”ã™
        yield gr.update(visible=False), gr.update(interactive=True), gr.update(interactive=True)
        return

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šyield ã‚’ä½¿ã£ãŸæ®µéšçš„ãªUIæ›´æ–° â–¼â–¼â–¼
    # 1. ã¾ãšã€Œç”Ÿæˆä¸­ã€ã®çŠ¶æ…‹ã‚’UIã«å³æ™‚åæ˜ ã•ã›ã‚‹
    yield (
        gr.update(visible=False), # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ä¸€æ—¦éš ã™
        gr.update(value="éŸ³å£°ç”Ÿæˆä¸­... â–Œ", interactive=False), # å†ç”Ÿãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–
        gr.update(interactive=False)  # è©¦è´ãƒœã‚¿ãƒ³ã‚‚ç„¡åŠ¹åŒ–
    )

    try:
        raw_text = utils.extract_raw_text_from_html(selected_message.get("content"))
        text_to_speak = utils.remove_thoughts_from_text(raw_text)
        if not text_to_speak:
            gr.Info("ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯éŸ³å£°ã§å†ç”Ÿã§ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        effective_settings = config_manager.get_effective_settings(character_name)
        voice_id, voice_style_prompt = effective_settings.get("voice_id", "iapetus"), effective_settings.get("voice_style_prompt", "")
        api_key = config_manager.API_KEYS.get(api_key_name)
        if not api_key:
            gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return

        from audio_manager import generate_audio_from_text
        gr.Info(f"ã€Œ{character_name}ã€ã®å£°ã§éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        audio_filepath = generate_audio_from_text(text_to_speak, api_key, voice_id, voice_style_prompt)

        if audio_filepath:
            gr.Info("å†ç”Ÿã—ã¾ã™ã€‚")
            # 2. æˆåŠŸã—ãŸã‚‰ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¡¨ç¤ºã—ã¦å†ç”Ÿã‚’é–‹å§‹
            yield gr.update(value=audio_filepath, visible=True), gr.update(), gr.update()
        else:
            gr.Error("éŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    finally:
        # 3. æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšã€å¿…ãšæœ€å¾Œã«ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’å…ƒã«æˆ»ã™
        yield (
            gr.update(), # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®çŠ¶æ…‹ã¯ãã®ã¾ã¾
            gr.update(value="ğŸ”Š é¸æŠã—ãŸç™ºè¨€ã‚’å†ç”Ÿ", interactive=True), # å†ç”Ÿãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
            gr.update(interactive=True)  # è©¦è´ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
        )

def handle_voice_preview(selected_voice_name: str, voice_style_prompt: str, text_to_speak: str, api_key_name: str):
    if not selected_voice_name or not text_to_speak or not api_key_name:
        gr.Warning("å£°ã€ãƒ†ã‚­ã‚¹ãƒˆã€APIã‚­ãƒ¼ãŒã™ã¹ã¦é¸æŠã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        yield gr.update(visible=False), gr.update(interactive=True), gr.update(interactive=True)
        return

    # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šyield ã‚’ä½¿ã£ãŸæ®µéšçš„ãªUIæ›´æ–° â–¼â–¼â–¼
    yield (
        gr.update(visible=False),
        gr.update(interactive=False),
        gr.update(value="ç”Ÿæˆä¸­...", interactive=False)
    )

    try:
        voice_id = next((key for key, value in config_manager.SUPPORTED_VOICES.items() if value == selected_voice_name), None)
        api_key = config_manager.API_KEYS.get(api_key_name)
        if not voice_id or not api_key:
            gr.Warning("å£°ã¾ãŸã¯APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚")
            return

        from audio_manager import generate_audio_from_text
        gr.Info(f"å£°ã€Œ{selected_voice_name}ã€ã§éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        audio_filepath = generate_audio_from_text(text_to_speak, api_key, voice_id, voice_style_prompt)

        if audio_filepath:
            gr.Info("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å†ç”Ÿã—ã¾ã™ã€‚")
            yield gr.update(value=audio_filepath, visible=True), gr.update(), gr.update()
        else:
            gr.Error("éŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    finally:
        # æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšã€å¿…ãšæœ€å¾Œã«ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’å…ƒã«æˆ»ã™
        yield (
            gr.update(),
            gr.update(interactive=True),
            gr.update(value="è©¦è´", interactive=True)
        )

def handle_generate_or_regenerate_scenery_image(character_name: str, api_key_name: str, style_choice: str) -> Optional[str]:
    """ã€Œæƒ…æ™¯ç”»åƒã‚’ç”Ÿæˆ/æ›´æ–°ã€ãƒœã‚¿ãƒ³å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ã€‚å¸¸ã«åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«åã§ä¸Šæ›¸ãä¿å­˜ã™ã‚‹ã€‚"""
    if not character_name or not api_key_name:
        gr.Warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã‚­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return None

    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key:
        gr.Warning(f"APIã‚­ãƒ¼ '{api_key_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

    location_id = utils.get_current_location(character_name)
    existing_image_path = utils.find_scenery_image(character_name, location_id)

    if not location_id:
        gr.Warning("ç¾åœ¨åœ°ãŒç‰¹å®šã§ãã¾ã›ã‚“ã€‚")
        return existing_image_path

    # ... (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã®ãƒ­ã‚¸ãƒƒã‚¯ã¯ãã®ã¾ã¾) ...
    char_base_path = os.path.join(constants.CHARACTERS_DIR, character_name)
    world_settings_path = character_manager.get_world_settings_path(character_name)
    prompt_cache_path = os.path.join(char_base_path, "cache", "image_prompts.json")
    structural_prompt = ""

    try:
        world_settings = utils.parse_world_markdown(world_settings_path)
        if not world_settings:
            gr.Error("ä¸–ç•Œè¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return existing_image_path

        space_data = character_manager.find_space_data_by_id_recursive(world_settings, location_id)
        if not space_data:
            gr.Error("ç¾åœ¨ã®å ´æ‰€ã®ç©ºé–“å®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return existing_image_path

        space_data_str = json.dumps(space_data, sort_keys=True)
        current_hash = hashlib.md5(space_data_str.encode('utf-8')).hexdigest()

        with open(prompt_cache_path, 'r', encoding='utf-8') as f:
            prompt_cache = json.load(f)

        cached_entry = prompt_cache.get("prompts", {}).get(location_id, {})
        cached_hash = cached_entry.get("source_hash")

        if current_hash == cached_hash and cached_entry.get("prompt_text"):
            structural_prompt = cached_entry["prompt_text"]
            print(f"--- [ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥HIT] å ´æ‰€ '{location_id}' ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ä½¿ç”¨ã—ã¾ã™ ---")
        else:
            print(f"--- [ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥MISS] å ´æ‰€ '{location_id}' ã®å®šç¾©ãŒå¤‰æ›´ã•ã‚ŒãŸãŸã‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†ç”Ÿæˆã—ã¾ã™ ---")
            from agent.graph import get_configured_llm
            translator_llm = get_configured_llm("gemini-2.5-flash", api_key)

            structural_data = {k: v for k, v in space_data.items() if k != 'description'}
            structural_data_json = json.dumps(structural_data, ensure_ascii=False, indent=2)

            translation_prompt_text = (
                "You are a professional translator for an image generation AI. "
                "Your task is to convert the following JSON data, which describes a location, "
                "into a concise, visually descriptive paragraph in English. "
                "Focus strictly on physical, visible attributes like structure, objects, materials, and lighting. "
                "Do not include any narrative, story elements, or metaphors. Output only the resulting English paragraph.\n\n"
                f"Location Data (JSON):\n{structural_data_json}"
            )

            structural_prompt = translator_llm.invoke(translation_prompt_text).content.strip()

            if "prompts" not in prompt_cache: prompt_cache["prompts"] = {}
            prompt_cache["prompts"][location_id] = { "source_hash": current_hash, "prompt_text": structural_prompt }
            with open(prompt_cache_path, 'w', encoding='utf-8') as f:
                json.dump(prompt_cache, f, indent=2, ensure_ascii=False)
            print(f"  - å ´æ‰€ '{location_id}' ã®æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        gr.Error(f"ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()
        return existing_image_path

    if not structural_prompt:
        gr.Error("ç”»åƒç”Ÿæˆã®å…ƒã¨ãªã‚‹æ§‹é€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return existing_image_path

    now = datetime.datetime.now()
    time_of_day = utils.get_time_of_day(now.hour); season = utils.get_season(now.month)
    dynamic_prompt = f"The current season is {season}, and the time of day is {time_of_day}."

    style_prompts = {
        "å†™çœŸé¢¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)": "An ultra-detailed, photorealistic masterpiece with cinematic lighting.",
        "ã‚¤ãƒ©ã‚¹ãƒˆé¢¨": "A beautiful and detailed anime-style illustration, pixiv contest winner.",
        "ã‚¢ãƒ‹ãƒ¡é¢¨": "A high-quality screenshot from a modern animated film.",
        "æ°´å½©ç”»é¢¨": "A gentle and emotional watercolor painting."
    }
    base_prompt = style_prompts.get(style_choice, style_prompts["å†™çœŸé¢¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)"])
    negative_prompt = "Absolutely no text, letters, characters, signatures, or watermarks of any kind should be present in the image. Do not include people."

    prompt = f"{base_prompt} {negative_prompt} Depict the following scene: {structural_prompt} {dynamic_prompt}"
    gr.Info(f"ã€Œ{style_choice}ã€ã§ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™...")

    result = generate_image_tool_func.func(prompt=prompt, character_name=character_name, api_key=api_key)

    if "Generated Image:" in result:
        generated_path = result.replace("[Generated Image: ", "").replace("]", "").strip()
        if os.path.exists(generated_path):
            save_dir = os.path.join(constants.CHARACTERS_DIR, character_name, "spaces", "images")
            now = datetime.datetime.now()

            # â–¼â–¼â–¼ ä¿®æ­£ã®æ ¸å¿ƒï¼šãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ç”»é¢¨ã‚’é™¤å¤–ã—ã€å¸¸ã«åŒã˜åå‰ã§ä¸Šæ›¸ãã™ã‚‹ â–¼â–¼â–¼
            cache_key = f"{location_id}_{utils.get_season(now.month)}_{utils.get_time_of_day(now.hour)}"
            specific_filename = f"{cache_key}.png"
            specific_path = os.path.join(save_dir, specific_filename)

            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°ä¸Šæ›¸ãã™ã‚‹ãŸã‚ã€äº‹å‰ã«å‰Šé™¤
            if os.path.exists(specific_path):
                os.remove(specific_path)
            # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

            shutil.move(generated_path, specific_path)
            print(f"--- æƒ…æ™¯ç”»åƒã‚’ç”Ÿæˆã—ã€ä¿å­˜ã—ã¾ã—ãŸ: {specific_path} ---")

            gr.Info("ç”»åƒã‚’ç”Ÿæˆ/æ›´æ–°ã—ã¾ã—ãŸã€‚")
            return specific_path
        else:
            gr.Error("ç”»åƒã®ç”Ÿæˆã«ã¯æˆåŠŸã—ã¾ã—ãŸãŒã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return existing_image_path
    else:
        gr.Error(f"ç”»åƒã®ç”Ÿæˆ/æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIã®å¿œç­”: {result}")
        return existing_image_path

#
# ui_handlers.py ã®ä¸€ç•ªä¸‹ã«ã‚ã‚‹ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ»ãƒ“ãƒ«ãƒ€ãƒ¼é–¢é€£ã®é–¢æ•°ç¾¤ã‚’ã€ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã§å®Œå…¨ã«ç½®ãæ›ãˆã¦ãã ã•ã„
#

from world_builder import get_world_data, save_world_data, generate_details_markdown, convert_data_to_yaml_str
import yaml

def get_choices_from_world_data(world_data: Dict) -> Tuple[List[Tuple[str, str]], Dict[str, List[Tuple[str, str]]]]:
    area_choices, room_choices_map = [], {}
    if not isinstance(world_data, dict): return area_choices, room_choices_map
    for area_id, area_data in world_data.items():
        if isinstance(area_data, dict):
            area_name = area_data.get("name", area_id)
            area_choices.append((area_name, area_id))
            room_choices = []
            for room_id, room_data in area_data.items():
                if isinstance(room_data, dict) and ("name" in room_data or "description" in room_data):
                    room_name = room_data.get("name", room_id)
                    room_choices.append((room_name, room_id))
            room_choices_map[area_id] = sorted(room_choices)
    return sorted(area_choices), room_choices_map

def handle_world_builder_load(character_name: str):
    """ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ»ãƒ“ãƒ«ãƒ€ãƒ¼ã‚¿ãƒ–ãŒé¸æŠã•ã‚ŒãŸæ™‚ã‚„ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒå¤‰æ›´ã•ã‚ŒãŸæ™‚ã®åˆæœŸåŒ–å‡¦ç†ã€‚"""
    world_data = get_world_data(character_name)
    area_choices, _ = get_choices_from_world_data(world_data)
    # nexus_ark.py ã® outputs ãƒªã‚¹ãƒˆï¼ˆ7é …ç›®ï¼‰ã«å¯¾å¿œã™ã‚‹ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™
    return (
        world_data,
        gr.update(choices=area_choices, value=None),
        gr.update(choices=[], value=None),
        "â† å·¦ã®ãƒ‘ãƒãƒ«ã‹ã‚‰ã‚¨ãƒªã‚¢ã‚„éƒ¨å±‹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
        gr.update(visible=False), # editor_wrapper_wb
        gr.update(visible=False), # edit_button_wb
        gr.update(visible=False)  # new_item_form_wb
    )

def handle_character_change_for_all_tabs(character_name: str, api_key_name: str):
    print(f"--- UIå¸ä»¤å¡”(handle_character_change_for_all_tabs)å®Ÿè¡Œ: {character_name} ---")
    chat_tab_updates = handle_character_change(character_name, api_key_name)
    world_builder_updates = handle_world_builder_load(character_name)
    return chat_tab_updates + world_builder_updates

def handle_item_selection(world_data: Dict, area_id: str, room_id: Optional[str]):
    """ã‚¨ãƒªã‚¢ã¾ãŸã¯éƒ¨å±‹ãŒé¸æŠã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚ãƒªã‚¹ãƒˆã¨è¾æ›¸ã‚¨ãƒ‡ã‚£ã‚¿ã®çŠ¶æ…‹ã‚‚æ›´æ–°ã™ã‚‹ã€‚"""
    _, room_choices_map = get_choices_from_world_data(world_data)
    room_choices = room_choices_map.get(area_id, []) if area_id else []

    selected_data = {}
    if area_id and room_id:
        selected_data = world_data.get(area_id, {}).get(room_id, {})
    elif area_id:
        selected_data = world_data.get(area_id, {})

    list_keys = [k for k, v in selected_data.items() if isinstance(v, list)]
    dict_keys = [k for k, v in selected_data.items() if isinstance(v, dict)]

    list_accordion_open = bool(list_keys)
    dict_accordion_open = bool(dict_keys)

    # æˆ»ã‚Šå€¤ã®æ•°ã‚’ nexus_ark.py ã® outputs (11é …ç›®) ã¨ä¸€è‡´ã•ã›ã‚‹
    if not selected_data:
        return (
            gr.update(choices=room_choices, value=None), "â† å·¦ã®ãƒ‘ãƒãƒ«ã‹ã‚‰ã‚¨ãƒªã‚¢ã‚„éƒ¨å±‹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
            gr.update(visible=False), gr.update(visible=True),
            gr.update(open=False), gr.update(choices=[], value=None),
            gr.update(choices=[], value=None), gr.update(visible=False),
            gr.update(open=False), gr.update(choices=[], value=None),
            pd.DataFrame(columns=["ã‚­ãƒ¼", "å€¤"])
        )
    else:
        return (
            gr.update(choices=room_choices, value=room_id), generate_details_markdown(selected_data),
            gr.update(visible=True), gr.update(visible=True),
            gr.update(open=list_accordion_open), gr.update(choices=list_keys, value=None),
            gr.update(choices=[], value=None), gr.update(visible=False),
            gr.update(open=dict_accordion_open), gr.update(choices=dict_keys, value=None),
            pd.DataFrame(columns=["ã‚­ãƒ¼", "å€¤"])
        )

def handle_edit_button_click(world_data: Dict, area_id: str, room_id: Optional[str]):
    """ã€Œç·¨é›†ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if area_id and room_id:
        selected_data = world_data.get(area_id, {}).get(room_id, {})
    elif area_id:
        selected_data = world_data.get(area_id, {})
    else:
        return gr.update(), gr.update(), gr.update()
    return gr.update(visible=False), gr.update(visible=True), convert_data_to_yaml_str(selected_data)

def handle_save_button_click(character_name: str, world_data: Dict, area_id: str, room_id: Optional[str], editor_content: str):
    """ç·¨é›†ãƒ•ã‚©ãƒ¼ãƒ ã®ã€Œä¿å­˜ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if not area_id:
        gr.Warning("ä¿å­˜å¯¾è±¡ã®ã‚¨ãƒªã‚¢ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return world_data, gr.update(), gr.update()
    try:
        new_data = yaml.safe_load(editor_content)
        if not isinstance(new_data, dict): raise ValueError("YAMLã®è§£æçµæœãŒè¾æ›¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        if room_id:
            world_data[area_id][room_id] = new_data
        else:
            existing_rooms = {k: v for k, v in world_data.get(area_id, {}).items() if isinstance(v, dict) and 'name' in v}
            world_data[area_id] = {**new_data, **existing_rooms}
        save_world_data(character_name, world_data)
        gr.Info(f"ã€Œ{character_name}ã€ã®ä¸–ç•Œè¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
        return world_data, generate_details_markdown(new_data), gr.update(visible=False)
    except (yaml.YAMLError, ValueError) as e:
        gr.Error(f"YAMLã®æ›¸å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: {e}")
        return world_data, gr.update(), gr.update()

def handle_add_item_button_click(item_type: str, selected_area_id: Optional[str]):
    """ã€Œã‚¨ãƒªã‚¢ã‚’è¿½åŠ ã€ã€Œéƒ¨å±‹ã‚’è¿½åŠ ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if item_type == "room" and not selected_area_id:
        gr.Warning("éƒ¨å±‹ã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã€ã¾ãšã€Œã‚¨ãƒªã‚¢ã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update()
    return (
        gr.update(visible=False),
        gr.update(visible=False),
        gr.update(visible=False),
        gr.update(visible=True),
        item_type,
        f"#### æ–°ã—ã„{ 'ã‚¨ãƒªã‚¢' if item_type == 'area' else 'éƒ¨å±‹' }ã®ä½œæˆ"
    )

def handle_cancel_add_button_click():
    """æ–°è¦ä½œæˆãƒ•ã‚©ãƒ¼ãƒ ã®ã€Œã‚­ãƒ£ãƒ³ã‚»ãƒ«ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    return (
        gr.update(visible=True),
        gr.update(visible=True),
        gr.update(visible=False),
        gr.update(visible=False),
        "",
        ""
    )

def handle_dict_key_selection(world_data: Dict, area_id: str, room_id: Optional[str], dict_key: str):
    """ã€Œç·¨é›†ã™ã‚‹è¾æ›¸ã€ãŒé¸æŠã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚DataFrameã‚’æ›´æ–°ã™ã‚‹ã€‚"""
    if not dict_key:
        return pd.DataFrame(columns=["ã‚­ãƒ¼", "å€¤"])

    target_dict = {}
    if area_id and room_id:
        target_dict = world_data.get(area_id, {}).get(room_id, {}).get(dict_key, {})
    elif area_id:
        target_dict = world_data.get(area_id, {}).get(dict_key, {})

    if isinstance(target_dict, dict):
        # DataFrameã«å¤‰æ›
        df_data = [[str(k), str(v)] for k, v in target_dict.items()]
        return pd.DataFrame(df_data, columns=["ã‚­ãƒ¼", "å€¤"])

    return pd.DataFrame(columns=["ã‚­ãƒ¼", "å€¤"])

def handle_save_dict_click(world_data: Dict, character_name: str, area_id: str, room_id: Optional[str], dict_key: str, edited_df: pd.DataFrame):
    """è¾æ›¸é …ç›®ã®ã€Œå¤‰æ›´ã‚’ä¿å­˜ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if not all([character_name, area_id, dict_key]):
        gr.Warning("é …ç›®ã®ä¿å­˜ã«å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return world_data, gr.update()

    try:
        # DataFrameã‚’è¾æ›¸ã«æˆ»ã™
        new_dict_data = dict(edited_df.values)

        # world_data Stateã‚’æ›´æ–°
        if room_id:
            world_data[area_id][room_id][dict_key] = new_dict_data
        else:
            world_data[area_id][dict_key] = new_dict_data

        save_world_data(character_name, world_data)
        gr.Info(f"è¾æ›¸ '{dict_key}' ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")

        # è©³ç´°è¡¨ç¤ºã‚‚æ›´æ–°
        updated_section_data = world_data[area_id][room_id] if room_id else world_data[area_id]

        return world_data, generate_details_markdown(updated_section_data)

    except Exception as e:
        gr.Error(f"è¾æ›¸ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return world_data, gr.update()

def handle_api_connection_test(api_key_name: str):
    """APIã‚­ãƒ¼ã‚’ä½¿ã£ã¦ã€Nexus ArkãŒå¿…è¦ã¨ã™ã‚‹å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹"""
    if not api_key_name:
        gr.Warning("ãƒ†ã‚¹ãƒˆã™ã‚‹APIã‚­ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    api_key = config_manager.API_KEYS.get(api_key_name)
    if not api_key or api_key.startswith("YOUR_API_KEY"):
        gr.Error(f"APIã‚­ãƒ¼ '{api_key_name}' ã¯ç„¡åŠ¹ã§ã™ã€‚config.jsonã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    gr.Info(f"APIã‚­ãƒ¼ '{api_key_name}' ã‚’ä½¿ã£ã¦ã€å¿…é ˆãƒ¢ãƒ‡ãƒ«ã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã„ã¾ã™...")

    # ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
    required_models = {
        "models/gemini-2.5-pro": "é€šå¸¸ãƒãƒ£ãƒƒãƒˆ",
        "models/gemini-2.5-flash": "æƒ…æ™¯æå†™ç”Ÿæˆ",
        "models/gemini-2.0-flash-preview-image-generation": "ç”»åƒç”Ÿæˆ"
    }

    results = []
    all_ok = True

    try:
        client = genai.Client(api_key=api_key)

        for model_name, purpose in required_models.items():
            try:
                # å„ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’å–å¾—ã—ã‚ˆã†ã¨è©¦ã¿ã‚‹
                client.models.get(model=model_name)
                results.append(f"âœ… **{purpose} ({model_name.split('/')[-1]})**: åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
            except Exception as model_e:
                results.append(f"âŒ **{purpose} ({model_name.split('/')[-1]})**: åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
                print(f"--- ãƒ¢ãƒ‡ãƒ« '{model_name}' ã®ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—: {model_e} ---")
                all_ok = False

        # æœ€çµ‚çš„ãªçµæœã‚’é€šçŸ¥
        result_message = "\n\n".join(results)
        if all_ok:
            gr.Info(f"âœ… **å…¨ã¦ã®å¿…é ˆãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™ï¼**\n\n{result_message}")
        else:
            gr.Warning(f"âš ï¸ **ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚**\n\n{result_message}\n\nGoogle AI Studioã¾ãŸã¯Google Cloudã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    except Exception as e:
        error_message = f"âŒ **APIã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šè‡ªä½“ã«å¤±æ•—ã—ã¾ã—ãŸã€‚**\n\nAPIã‚­ãƒ¼ãŒç„¡åŠ¹ã‹ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nè©³ç´°: {str(e)}"
        print(f"--- APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ ---\n{traceback.format_exc()}")
        gr.Error(error_message)

def handle_add_new_list_click(world_data: Dict, character_name: str, area_id: str, room_id: Optional[str], new_list_key: str):
    """ã€Œãƒªã‚¹ãƒˆã‚’æ–°è¦ä½œæˆã€ã§å…¥åŠ›ã•ã‚ŒãŸã‚­ãƒ¼ã§æ–°ã—ã„ãƒªã‚¹ãƒˆã‚’ä½œæˆã™ã‚‹"""
    if not new_list_key or not new_list_key.strip():
        gr.Warning("ãƒªã‚¹ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update(), gr.update(visible=True), new_list_key

    if not area_id:
        gr.Warning("ãƒªã‚¹ãƒˆã‚’è¿½åŠ ã™ã‚‹ã€Œã‚¨ãƒªã‚¢ã€ã¾ãŸã¯ã€Œéƒ¨å±‹ã€ã‚’å…ˆã«é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update(), gr.update(visible=True), new_list_key

    clean_key = new_list_key.strip()
    if not re.match(r"^[a-zA-Z0-9_]+$", clean_key):
        gr.Warning("ãƒªã‚¹ãƒˆåã«ã¯åŠè§’è‹±æ•°å­—ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢(_)ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚")
        return world_data, gr.update(), gr.update(visible=True), new_list_key

    target_data = world_data[area_id][room_id] if room_id else world_data[area_id]

    if clean_key in target_data:
        gr.Warning(f"ãƒªã‚¹ãƒˆ '{clean_key}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
        return world_data, gr.update(value=clean_key), gr.update(visible=False), ""

    target_data[clean_key] = []
    save_world_data(character_name, world_data)
    gr.Info(f"æ–°ã—ã„ãƒªã‚¹ãƒˆ '{clean_key}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

    new_list_keys = [k for k, v in target_data.items() if isinstance(v, list)]
    return world_data, gr.update(choices=new_list_keys, value=clean_key), gr.update(visible=False), ""

def handle_add_new_item_click(world_data: Dict, area_id: str, room_id: Optional[str], list_key: str):
    """ã€Œæ–°è¦é …ç›®ã‚’è¿½åŠ ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚ç©ºã®ç·¨é›†ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    if not list_key:
        gr.Warning("é …ç›®ã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã€ã¾ãšã€Œç·¨é›†ã™ã‚‹ãƒªã‚¹ãƒˆã‚’é¸æŠã€ã—ã¦ãã ã•ã„ã€‚ãƒªã‚¹ãƒˆãŒãªã„å ´åˆã¯ã€Œãƒªã‚¹ãƒˆã‚’æ–°è¦ä½œæˆã€ã—ã¦ãã ã•ã„ã€‚")
        return gr.update(), gr.update(), gr.update(), gr.update()

    # æ–°ã—ã„é …ç›®ã®ä¸€æ™‚çš„ãªIDã¨ã—ã¦ "-1" ã‚’ä½¿ç”¨ã™ã‚‹
    return (
        gr.update(visible=True),
        "-1", # æ–°è¦ä½œæˆã‚’ç¤ºã™ID
        "æ–°ã—ã„é …ç›®", # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åå‰
        "" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®èª¬æ˜
    )

def handle_save_item_click(world_data: Dict, character_name: str, area_id: str, room_id: Optional[str], list_key: str, item_id_str: str, item_name: str, item_desc: str):
    """ãƒªã‚¹ãƒˆé …ç›®ã®ã€Œä¿å­˜ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if not all([character_name, area_id, list_key, item_id_str]):
        gr.Warning("é …ç›®ã®ä¿å­˜ã«å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return world_data, gr.update(), gr.update()

    try:
        item_index = int(item_id_str)
        target_list = []
        if room_id:
            target_list = world_data[area_id][room_id].setdefault(list_key, [])
        else:
            target_list = world_data[area_id].setdefault(list_key, [])

        new_item = {"name": item_name, "description": item_desc}

        if item_index == -1: # æ–°è¦ä½œæˆ
            target_list.append(new_item)
            gr.Info(f"ãƒªã‚¹ãƒˆ '{list_key}' ã«æ–°ã—ã„é …ç›® '{item_name}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
            # æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸé …ç›®ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç‰¹å®š
            new_item_id = str(len(target_list) - 1)
        else: # æ—¢å­˜ã®æ›´æ–°
            target_list[item_index] = new_item
            gr.Info(f"é …ç›® '{item_name}' ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
            new_item_id = item_id_str

        save_world_data(character_name, world_data)

        # UIã‚’æ›´æ–°
        new_item_choices = [(f"{item.get('name', '')} (ID:{i})", str(i)) for i, item in enumerate(target_list)]

        return (
            world_data,
            gr.update(choices=new_item_choices, value=new_item_id),
            gr.update(visible=False) # ãƒ•ã‚©ãƒ¼ãƒ ã‚’é–‰ã˜ã‚‹
        )
    except (ValueError, IndexError, KeyError) as e:
        gr.Error(f"é …ç›®ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return world_data, gr.update(), gr.update()

def handle_delete_item_click(world_data: Dict, character_name: str, area_id: str, room_id: Optional[str], list_key: str, item_id_str: str):
    """ãƒªã‚¹ãƒˆé …ç›®ã®ã€Œå‰Šé™¤ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if not all([character_name, area_id, list_key, item_id_str]) or item_id_str == "-1":
        gr.Warning("å‰Šé™¤ã™ã‚‹é …ç›®ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return world_data, gr.update(), gr.update()

    try:
        item_index = int(item_id_str)
        target_list = []
        if room_id:
            target_list = world_data[area_id][room_id].get(list_key, [])
        else:
            target_list = world_data[area_id].get(list_key, [])

        deleted_item_name = target_list.pop(item_index).get("name", "ç„¡åã®é …ç›®")
        gr.Info(f"é …ç›® '{deleted_item_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

        save_world_data(character_name, world_data)

        # UIã‚’æ›´æ–°
        new_item_choices = [(f"{item.get('name', '')} (ID:{i})", str(i)) for i, item in enumerate(target_list)]

        return (
            world_data,
            gr.update(choices=new_item_choices, value=None),
            gr.update(visible=False) # ãƒ•ã‚©ãƒ¼ãƒ ã‚’é–‰ã˜ã‚‹
        )
    except (ValueError, IndexError, KeyError) as e:
        gr.Error(f"é …ç›®ã®å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return world_data, gr.update(), gr.update()


def handle_list_key_selection(world_data: Dict, area_id: str, room_id: Optional[str], list_key: str):
    """ã€Œç·¨é›†ã™ã‚‹ãƒªã‚¹ãƒˆã€ãŒé¸æŠã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚é …ç›®é¸æŠãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‚’æ›´æ–°ã™ã‚‹ã€‚"""
    if not list_key:
        return gr.update(choices=[], value=None), gr.update(visible=False)

    selected_data = {}
    if area_id and room_id:
        selected_data = world_data.get(area_id, {}).get(room_id, {})
    elif area_id:
        selected_data = world_data.get(area_id, {})

    items = selected_data.get(list_key, [])
    item_choices = []
    if isinstance(items, list):
        # å„é …ç›®ã«ä¸€æ„ã®IDã‚’ä»˜ä¸ã™ã‚‹ (ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨)
        for i, item in enumerate(items):
            if isinstance(item, dict) and "name" in item:
                item_choices.append((f"{item['name']} (ID:{i})", str(i)))

    return gr.update(choices=item_choices, value=None), gr.update(visible=False)


def handle_list_item_selection(world_data: Dict, area_id: str, room_id: Optional[str], list_key: str, item_id_str: str):
    """ãƒªã‚¹ãƒˆå†…ã®ã€Œé …ç›®ã€ãŒé¸æŠã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚ç·¨é›†ãƒ•ã‚©ãƒ¼ãƒ ã«è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    if not item_id_str:
        return gr.update(visible=False), gr.update(), gr.update(), gr.update()

    try:
        item_index = int(item_id_str)
        selected_data = {}
        if area_id and room_id:
            selected_data = world_data.get(area_id, {}).get(room_id, {})
        elif area_id:
            selected_data = world_data.get(area_id, {})

        item = selected_data.get(list_key, [])[item_index]

        return (
            gr.update(visible=True),
            item_id_str,
            item.get("name", ""),
            item.get("description", "")
        )
    except (ValueError, IndexError, KeyError) as e:
        print(f"ãƒªã‚¹ãƒˆé …ç›®ã®é¸æŠå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return gr.update(visible=False), None, "", ""

def handle_confirm_add_button_click(character_name: str, world_data: Dict, selected_area_id: Optional[str], item_type: str, new_id: str, new_name: str):
    """æ–°è¦ä½œæˆãƒ•ã‚©ãƒ¼ãƒ ã®ã€Œæ±ºå®šã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†ã€‚"""
    if not new_id or not new_name:
        gr.Warning("IDã¨è¡¨ç¤ºåã®ä¸¡æ–¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return world_data, gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update()
    if not re.match(r"^[a-zA-Z0-9_]+$", new_id):
        gr.Warning("IDã«ã¯åŠè§’è‹±æ•°å­—ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢(_)ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚")
        return world_data, gr.update(), gr.update(), gr.update(), gr.update(), new_id, new_name
    if item_type == "area" and new_id in world_data:
        gr.Warning(f"ID '{new_id}' ã¯æ—¢ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        return world_data, gr.update(), gr.update(), gr.update(), gr.update(), new_id, new_name
    if item_type == "room" and selected_area_id and new_id in world_data.get(selected_area_id, {}):
        gr.Warning(f"ã‚¨ãƒªã‚¢ '{selected_area_id}' å†…ã§ID '{new_id}' ã¯æ—¢ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        return world_data, gr.update(), gr.update(), gr.update(), gr.update(), new_id, new_name

    if item_type == "area":
        world_data[new_id] = {"name": new_name, "description": "æ–°ã—ã„ã‚¨ãƒªã‚¢ã§ã™ã€‚"}
    elif item_type == "room" and selected_area_id:
        if selected_area_id not in world_data: world_data[selected_area_id] = {}
        world_data[selected_area_id][new_id] = {"name": new_name, "description": "æ–°ã—ã„éƒ¨å±‹ã§ã™ã€‚"}

    save_world_data(character_name, world_data)
    area_choices, room_choices_map = get_choices_from_world_data(world_data)
    current_area = new_id if item_type == 'area' else selected_area_id
    current_room = new_id if item_type == 'room' else None
    room_choices = room_choices_map.get(current_area, [])

    gr.Info(f"æ–°ã—ã„{ 'ã‚¨ãƒªã‚¢' if item_type == 'area' else 'éƒ¨å±‹' }ã€Œ{new_name}ã€ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

    return (
        world_data,
        gr.update(choices=area_choices, value=current_area),
        gr.update(choices=room_choices, value=current_room),
        gr.update(visible=True),
        gr.update(visible=False),
        "",
        ""
    )
