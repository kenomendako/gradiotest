# tools/image_tools.py

import os
import io
import base64
import datetime
import traceback
from PIL import Image
import google.genai as genai
import httpx
from langchain_core.tools import tool
from google.genai import types
import config_manager 


def _generate_with_gemini(prompt: str, model_name: str, api_key: str, save_dir: str, room_name: str) -> str:
    """Gemini (google.genai) ã§ç”»åƒã‚’ç”Ÿæˆã™ã‚‹"""
    client = genai.Client(api_key=api_key)
    
    response = client.models.generate_content(
        model=model_name,
        contents=prompt,
    )

    image_data = None
    image_text_response = ""
    if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
        for part in response.candidates[0].content.parts:
            if part.text:
                image_text_response = part.text
                print(f"  - APIã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”: {part.text}")
            if part.inline_data and part.inline_data.mime_type.startswith("image/"):
                image_data = io.BytesIO(part.inline_data.data)

    if not image_data:
        return "ã€ã‚¨ãƒ©ãƒ¼ã€‘APIã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä¸é©åˆ‡ã‹ã€å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"

    image = Image.open(image_data)
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{room_name.lower()}_{timestamp}.png"
    save_path = os.path.join(save_dir, filename)

    image.save(save_path, "PNG")
    print(f"  - ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")

    model_comment = f"\nAI Model Comment: {image_text_response}" if image_text_response else ""
    return f"[Generated Image: {save_path}]{model_comment}\nğŸ“ Prompt: {prompt}\nç”»åƒç”Ÿæˆå®Œäº†ã€‚ã“ã®ç”»åƒã«ã¤ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ·»ãˆã¦ãã ã•ã„ã€‚"


def _generate_with_openai(prompt: str, model_name: str, base_url: str, api_key: str, save_dir: str, room_name: str) -> str:
    """OpenAIäº’æ›API (Images API) ã§ç”»åƒã‚’ç”Ÿæˆã™ã‚‹"""
    from openai import OpenAI
    import requests
    
    print(f"  [OpenAI Image] base_url={base_url}, model={model_name}")
    print(f"  [OpenAI Image] api_key set: {bool(api_key and len(api_key) > 5)}")
    
    client = OpenAI(base_url=base_url, api_key=api_key)
    
    # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã‚µã‚¤ã‚ºã‚’èª¿æ•´
    size = "1024x1024"
    if "dall-e-3" in model_name:
        size = "1024x1024"  # DALL-E 3ã¯1024x1024, 1792x1024, 1024x1792
    
    # gpt-image-1ç³»ãƒ¢ãƒ‡ãƒ«ã¯response_formatã‚’ã‚µãƒãƒ¼ãƒˆã—ãªã„ï¼ˆURLãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰
    is_gpt_image = "gpt-image" in model_name.lower()
    print(f"  [OpenAI Image] is_gpt_image={is_gpt_image}, size={size}")
    
    if is_gpt_image:
        # GPT Image ãƒ¢ãƒ‡ãƒ«ç”¨ï¼ˆresponse_formatãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã•ãªã„ãŒã€b64_jsonã§è¿”ã‚‹ï¼‰
        print(f"  [OpenAI Image] Calling images.generate (gpt-image mode, no response_format param)...")
        response = client.images.generate(
            model=model_name,
            prompt=prompt,
            n=1,
            size=size
        )
        print(f"  [OpenAI Image] Response received")
        
        # gpt-image-1ã¯å®Ÿéš›ã«ã¯b64_jsonã§è¿”ã™ï¼ˆurlã¯Noneï¼‰
        if response.data and response.data[0].b64_json:
            print(f"  [OpenAI Image] Found b64_json data, decoding...")
            image_data = base64.b64decode(response.data[0].b64_json)
            image = Image.open(io.BytesIO(image_data))
        elif response.data and response.data[0].url:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: URLãŒã‚ã‚‹å ´åˆ
            image_url = response.data[0].url
            print(f"  [OpenAI Image] Downloading from URL: {image_url[:100]}...")
            img_response = requests.get(image_url, timeout=60)
            img_response.raise_for_status()
            image = Image.open(io.BytesIO(img_response.content))
        else:
            print(f"  [OpenAI Image] ERROR: No image data in response")
            return "ã€ã‚¨ãƒ©ãƒ¼ã€‘APIã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        print(f"  [OpenAI Image] Image processed successfully")
    else:
        # DALL-Eç­‰ï¼ˆb64_jsonå¯¾å¿œï¼‰
        print(f"  [OpenAI Image] Calling images.generate (b64_json mode)...")
        response = client.images.generate(
            model=model_name,
            prompt=prompt,
            n=1,
            size=size,
            response_format="b64_json"
        )
        print(f"  [OpenAI Image] Response received")
        
        if not response.data or not response.data[0].b64_json:
            print(f"  [OpenAI Image] ERROR: No b64_json in response.data")
            return "ã€ã‚¨ãƒ©ãƒ¼ã€‘APIã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        image_data = base64.b64decode(response.data[0].b64_json)
        image = Image.open(io.BytesIO(image_data))
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{room_name.lower()}_{timestamp}.png"
    save_path = os.path.join(save_dir, filename)
    
    image.save(save_path, "PNG")
    print(f"  - ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")
    
    revised_prompt = getattr(response.data[0], 'revised_prompt', None)
    model_comment = f"\nRevised Prompt: {revised_prompt}" if revised_prompt else ""
    return f"[Generated Image: {save_path}]{model_comment}\nğŸ“ Prompt: {prompt}\nç”»åƒç”Ÿæˆå®Œäº†ã€‚ã“ã®ç”»åƒã«ã¤ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ·»ãˆã¦ãã ã•ã„ã€‚"


@tool
def generate_image(prompt: str, room_name: str, api_key: str, api_key_name: str = None) -> str:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æœ›ã‚„ä¼šè©±ã®æ–‡è„ˆã«å¿œã˜ã¦ã€æƒ…æ™¯ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€ã‚¢ã‚¤ãƒ†ãƒ ãªã©ã®ã‚¤ãƒ©ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    æˆåŠŸã—ãŸå ´åˆã¯ã€UIã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ç‰¹åˆ¥ãªç”»åƒã‚¿ã‚°ã‚’è¿”ã™ã€‚
    prompt: ç”»åƒç”Ÿæˆã®ãŸã‚ã®è©³ç´°ãªæŒ‡ç¤ºï¼ˆè‹±èªãŒæœ›ã¾ã—ã„ï¼‰ã€‚
    """
    # --- æœ€æ–°ã®è¨­å®šã‚’èª­ã¿è¾¼ã‚€ ---
    latest_config = config_manager.load_config_file()
    provider = latest_config.get("image_generation_provider", "gemini")
    model_name = latest_config.get("image_generation_model", "gemini-2.5-flash-image")
    openai_settings = latest_config.get("image_generation_openai_settings", {})

    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãŒç„¡åŠ¹ã®å ´åˆ
    if provider == "disabled":
        return "ã€ã‚¨ãƒ©ãƒ¼ã€‘ç”»åƒç”Ÿæˆæ©Ÿèƒ½ã¯ç¾åœ¨ã€è¨­å®šã§ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚"

    if not room_name:
        return "ã€ã‚¨ãƒ©ãƒ¼ã€‘ç”»åƒç”Ÿæˆã«ã¯ãƒ«ãƒ¼ãƒ åãŒå¿…é ˆã§ã™ã€‚"

    print(f"--- ç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ (Provider: {provider}, Model: {model_name}, Prompt: '{prompt[:100]}...') ---")

    try:
        save_dir = os.path.join("characters", room_name, "generated_images")
        os.makedirs(save_dir, exist_ok=True)

        if provider == "gemini":
            # Geminiç”¨ã®APIã‚­ãƒ¼ã‚’ä½¿ç”¨ï¼ˆãƒ„ãƒ¼ãƒ«å¼•æ•°ã¨ã—ã¦æ¸¡ã•ã‚ŒãŸã‚‚ã®ï¼‰
            if not api_key:
                return "ã€ã‚¨ãƒ©ãƒ¼ã€‘Geminiç”»åƒç”Ÿæˆã«ã¯APIã‚­ãƒ¼ãŒå¿…é ˆã§ã™ã€‚"
            return _generate_with_gemini(prompt, model_name, api_key, save_dir, room_name)
        
        elif provider == "openai":
            # OpenAIäº’æ›è¨­å®šã‚’å–å¾—ï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰è¨­å®šã‚’å‚ç…§ï¼‰
            profile_name = openai_settings.get("profile_name", "")
            openai_model = openai_settings.get("model", model_name)
            
            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Base URLã¨APIã‚­ãƒ¼ã‚’å–å¾—
            openai_provider_settings = latest_config.get("openai_provider_settings", [])
            target_profile = None
            for profile in openai_provider_settings:
                if profile.get("name") == profile_name:
                    target_profile = profile
                    break
            
            if not target_profile:
                return f"ã€ã‚¨ãƒ©ãƒ¼ã€‘ç”»åƒç”Ÿæˆç”¨ã®OpenAIäº’æ›ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« '{profile_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã€Œå…±é€šè¨­å®šã€â†’ã€Œç”»åƒç”Ÿæˆè¨­å®šã€ã§ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
            
            openai_base_url = target_profile.get("base_url", "https://api.openai.com/v1")
            openai_api_key = target_profile.get("api_key", "")
            
            if not openai_api_key:
                return f"ã€ã‚¨ãƒ©ãƒ¼ã€‘ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« '{profile_name}' ã«APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€ŒAPIã‚­ãƒ¼ / Webhookç®¡ç†ã€ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
            
            return _generate_with_openai(prompt, openai_model, openai_base_url, openai_api_key, save_dir, room_name)
        
        else:
            return f"ã€ã‚¨ãƒ©ãƒ¼ã€‘ä¸æ˜ãªç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒã‚¤ãƒ€: {provider}"

    except httpx.RemoteProtocolError as e:
        print(f"  - ç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«ã§ã‚µãƒ¼ãƒãƒ¼åˆ‡æ–­ã‚¨ãƒ©ãƒ¼: {e}")
        return "ã€ã‚¨ãƒ©ãƒ¼ã€‘ã‚µãƒ¼ãƒãƒ¼ãŒå¿œç­”ã›ãšã«æ¥ç¶šã‚’åˆ‡æ–­ã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç°¡æ½”ã«ã—ã¦ã€ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
    except genai.errors.ServerError as e:
        print(f"  - ç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«ã§ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼(500ç•ªå°): {e}")
        return "ã€ã‚¨ãƒ©ãƒ¼ã€‘ã‚µãƒ¼ãƒãƒ¼å´ã§å†…éƒ¨ã‚¨ãƒ©ãƒ¼(500)ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã«ã—ã¦ã€ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
    except genai.errors.ClientError as e:
        print(f"  - ç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼(400ç•ªå°): {e}")
        return f"ã€ã‚¨ãƒ©ãƒ¼ã€‘APIãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒç„¡åŠ¹ã§ã™(400ç•ªå°)ã€‚è©³ç´°: {e}"
    except Exception as e:
        print(f"  - ç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return f"ã€ã‚¨ãƒ©ãƒ¼ã€‘ç”»åƒç”Ÿæˆä¸­ã«äºˆæœŸã›ã¬å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°: {e}"