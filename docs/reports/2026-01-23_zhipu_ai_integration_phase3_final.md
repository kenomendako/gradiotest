# レポート: Phase 3: Zhipu AI 統合と UI 改善の完了

**日付:** 2026-01-23  
**ブランチ:** `fix/entity-memory-api-key-error` (Phase 3 最終ブランチ)  
**ステータス:** ✅ 完了

---

## 問題の概要

マルチモデルアーキテクチャ計画の「Phase 3: 代替プロバイダ統合」として、Zhipu AI (GLM-4) の統合、内部モデル設定 UI の提供、および API キー管理の改善を行いました。また、実装中に発見された内部 LLM 呼び出し時の API キー欠落バグも修正しました。

---

## 修正内容

1.  **Zhipu AI (GLM-4) 統合**:
    - `llm_factory.py` に `zhipu` プロバイダを追加し、GLM-4-Flash (無料モデル) 等を利用可能にしました。
    - 内部処理（要約・分類）の代替プロバイダとして Zhipu AI を選択可能にしました。
2.  **APIキー管理 UI の集約**:
    - 「🔑 APIキー / Webhook管理」アコーディオンに、Gemini, Pushover, Discord, Zhipu, Tavily の全設定を集約しました。
    - 検索プロバイダ設定と連動していた鍵入力欄を固定配置にし、視認性を向上させました。
3.  **内部モデル設定 UI**:
    - 共通設定タブに「🔧 内部処理モデル設定」を追加し、ユーザーが内部タスクに使用するプロバイダとモデルを自由に選択できるようにしました。
4.  **不具合修正**:
    - エンティティ記憶の書き込みや統合時に API キーが正しく渡されず `400` エラーが発生する問題を、`llm_factory` での自動補完ロジックにより根本解決しました。
    - 初期ロード時に Zhipu/Tavily の鍵が UI に反映されない問題を修正しました。

---

## 変更したファイル

- `nexus_ark.py` - UI 定義の刷新、イベント配線の整理、初期ロード同期
- `ui_handlers.py` - プロバイダ変更、初期ロード、モデルリスト取得等のハンドラ修正
- `config_manager.py` - 内部モデル設定の保存・取得ロジック、設定永続化
- `llm_factory.py` - Zhipu プロバイダ対応、API キー自動補完ロジック
- `agent/graph.py` - 内部処理呼び出し時の引数調整
- `utils.py` - UI 表示形式の微調整

---

## 検証結果

- [x] アプリ起動確認 (Syntax OK, Wiring OK)
- [x] Zhipu AI プロバイダによる正常なチャット応答
- [x] 内部処理モデルの切り替え（Google <-> Zhipu）
- [x] API キー保存と初期ロード時の自動反映
- [x] エンティティ記憶の書き込みエラー解消確認

---

## 残課題（あれば）

- Groq 対応、ローカル LLM (llama.cpp) 対応（Phase 3 の後半ステップとして継続検討）
- フォールバック機構の実装 (Phase 4)
